{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-learning for GridWorld - Complete code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from Gridworld import Gridworld\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set = {\n",
    "    0: 'u',\n",
    "    1: 'd',\n",
    "    2: 'l',\n",
    "    3: 'r',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experience Replay to eliminate Catastrophic forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = 29\n",
    "l2 = 64\n",
    "l3 = 32\n",
    "l4 = 5\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(l1, l2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l2, l3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l3,l4)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9\n",
    "epsilon = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Target network to handle learning instability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Training with Experience Replay and Target Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main network and target network\n",
    "model2 = copy.deepcopy(model)  # Target network\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training hyperparameters\n",
    "gamma = 0.99      # Discount factor\n",
    "epsilon = 1.0     # Initial exploration rate\n",
    "epsilon_min = 0.1 # Minimum exploration rate\n",
    "epsilon_decay = 0.995  # Decay rate for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting compound training with curriculum learning...\n",
      "\n",
      "===== Starting Stage 1/7 =====\n",
      "Grid sizes: [5, 6]\n",
      "Obstacles: (1, 3)\n",
      "Patterns: ['random']\n",
      "Episodes: 500\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Gridworld' object has no attribute 'add_border_walls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 413\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m success_rate, avg_reward\n\u001b[1;32m    412\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m--> 413\u001b[0m results \u001b[38;5;241m=\u001b[39m train_compound(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, memory_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m, render_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m    414\u001b[0m model \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# Save final model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 102\u001b[0m, in \u001b[0;36mtrain_compound\u001b[0;34m(epochs, batch_size, memory_size, render_interval)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Create environment for this episode\u001b[39;00m\n\u001b[1;32m    101\u001b[0m max_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(grid_size \u001b[38;5;241m*\u001b[39m stage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_steps_factor\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Scale max steps with grid size\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m game \u001b[38;5;241m=\u001b[39m Gridworld(size\u001b[38;5;241m=\u001b[39mgrid_size, mode\u001b[38;5;241m=\u001b[39mpattern, num_obstacles\u001b[38;5;241m=\u001b[39mnum_obstacles, max_steps\u001b[38;5;241m=\u001b[39mmax_steps)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Initialize state\u001b[39;00m\n\u001b[1;32m    105\u001b[0m state \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Desktop/ISEF/Active_Inference/Active-Inference-2025/Experiment/New_RL/Gridworld.py:68\u001b[0m, in \u001b[0;36mGridworld.__init__\u001b[0;34m(self, size, mode, num_obstacles, random_seed, max_steps, use_coppeliasim)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;241m=\u001b[39m spaces\u001b[38;5;241m.\u001b[39mBox(\n\u001b[1;32m     61\u001b[0m     low\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m     62\u001b[0m     high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \n\u001b[1;32m     63\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m29\u001b[39m,), \n\u001b[1;32m     64\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Reset to initialize the environment\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Desktop/ISEF/Active_Inference/Active-Inference-2025/Experiment/New_RL/Gridworld.py:131\u001b[0m, in \u001b[0;36mGridworld.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Add border walls first - this is now done for ALL environment types\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_border_walls()\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Generate additional obstacles based on mode\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Add random obstacles\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Gridworld' object has no attribute 'add_border_walls'"
     ]
    }
   ],
   "source": [
    "# Enhanced Compound Training Function\n",
    "def train_compound(epochs=20000, batch_size=64, memory_size=100000, render_interval=500):\n",
    "    # Initialize metrics tracking\n",
    "    losses = []\n",
    "    all_rewards = []\n",
    "    avg_rewards = []\n",
    "    success_rates = []\n",
    "    best_eval_score = float('-inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Create replay memory\n",
    "    replay = deque(maxlen=memory_size)\n",
    "    \n",
    "    # Create model checkpoint directory\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    # Initialize epsilon for exploration\n",
    "    epsilon = 1.0\n",
    "    epsilon_min = 0.05\n",
    "    epsilon_decay_rate = 0.99995  # Slower decay for more exploration\n",
    "    \n",
    "    # Set up curriculum - progression from very simple to complex environments\n",
    "    curriculum = [\n",
    "        # Stage 1: Very small grids (5x5, 6x6) with minimal obstacles\n",
    "        {'episodes': int(epochs * 0.05), 'grid_sizes': [5, 6], 'obstacles': (1, 3), 'patterns': ['random'], \n",
    "         'max_steps_factor': 3, 'epsilon_min': 0.2},\n",
    "        \n",
    "        # Stage 2: Small grids (7x7, 8x8) with few obstacles\n",
    "        {'episodes': int(epochs * 0.1), 'grid_sizes': [7, 8], 'obstacles': (2, 5), 'patterns': ['random'], \n",
    "         'max_steps_factor': 3, 'epsilon_min': 0.15},\n",
    "        \n",
    "        # Stage 3: Medium-small grids (10x10, 12x12) with more obstacles\n",
    "        {'episodes': int(epochs * 0.15), 'grid_sizes': [10, 12], 'obstacles': (4, 8), 'patterns': ['random', 'clusters'],\n",
    "         'max_steps_factor': 2.5, 'epsilon_min': 0.1},\n",
    "        \n",
    "        # Stage 4: Medium grids (15x15, 18x18) with more complexity\n",
    "        {'episodes': int(epochs * 0.2), 'grid_sizes': [15, 18], 'obstacles': (6, 12), 'patterns': ['random', 'clusters'],\n",
    "         'max_steps_factor': 2.5, 'epsilon_min': 0.1},\n",
    "        \n",
    "        # Stage 5: Large grids (20x20, 25x25) with challenging obstacles\n",
    "        {'episodes': int(epochs * 0.2), 'grid_sizes': [20, 25], 'obstacles': (10, 20), 'patterns': ['random', 'clusters', 'walls'],\n",
    "         'max_steps_factor': 2.2, 'epsilon_min': 0.08},\n",
    "        \n",
    "        # Stage 6: Very large grids (30x30, 35x35) with complex obstacles\n",
    "        {'episodes': int(epochs * 0.15), 'grid_sizes': [30, 35], 'obstacles': (15, 30), 'patterns': ['random', 'clusters', 'walls'],\n",
    "         'max_steps_factor': 2.0, 'epsilon_min': 0.05},\n",
    "        \n",
    "        # Stage 7: Extremely large grids (40x40) with many obstacles\n",
    "        {'episodes': int(epochs * 0.15), 'grid_sizes': [40], 'obstacles': (20, 40), 'patterns': ['random', 'clusters', 'walls'],\n",
    "         'max_steps_factor': 2.0, 'epsilon_min': 0.05}\n",
    "    ]\n",
    "    \n",
    "    # Setup for periodic evaluation\n",
    "    eval_interval = 200  # Evaluate model every 200 episodes\n",
    "    eval_episodes = 20   # Number of episodes to use for evaluation\n",
    "    \n",
    "    # Validation environments for consistent evaluation\n",
    "    validation_envs = [\n",
    "        # Simple validation environments\n",
    "        (10, 5, 'random'),   # (grid_size, obstacles, pattern)\n",
    "        (15, 10, 'random'),\n",
    "        (20, 15, 'clusters'),\n",
    "        (30, 20, 'walls'),\n",
    "        (40, 30, 'random')\n",
    "    ]\n",
    "\n",
    "    # Define sync frequency for target network updates (steps)\n",
    "    sync_freq = 1000\n",
    "    \n",
    "    # Global step counter\n",
    "    global_step = 0\n",
    "    episode_count = 0\n",
    "    \n",
    "    print(\"Starting compound training with curriculum learning...\")\n",
    "    \n",
    "    # Loop through curriculum stages\n",
    "    for stage_idx, stage in enumerate(curriculum):\n",
    "        print(f\"\\n===== Starting Stage {stage_idx + 1}/{len(curriculum)} =====\")\n",
    "        print(f\"Grid sizes: {stage['grid_sizes']}\")\n",
    "        print(f\"Obstacles: {stage['obstacles']}\")\n",
    "        print(f\"Patterns: {stage['patterns']}\")\n",
    "        print(f\"Episodes: {stage['episodes']}\")\n",
    "        \n",
    "        # Update epsilon min for this stage\n",
    "        stage_epsilon_min = stage['epsilon_min']\n",
    "        \n",
    "        # Reset epsilon for new stage if needed (optional - keep this line if you want epsilon reset per stage)\n",
    "        epsilon = max(1.0 - stage_idx * 0.1, 0.5)  # Start with less exploration in later stages\n",
    "        \n",
    "        # Track episodes in this stage\n",
    "        stage_episodes = 0\n",
    "        \n",
    "        # Continue until we've completed the designated episodes for this stage\n",
    "        while stage_episodes < stage['episodes'] and episode_count < epochs:\n",
    "            # Select random parameters for this episode\n",
    "            grid_size = random.choice(stage['grid_sizes'])\n",
    "            num_obstacles = random.randint(stage['obstacles'][0], stage['obstacles'][1])\n",
    "            pattern = random.choice(stage['patterns'])\n",
    "            \n",
    "            # Create environment for this episode\n",
    "            max_steps = int(grid_size * stage['max_steps_factor'])  # Scale max steps with grid size\n",
    "            game = Gridworld(size=grid_size, mode=pattern, num_obstacles=num_obstacles, max_steps=max_steps)\n",
    "            \n",
    "            # Initialize state\n",
    "            state = game.reset()\n",
    "            state = torch.from_numpy(state).float().unsqueeze(0)  # Add batch dimension\n",
    "            \n",
    "            done = False\n",
    "            steps = 0\n",
    "            episode_reward = 0\n",
    "            success = False\n",
    "            \n",
    "            # Display info periodically\n",
    "            should_render = (episode_count % render_interval == 0)\n",
    "            \n",
    "            if episode_count % 50 == 0:\n",
    "                print(f\"Episode {episode_count}/{epochs} (Stage {stage_idx+1}, Ep {stage_episodes}/{stage['episodes']})\")\n",
    "                print(f\"Grid: {grid_size}x{grid_size}, Obstacles: {num_obstacles}, Pattern: {pattern}\")\n",
    "                print(f\"Epsilon: {epsilon:.4f}, Memory: {len(replay)}/{memory_size}\")\n",
    "            \n",
    "            # Run episode\n",
    "            while not done and steps < max_steps:\n",
    "                steps += 1\n",
    "                global_step += 1\n",
    "                \n",
    "                # Epislon-greedy action selection\n",
    "                if random.random() < epsilon:\n",
    "                    action = random.randint(0, 4)  # Random action\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        q_values = model(state)\n",
    "                        action = torch.argmax(q_values).item()  # Greedy action\n",
    "                \n",
    "                # Take action in environment\n",
    "                next_state, reward, done, info = game.step(action)\n",
    "                next_state = torch.from_numpy(next_state).float().unsqueeze(0)\n",
    "                \n",
    "                # Record success if goal reached\n",
    "                if reward > 0:  # Assuming positive reward means goal reached\n",
    "                    success = True\n",
    "                \n",
    "                # Store in replay memory\n",
    "                replay.append((state, action, reward, next_state, done))\n",
    "                \n",
    "                # Update state and accumulate reward\n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "                \n",
    "                # Render if needed\n",
    "                if should_render and steps % 5 == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    game.render()\n",
    "                    plt.title(f\"Stage {stage_idx+1}, Episode {episode_count}, Step {steps}, Reward: {episode_reward:.2f}\")\n",
    "                    plt.pause(0.1)\n",
    "                \n",
    "                # Training step (if we have enough samples)\n",
    "                if len(replay) >= batch_size:\n",
    "                    # Sample mini-batch\n",
    "                    minibatch = random.sample(replay, batch_size)\n",
    "                    \n",
    "                    # Extract batch components\n",
    "                    state_batch = torch.cat([s1 for (s1, _, _, _, _) in minibatch])\n",
    "                    action_batch = torch.tensor([a for (_, a, _, _, _) in minibatch], dtype=torch.long)\n",
    "                    reward_batch = torch.tensor([r for (_, _, r, _, _) in minibatch], dtype=torch.float)\n",
    "                    next_state_batch = torch.cat([s2 for (_, _, _, s2, _) in minibatch])\n",
    "                    done_batch = torch.tensor([d for (_, _, _, _, d) in minibatch], dtype=torch.float)\n",
    "                    \n",
    "                    # Compute current Q values\n",
    "                    current_Q = model(state_batch).gather(1, action_batch.unsqueeze(1)).squeeze(1)\n",
    "                    \n",
    "                    # Double DQN: Use online network to select actions, target network to evaluate\n",
    "                    with torch.no_grad():\n",
    "                        # Find best actions using online model\n",
    "                        best_actions = model(next_state_batch).max(1)[1].unsqueeze(1)\n",
    "                        # Evaluate those actions using target model\n",
    "                        next_Q = model2(next_state_batch).gather(1, best_actions).squeeze(1)\n",
    "                        # Compute target Q values\n",
    "                        target_Q = reward_batch + gamma * next_Q * (1 - done_batch)\n",
    "                    \n",
    "                    # Compute loss and update model\n",
    "                    loss = loss_fn(current_Q, target_Q)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # Gradient clipping to prevent exploding gradients\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # Store loss\n",
    "                    losses.append(loss.item())\n",
    "                \n",
    "                # Update target network\n",
    "                if global_step % sync_freq == 0:\n",
    "                    model2.load_state_dict(model.state_dict())\n",
    "                    print(f\"Target network updated at step {global_step}\")\n",
    "            \n",
    "            # Episode completed\n",
    "            all_rewards.append(episode_reward)\n",
    "            \n",
    "            # Calculate running average reward\n",
    "            window_size = min(100, len(all_rewards))\n",
    "            avg_reward = sum(all_rewards[-window_size:]) / window_size\n",
    "            avg_rewards.append(avg_reward)\n",
    "            \n",
    "            # Print episode results\n",
    "            if success:\n",
    "                print(f\"Episode {episode_count}: Success! Reward: {episode_reward:.2f}, Steps: {steps}\")\n",
    "            elif episode_count % 50 == 0:\n",
    "                print(f\"Episode {episode_count}: Failed. Reward: {episode_reward:.2f}, Steps: {steps}\")\n",
    "            \n",
    "            # Evaluate periodically\n",
    "            if episode_count % eval_interval == 0 and episode_count > 0:\n",
    "                print(\"\\nRunning evaluation...\")\n",
    "                eval_success_rate, eval_avg_reward = evaluate_model(model, validation_envs, episodes_per_env=eval_episodes)\n",
    "                success_rates.append(eval_success_rate)\n",
    "                \n",
    "                print(f\"Evaluation - Success rate: {eval_success_rate:.2f}, Avg reward: {eval_avg_reward:.2f}\")\n",
    "                \n",
    "                # Save best model\n",
    "                eval_score = eval_success_rate * 10 + eval_avg_reward  # Combined metric\n",
    "                if eval_score > best_eval_score:\n",
    "                    best_eval_score = eval_score\n",
    "                    best_model_state = model.state_dict().copy()\n",
    "                    print(f\"New best model with eval score {eval_score:.2f}!\")\n",
    "                    \n",
    "                    # Save best model\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'epsilon': epsilon,\n",
    "                        'episode': episode_count,\n",
    "                        'eval_score': eval_score,\n",
    "                        'success_rate': eval_success_rate,\n",
    "                        'avg_reward': eval_avg_reward,\n",
    "                    }, 'models/dqn_best.pth')\n",
    "            \n",
    "            # Checkpoint model periodically\n",
    "            if episode_count % 500 == 0 and episode_count > 0:\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'epsilon': epsilon,\n",
    "                    'episode': episode_count,\n",
    "                    'stage': stage_idx,\n",
    "                    'all_rewards': all_rewards,\n",
    "                    'avg_rewards': avg_rewards,\n",
    "                    'losses': losses,\n",
    "                }, f'models/dqn_checkpoint_ep{episode_count}.pth')\n",
    "                print(f\"Checkpoint saved at episode {episode_count}\")\n",
    "            \n",
    "            # Decay epsilon - but respect the minimum for this stage\n",
    "            epsilon = max(stage_epsilon_min, epsilon * epsilon_decay_rate)\n",
    "            \n",
    "            # Increment counters\n",
    "            episode_count += 1\n",
    "            stage_episodes += 1\n",
    "        \n",
    "        # End of stage - evaluate and save stage model\n",
    "        print(f\"\\n===== Completed Stage {stage_idx + 1}/{len(curriculum)} =====\")\n",
    "        stage_eval_success, stage_eval_reward = evaluate_model(model, validation_envs, episodes_per_env=eval_episodes)\n",
    "        \n",
    "        print(f\"Stage {stage_idx+1} Evaluation - Success rate: {stage_eval_success:.2f}, Avg reward: {stage_eval_reward:.2f}\")\n",
    "        \n",
    "        # Save stage model\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epsilon': epsilon,\n",
    "            'episode': episode_count,\n",
    "            'stage': stage_idx,\n",
    "            'success_rate': stage_eval_success,\n",
    "            'avg_reward': stage_eval_reward,\n",
    "        }, f'models/dqn_stage{stage_idx+1}.pth')\n",
    "    \n",
    "    # Training complete - final evaluation with best model\n",
    "    print(\"\\n===== Training Complete =====\")\n",
    "    \n",
    "    # Load best model for final evaluation\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model for final evaluation\")\n",
    "    \n",
    "    # Comprehensive final evaluation\n",
    "    print(\"\\nRunning final evaluation...\")\n",
    "    final_success_rate, final_avg_reward = evaluate_model(model, validation_envs, episodes_per_env=50)  # More episodes for final eval\n",
    "    \n",
    "    print(f\"Final Evaluation - Success rate: {final_success_rate:.2f}, Avg reward: {final_avg_reward:.2f}\")\n",
    "    \n",
    "    # Plot training metrics\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(all_rewards)\n",
    "    plt.title('Episode Rewards')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(avg_rewards)\n",
    "    plt.title('Average Reward (100 episodes)')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Reward')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(losses[-10000:])  # Plot last 10000 losses to see recent trends\n",
    "    plt.title('Training Loss (last 10000 updates)')\n",
    "    plt.xlabel('Update Step')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    if success_rates:\n",
    "        plt.subplot(2, 2, 4)\n",
    "        # Generate x values that match exactly with the length of success_rates\n",
    "        eval_points = np.arange(eval_interval, eval_interval * (len(success_rates) + 1), eval_interval)[:len(success_rates)]\n",
    "        plt.plot(eval_points, success_rates)\n",
    "        plt.title('Evaluation Success Rate')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Success Rate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('models/training_curves.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epsilon': epsilon,\n",
    "        'episode': episode_count,\n",
    "        'final_success_rate': final_success_rate,\n",
    "        'final_avg_reward': final_avg_reward,\n",
    "    }, 'models/dqn_final.pth')\n",
    "    \n",
    "    # Return relevant data for analysis\n",
    "    return {\n",
    "        'model': model,\n",
    "        'rewards': all_rewards,\n",
    "        'avg_rewards': avg_rewards,\n",
    "        'losses': losses,\n",
    "        'success_rates': success_rates,\n",
    "        'final_success_rate': final_success_rate,\n",
    "        'final_avg_reward': final_avg_reward,\n",
    "        'best_eval_score': best_eval_score\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, env_configs, episodes_per_env=10):\n",
    "    \"\"\"\n",
    "    Evaluate model on multiple environment configurations\n",
    "    \n",
    "    Args:\n",
    "        model: The DQN model to evaluate\n",
    "        env_configs: List of tuples (grid_size, num_obstacles, pattern)\n",
    "        episodes_per_env: Number of episodes to run for each environment config\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (success_rate, average_reward)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    success_count = 0\n",
    "    total_rewards = []\n",
    "    total_episodes = len(env_configs) * episodes_per_env\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for grid_size, num_obstacles, pattern in env_configs:\n",
    "            print(f\"Evaluating on grid {grid_size}x{grid_size}, {num_obstacles} obstacles, {pattern} pattern\")\n",
    "            \n",
    "            for ep in range(episodes_per_env):\n",
    "                # Create environment\n",
    "                max_steps = grid_size * 2\n",
    "                game = Gridworld(size=grid_size, mode=pattern, num_obstacles=num_obstacles, max_steps=max_steps)\n",
    "                \n",
    "                state = game.reset()\n",
    "                state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "                \n",
    "                done = False\n",
    "                steps = 0\n",
    "                episode_reward = 0\n",
    "                success = False\n",
    "                \n",
    "                while not done and steps < max_steps:\n",
    "                    steps += 1\n",
    "                    \n",
    "                    # Get action from model - no exploration during evaluation\n",
    "                    q_values = model(state)\n",
    "                    action = torch.argmax(q_values).item()\n",
    "                    \n",
    "                    # Take action\n",
    "                    next_state, reward, done, info = game.step(action)\n",
    "                    next_state = torch.from_numpy(next_state).float().unsqueeze(0)\n",
    "                    \n",
    "                    # Update state and reward\n",
    "                    state = next_state\n",
    "                    episode_reward += reward\n",
    "                    \n",
    "                    # Check for success\n",
    "                    if reward > 0:  # Positive reward means goal reached\n",
    "                        success = True\n",
    "                        break\n",
    "                \n",
    "                # Record results\n",
    "                if success:\n",
    "                    success_count += 1\n",
    "                total_rewards.append(episode_reward)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    success_rate = success_count / total_episodes\n",
    "    avg_reward = sum(total_rewards) / len(total_rewards)\n",
    "    \n",
    "    model.train()  # Set model back to training mode\n",
    "    return success_rate, avg_reward\n",
    "\n",
    "epochs = 10000\n",
    "results = train_compound(epochs=10000, batch_size=64, memory_size=50000, render_interval=500)\n",
    "model = results['model']\n",
    "\n",
    "# Save final model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epsilon': epsilon,\n",
    "    'episode': epochs,\n",
    "}, 'models/dqn_final.pth')\n",
    "print(\"Training completed. Final model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ FAILED! Agent did not reach goal after 120 steps. Reward: -24.0\n",
      "Warning: Environment mode 'walls' not recognized. Using 'random'.\n",
      "Warning: Environment mode 'walls' not recognized. Using 'random'.\n",
      "Warning: Environment mode 'walls' not recognized. Using 'random'.\n",
      "Warning: Environment mode 'walls' not recognized. Using 'random'.\n",
      "Completed 3/3 episodes. Current success rate: 0.00\n",
      "\n",
      "===== TEST RESULTS SUMMARY =====\n",
      "Overall Success Rate: 0.33\n",
      "Overall Average Steps: 86.00\n",
      "Overall Average Reward: -19.27\n",
      "\n",
      "--- Results by Grid Size ---\n",
      "Size 40×40: Success Rate 0.33, Avg Steps 86.00, Avg Reward -19.27\n"
     ]
    }
   ],
   "source": [
    "# Clear testing function with visualization and proper return values\n",
    "def test_model(size=40, mode='random', obstacles=30, max_steps=150, \n",
    "               render=True, pause_time=0.1):\n",
    "    \"\"\"\n",
    "    Test a single episode with the current model\n",
    "    \n",
    "    Args:\n",
    "        size: Grid size (default 15)\n",
    "        mode: Obstacle pattern - 'random', 'clusters', or 'walls' (default 'random')\n",
    "        obstacles: Number of obstacles (default 10)\n",
    "        max_steps: Maximum steps allowed (default 50)\n",
    "        render: Whether to render the environment (default True)\n",
    "        pause_time: Time to pause between renders (default 0.1)\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if agent reached goal, False otherwise\n",
    "        int: Number of steps taken\n",
    "        float: Total reward accumulated\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Create environment\n",
    "    game = Gridworld(size=size, mode=mode, num_obstacles=obstacles, max_steps=max_steps)\n",
    "    \n",
    "    # Initialize state\n",
    "    state = game.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    # Print initial positions if rendering\n",
    "    if render:\n",
    "        print(f\"\\nStarting test: {size}x{size} grid, {obstacles} obstacles, {mode} pattern\")\n",
    "        print(f\"Agent at {game.player_position}, Goal at {game.goal_position}\")\n",
    "        print(f\"Manhattan distance: {abs(game.player_position[0] - game.goal_position[0]) + abs(game.player_position[1] - game.goal_position[1])}\")\n",
    "    \n",
    "    # Run episode\n",
    "    done = False\n",
    "    steps = 0\n",
    "    total_reward = 0\n",
    "    success = False\n",
    "    \n",
    "    while not done and steps < max_steps:\n",
    "        # Select action\n",
    "        with torch.no_grad():\n",
    "            q_values = model(state)\n",
    "            action = torch.argmax(q_values).item()\n",
    "        \n",
    "        # Take action\n",
    "        next_state, reward, done, info = game.step(action)\n",
    "        next_state = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Update state and tracking variables\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "        # Check for success\n",
    "        if reward > 0:  # Positive reward means reached goal\n",
    "            success = True\n",
    "            done = True\n",
    "        \n",
    "        # Render if requested\n",
    "        if render and (steps % 2 == 0 or done):  # Render every other step\n",
    "            clear_output(wait=True)\n",
    "            game.render()\n",
    "            status = \"SUCCESS!\" if success else (\"FAILED!\" if done else \"In progress...\")\n",
    "            plt.title(f\"Step {steps}/{max_steps}, Reward: {total_reward:.1f}, Status: {status}\")\n",
    "            plt.pause(pause_time)\n",
    "    \n",
    "    # Final status message\n",
    "    if render:\n",
    "        if success:\n",
    "            print(f\"\\n✅ SUCCESS! Goal reached in {steps} steps with reward {total_reward:.1f}\")\n",
    "        else:\n",
    "            print(f\"\\n❌ FAILED! Agent did not reach goal after {steps} steps. Reward: {total_reward:.1f}\")\n",
    "    \n",
    "    return success, steps, total_reward\n",
    "\n",
    "# Function to run multiple test episodes and collect statistics\n",
    "def run_test_suite(model_path=None, num_episodes=50, grid_sizes=None, render_one=True):\n",
    "    \"\"\"\n",
    "    Run a comprehensive test suite on the model\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to model to load (None to use current model)\n",
    "        num_episodes: Total number of episodes to test (default 50)\n",
    "        grid_sizes: List of grid sizes to test (default [10, 20, 40])\n",
    "        render_one: Whether to render one episode per configuration (default True)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Test results by grid size and overall\n",
    "    \"\"\"\n",
    "    # Load model if path provided\n",
    "    if model_path:\n",
    "        try:\n",
    "            checkpoint = torch.load(model_path)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            print(f\"Loaded model from {model_path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"⚠️ Model not found at {model_path}, using current model\")\n",
    "    \n",
    "    # Set evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Define test configurations if not provided\n",
    "    if grid_sizes is None:\n",
    "        grid_sizes = [10, 20, 40]\n",
    "    \n",
    "    # Create test environments\n",
    "    test_configs = []\n",
    "    for size in grid_sizes:\n",
    "        # Scale obstacles and steps based on grid size\n",
    "        easy_obstacles = max(3, int(size * 0.1))\n",
    "        medium_obstacles = max(5, int(size * 0.2))\n",
    "        hard_obstacles = max(8, int(size * 0.3))\n",
    "        max_steps = size * 3\n",
    "        \n",
    "        # Add configurations for this grid size\n",
    "        test_configs.extend([\n",
    "            {\"size\": size, \"obstacles\": easy_obstacles, \"mode\": \"random\", \"max_steps\": max_steps},\n",
    "            {\"size\": size, \"obstacles\": medium_obstacles, \"mode\": \"clusters\", \"max_steps\": max_steps},\n",
    "            {\"size\": size, \"obstacles\": hard_obstacles, \"mode\": \"walls\", \"max_steps\": max_steps}\n",
    "        ])\n",
    "    \n",
    "    # Results tracking\n",
    "    results = {\n",
    "        \"overall\": {\"success\": 0, \"episodes\": 0, \"total_steps\": 0, \"total_reward\": 0},\n",
    "        \"by_size\": {size: {\"success\": 0, \"episodes\": 0, \"total_steps\": 0, \"total_reward\": 0} for size in grid_sizes},\n",
    "        \"by_config\": {}\n",
    "    }\n",
    "    \n",
    "    # Distribute episodes across configurations\n",
    "    episodes_per_config = max(1, num_episodes // len(test_configs))\n",
    "    total_episodes = episodes_per_config * len(test_configs)\n",
    "    \n",
    "    print(f\"Starting test suite with {total_episodes} total episodes across {len(test_configs)} configurations\")\n",
    "    print(f\"Testing grid sizes: {grid_sizes}\")\n",
    "    \n",
    "    # Test each configuration\n",
    "    for config_idx, config in enumerate(test_configs):\n",
    "        size = config[\"size\"]\n",
    "        mode = config[\"mode\"]\n",
    "        obstacles = config[\"obstacles\"]\n",
    "        max_steps = config[\"max_steps\"]\n",
    "        \n",
    "        # Create config key\n",
    "        config_key = f\"{size}x{size}_{mode}_{obstacles}\"\n",
    "        results[\"by_config\"][config_key] = {\"success\": 0, \"episodes\": 0, \"total_steps\": 0, \"total_reward\": 0}\n",
    "        \n",
    "        print(f\"\\n--- Testing Configuration {config_idx+1}/{len(test_configs)}: Size {size}, {obstacles} obstacles, {mode} pattern ---\")\n",
    "        \n",
    "        # Run episodes for this configuration\n",
    "        for ep in range(episodes_per_config):\n",
    "            # Determine if we should render this episode\n",
    "            should_render = render_one and ep == 0\n",
    "            \n",
    "            # Run test episode\n",
    "            success, steps, reward = test_model(\n",
    "                size=size, \n",
    "                mode=mode,\n",
    "                obstacles=obstacles, \n",
    "                max_steps=max_steps,\n",
    "                render=should_render,\n",
    "                pause_time=0.05 if should_render else 0\n",
    "            )\n",
    "            \n",
    "            # Update results\n",
    "            results[\"overall\"][\"episodes\"] += 1\n",
    "            results[\"overall\"][\"success\"] += 1 if success else 0\n",
    "            results[\"overall\"][\"total_steps\"] += steps\n",
    "            results[\"overall\"][\"total_reward\"] += reward\n",
    "            \n",
    "            results[\"by_size\"][size][\"episodes\"] += 1\n",
    "            results[\"by_size\"][size][\"success\"] += 1 if success else 0\n",
    "            results[\"by_size\"][size][\"total_steps\"] += steps\n",
    "            results[\"by_size\"][size][\"total_reward\"] += reward\n",
    "            \n",
    "            results[\"by_config\"][config_key][\"episodes\"] += 1\n",
    "            results[\"by_config\"][config_key][\"success\"] += 1 if success else 0\n",
    "            results[\"by_config\"][config_key][\"total_steps\"] += steps\n",
    "            results[\"by_config\"][config_key][\"total_reward\"] += reward\n",
    "            \n",
    "            # Print progress\n",
    "            if (ep + 1) % 5 == 0 or ep == episodes_per_config - 1:\n",
    "                success_rate = results[\"by_config\"][config_key][\"success\"] / (ep + 1)\n",
    "                print(f\"Completed {ep+1}/{episodes_per_config} episodes. Current success rate: {success_rate:.2f}\")\n",
    "    \n",
    "    # Calculate final statistics\n",
    "    # Overall stats\n",
    "    results[\"overall\"][\"success_rate\"] = results[\"overall\"][\"success\"] / results[\"overall\"][\"episodes\"]\n",
    "    results[\"overall\"][\"avg_steps\"] = results[\"overall\"][\"total_steps\"] / results[\"overall\"][\"episodes\"]\n",
    "    results[\"overall\"][\"avg_reward\"] = results[\"overall\"][\"total_reward\"] / results[\"overall\"][\"episodes\"]\n",
    "    \n",
    "    # Stats by grid size\n",
    "    for size in grid_sizes:\n",
    "        size_data = results[\"by_size\"][size]\n",
    "        size_data[\"success_rate\"] = size_data[\"success\"] / size_data[\"episodes\"]\n",
    "        size_data[\"avg_steps\"] = size_data[\"total_steps\"] / size_data[\"episodes\"]\n",
    "        size_data[\"avg_reward\"] = size_data[\"total_reward\"] / size_data[\"episodes\"]\n",
    "    \n",
    "    # Stats by configuration\n",
    "    for config_key, config_data in results[\"by_config\"].items():\n",
    "        config_data[\"success_rate\"] = config_data[\"success\"] / config_data[\"episodes\"]\n",
    "        config_data[\"avg_steps\"] = config_data[\"total_steps\"] / config_data[\"episodes\"]\n",
    "        config_data[\"avg_reward\"] = config_data[\"total_reward\"] / config_data[\"episodes\"]\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n===== TEST RESULTS SUMMARY =====\")\n",
    "    print(f\"Overall Success Rate: {results['overall']['success_rate']:.2f}\")\n",
    "    print(f\"Overall Average Steps: {results['overall']['avg_steps']:.2f}\")\n",
    "    print(f\"Overall Average Reward: {results['overall']['avg_reward']:.2f}\")\n",
    "    \n",
    "    print(\"\\n--- Results by Grid Size ---\")\n",
    "    for size in grid_sizes:\n",
    "        size_data = results[\"by_size\"][size]\n",
    "        print(f\"Size {size}×{size}: Success Rate {size_data['success_rate']:.2f}, \" +\n",
    "              f\"Avg Steps {size_data['avg_steps']:.2f}, Avg Reward {size_data['avg_reward']:.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage example:\n",
    "# Load and test the final model\n",
    "results = run_test_suite(model_path='models/dqn_final.pth', \n",
    "                         num_episodes=10,  # 30 episodes per grid size\n",
    "                         grid_sizes=[40],\n",
    "                         render_one=True)\n",
    "\n",
    "# To test without loading a saved model (using the current model):\n",
    "# results = run_test_suite(num_episodes=90, grid_sizes=[10, 20, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
