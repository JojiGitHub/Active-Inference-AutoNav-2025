{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-learning for GridWorld - Complete code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from Gridworld import Gridworld\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set = {\n",
    "    0: 'u',\n",
    "    1: 'd',\n",
    "    2: 'l',\n",
    "    3: 'r',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced DQN model - lighter regularization\n",
    "class BalancedDQN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=29, output_dim=4):\n",
    "        super(BalancedDQN, self).__init__()\n",
    "        # First layer with lighter dropout\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 128)\n",
    "        self.dropout1 = torch.nn.Dropout(0.1)  # Reduced dropout (10%)\n",
    "        \n",
    "        # Second layer with lighter dropout\n",
    "        self.fc2 = torch.nn.Linear(128, 128)\n",
    "        self.dropout2 = torch.nn.Dropout(0.1)  # Reduced dropout (10%)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc3 = torch.nn.Linear(128, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # No batch normalization, which can be destabilizing for RL\n",
    "        # Simple clean forward pass with minimal regularization\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        # Only use dropout during training\n",
    "        if self.training:\n",
    "            x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        if self.training:\n",
    "            x = self.dropout2(x)\n",
    "            \n",
    "        return self.fc3(x)\n",
    "    \n",
    "model = BalancedDQN(input_dim=29, output_dim=4)\n",
    "    \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9\n",
    "epsilon = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Target network to handle learning instability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Training with Experience Replay and Target Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main network and target network\n",
    "model2 = copy.deepcopy(model)  # Target network\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training hyperparameters\n",
    "gamma = 0.99      # Discount factor\n",
    "epsilon = 1.0     # Initial exploration rate\n",
    "epsilon_min = 0.1 # Minimum exploration rate\n",
    "epsilon_decay = 0.995  # Decay rate for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500: Success! Reward: 9.40, Steps: 19\n",
      "Checkpoint saved at episode 500\n",
      "Episode 501: Success! Reward: 10.20, Steps: 7\n",
      "Episode 502: Success! Reward: -3.60, Steps: 21\n",
      "Episode 503: Success! Reward: 9.00, Steps: 15\n",
      "Episode 504: Success! Reward: 8.60, Steps: 18\n",
      "Episode 505: Success! Reward: 10.40, Steps: 2\n",
      "Episode 506: Success! Reward: 9.80, Steps: 8\n",
      "Episode 507: Success! Reward: -2.60, Steps: 21\n",
      "Episode 508: Success! Reward: 9.60, Steps: 15\n",
      "Episode 509: Success! Reward: 9.80, Steps: 2\n",
      "Episode 510: Success! Reward: 9.80, Steps: 17\n",
      "Episode 511: Success! Reward: -2.60, Steps: 21\n",
      "Episode 512: Success! Reward: -3.60, Steps: 21\n",
      "Episode 513: Success! Reward: -3.20, Steps: 21\n",
      "Episode 514: Success! Reward: -1.60, Steps: 21\n",
      "Episode 515: Success! Reward: -3.40, Steps: 21\n",
      "Episode 516: Success! Reward: 10.60, Steps: 5\n",
      "Episode 517: Success! Reward: 9.60, Steps: 4\n",
      "Episode 518: Success! Reward: -2.00, Steps: 21\n",
      "Episode 519: Success! Reward: 8.60, Steps: 15\n",
      "Episode 520: Success! Reward: 9.20, Steps: 7\n",
      "Episode 521: Success! Reward: 8.80, Steps: 11\n",
      "Episode 522: Success! Reward: 10.80, Steps: 6\n",
      "Episode 523: Success! Reward: -3.00, Steps: 21\n",
      "Episode 524: Success! Reward: 9.80, Steps: 2\n",
      "Episode 525: Success! Reward: 7.80, Steps: 17\n",
      "Episode 526: Success! Reward: -2.40, Steps: 21\n",
      "Episode 527: Success! Reward: 8.80, Steps: 12\n",
      "Episode 528: Success! Reward: 8.80, Steps: 9\n",
      "Episode 529: Success! Reward: -4.00, Steps: 21\n",
      "Episode 530: Success! Reward: -3.20, Steps: 21\n",
      "Episode 531: Success! Reward: 9.20, Steps: 13\n",
      "Episode 532: Success! Reward: -1.60, Steps: 21\n",
      "Episode 533: Success! Reward: -3.00, Steps: 21\n",
      "Episode 534: Success! Reward: 10.40, Steps: 2\n",
      "Episode 535: Success! Reward: 10.00, Steps: 1\n",
      "Episode 536: Success! Reward: -2.60, Steps: 21\n",
      "Episode 537: Success! Reward: 9.00, Steps: 16\n",
      "Episode 538: Success! Reward: 10.00, Steps: 1\n",
      "Episode 539: Success! Reward: 8.00, Steps: 21\n",
      "Episode 540: Success! Reward: 10.40, Steps: 2\n",
      "Episode 541: Success! Reward: 10.00, Steps: 1\n",
      "Episode 542: Success! Reward: -2.60, Steps: 21\n",
      "Episode 543: Success! Reward: 9.40, Steps: 8\n",
      "Episode 544: Success! Reward: -3.40, Steps: 21\n",
      "Episode 545: Success! Reward: 9.40, Steps: 18\n",
      "Episode 546: Success! Reward: 9.40, Steps: 4\n",
      "Episode 547: Success! Reward: 10.00, Steps: 1\n",
      "Episode 548: Success! Reward: 9.80, Steps: 2\n",
      "Episode 549: Success! Reward: -3.80, Steps: 21\n",
      "Episode 550/24000 (Stage 2, Ep 70/720)\n",
      "Grid: 6x6, Obstacles: 2, Pattern: random\n",
      "Epsilon: 0.8969, Memory: 5768/50000\n",
      "Episode 550: Success! Reward: 10.80, Steps: 8\n",
      "Episode 551: Success! Reward: 9.20, Steps: 8\n",
      "Episode 552: Success! Reward: -1.40, Steps: 21\n",
      "Episode 553: Success! Reward: 10.00, Steps: 1\n",
      "Episode 554: Success! Reward: -3.40, Steps: 21\n",
      "Episode 555: Success! Reward: -3.60, Steps: 21\n",
      "Episode 556: Success! Reward: -2.80, Steps: 21\n",
      "Episode 557: Success! Reward: 7.80, Steps: 19\n",
      "Episode 558: Success! Reward: 8.60, Steps: 13\n",
      "Episode 559: Success! Reward: -3.00, Steps: 21\n",
      "Episode 560: Success! Reward: 9.20, Steps: 15\n",
      "Episode 561: Success! Reward: -1.40, Steps: 21\n",
      "Episode 562: Success! Reward: 8.80, Steps: 10\n",
      "Episode 563: Success! Reward: -2.60, Steps: 21\n",
      "Episode 564: Success! Reward: 10.40, Steps: 2\n",
      "Episode 565: Success! Reward: 9.80, Steps: 3\n",
      "Target network updated at step 6000\n",
      "Episode 566: Success! Reward: -2.40, Steps: 21\n",
      "Episode 567: Success! Reward: 9.40, Steps: 6\n",
      "Episode 568: Success! Reward: -2.40, Steps: 21\n",
      "Episode 569: Success! Reward: 10.20, Steps: 12\n",
      "Episode 570: Success! Reward: -3.40, Steps: 21\n",
      "Episode 571: Success! Reward: -2.40, Steps: 21\n",
      "Episode 572: Success! Reward: 8.20, Steps: 13\n",
      "Episode 573: Success! Reward: 8.80, Steps: 19\n",
      "Episode 574: Success! Reward: 9.00, Steps: 13\n",
      "Episode 575: Success! Reward: 9.20, Steps: 5\n",
      "Episode 576: Success! Reward: 10.40, Steps: 2\n",
      "Episode 577: Success! Reward: 10.00, Steps: 1\n",
      "Episode 578: Success! Reward: 9.00, Steps: 14\n",
      "Episode 579: Success! Reward: 9.60, Steps: 14\n",
      "Episode 580: Success! Reward: 9.80, Steps: 7\n",
      "Episode 581: Success! Reward: 8.20, Steps: 16\n",
      "Episode 582: Success! Reward: 9.80, Steps: 10\n",
      "Episode 583: Success! Reward: -1.40, Steps: 21\n",
      "Episode 584: Success! Reward: 10.40, Steps: 2\n",
      "Episode 585: Success! Reward: -2.60, Steps: 21\n",
      "Episode 586: Success! Reward: 9.40, Steps: 8\n",
      "Episode 587: Success! Reward: 9.40, Steps: 20\n",
      "Episode 588: Success! Reward: 10.40, Steps: 6\n",
      "Episode 589: Success! Reward: 8.40, Steps: 18\n",
      "Episode 590: Success! Reward: -1.00, Steps: 21\n",
      "Episode 591: Success! Reward: 9.60, Steps: 7\n",
      "Episode 592: Success! Reward: 9.60, Steps: 4\n",
      "Episode 593: Success! Reward: 10.20, Steps: 3\n",
      "Episode 594: Success! Reward: 9.00, Steps: 12\n",
      "Episode 595: Success! Reward: 9.60, Steps: 11\n",
      "Episode 596: Success! Reward: 9.60, Steps: 9\n",
      "Episode 597: Success! Reward: 10.00, Steps: 6\n",
      "Episode 598: Success! Reward: 9.80, Steps: 9\n",
      "Episode 599: Success! Reward: -3.00, Steps: 21\n",
      "Episode 600/24000 (Stage 2, Ep 120/720)\n",
      "Grid: 6x6, Obstacles: 4, Pattern: random\n",
      "Epsilon: 0.8946, Memory: 6409/50000\n",
      "Episode 600: Success! Reward: -2.60, Steps: 21\n",
      "\n",
      "Running evaluation...\n",
      "Evaluating on grid 10x10, 5 obstacles, random pattern\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 446\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m success_rate, avg_reward\n\u001b[0;32m    445\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24000\u001b[39m\n\u001b[1;32m--> 446\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_compound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m model \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# Save final model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 248\u001b[0m, in \u001b[0;36mtrain_compound\u001b[1;34m(epochs, batch_size, memory_size, render_interval)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode_count \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m episode_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 248\u001b[0m     eval_success_rate, eval_avg_reward \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes_per_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_episodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m     success_rates\u001b[38;5;241m.\u001b[39mappend(eval_success_rate)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation - Success rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_success_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Avg reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_avg_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 417\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, env_configs, episodes_per_env)\u001b[0m\n\u001b[0;32m    414\u001b[0m steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# Get action from model - no exploration during evaluation\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(q_values)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Take action\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mBalancedDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Only use dropout during training\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Enhanced Compound Training Function\n",
    "def train_compound(epochs=24000, batch_size=64, memory_size=150000, render_interval=500):\n",
    "    # Initialize metrics tracking\n",
    "    losses = []\n",
    "    all_rewards = []\n",
    "    avg_rewards = []\n",
    "    success_rates = []\n",
    "    best_eval_score = float('-inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Create replay memory\n",
    "    replay = deque(maxlen=memory_size)\n",
    "    \n",
    "    # Create model checkpoint directory\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    # Initialize epsilon for exploration\n",
    "    epsilon = 1.0\n",
    "    epsilon_min = 0.05\n",
    "    epsilon_decay_rate = 0.99995  # Slower decay for more exploration\n",
    "    \n",
    "    # Enhanced curriculum with more intermediate stages and higher obstacle density\n",
    "    curriculum = [\n",
    "        # Stage 1: Very small grids (5x5) with minimal obstacles\n",
    "        {'episodes': int(epochs * 0.02), 'grid_sizes': [5], 'obstacles': (1, 3), 'patterns': ['random'], \n",
    "        'max_steps_factor': 3.5, 'epsilon_min': 0.2},\n",
    "        \n",
    "        # Stage 2: Small grids (6x6) with increasing obstacles\n",
    "        {'episodes': int(epochs * 0.03), 'grid_sizes': [6], 'obstacles': (2, 4), 'patterns': ['random'], \n",
    "        'max_steps_factor': 3.5, 'epsilon_min': 0.18},\n",
    "        \n",
    "        # Stage 3: Small grids (7x7, 8x8) with more obstacles\n",
    "        {'episodes': int(epochs * 0.04), 'grid_sizes': [7, 8], 'obstacles': (3, 6), 'patterns': ['random'], \n",
    "        'max_steps_factor': 3.2, 'epsilon_min': 0.16},\n",
    "        \n",
    "        # Stage 4: Early medium grids (9x9, 10x10) with moderate obstacles\n",
    "        {'episodes': int(epochs * 0.05), 'grid_sizes': [9, 10], 'obstacles': (4, 8), 'patterns': ['random'], \n",
    "        'max_steps_factor': 3.0, 'epsilon_min': 0.15},\n",
    "        \n",
    "        # Stage 5: Medium grids (11x11, 12x12) with clusters\n",
    "        {'episodes': int(epochs * 0.05), 'grid_sizes': [11, 12], 'obstacles': (5, 10), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.8, 'epsilon_min': 0.14},\n",
    "        \n",
    "        # Stage 6: Larger medium grids (13x13, 14x14) with more obstacles\n",
    "        {'episodes': int(epochs * 0.06), 'grid_sizes': [13, 14], 'obstacles': (8, 14), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.8, 'epsilon_min': 0.13},\n",
    "        \n",
    "        # Stage 7: Medium-large grids (15x15, 16x16) with substantial obstacles \n",
    "        {'episodes': int(epochs * 0.07), 'grid_sizes': [15, 16], 'obstacles': (10, 15), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.6, 'epsilon_min': 0.12},\n",
    "        \n",
    "        # Stage 8: Large medium grids (17x17, 18x18) introducing walls pattern\n",
    "        {'episodes': int(epochs * 0.07), 'grid_sizes': [17, 18], 'obstacles': (12, 16), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.6, 'epsilon_min': 0.11},\n",
    "        \n",
    "        # Stage 9: First large grids (19x19, 20x20) with challenging obstacles\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [19, 20], 'obstacles': (15, 18), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.5, 'epsilon_min': 0.10},\n",
    "        \n",
    "        # Stage 10: Growing large grids (22x22, 24x24) with dense obstacles\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [22, 24], 'obstacles': (18, 20), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.4, 'epsilon_min': 0.09},\n",
    "        \n",
    "        # Stage 11: Large grids (25x25, 27x27) with very high obstacle count\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [25, 27], 'obstacles': (21, 24), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.3, 'epsilon_min': 0.08},\n",
    "        \n",
    "        # Stage 12: Very large grids (30x30) with maze-like obstacles\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [30], 'obstacles': (24, 30), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.2, 'epsilon_min': 0.07},\n",
    "        \n",
    "        # Stage 13: Larger grids (33x33, 35x35) with high obstacle density\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [33, 35], 'obstacles': (25, 35), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.1, 'epsilon_min': 0.06},\n",
    "        \n",
    "        # Stage 14: Extremely large grids (38x38) with extreme obstacles\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [38], 'obstacles': (30, 40), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.0, 'epsilon_min': 0.055},\n",
    "        \n",
    "        # Stage 15: Maximum challenge (40x40) with highest obstacle density\n",
    "        {'episodes': int(epochs * 0.13), 'grid_sizes': [40], 'obstacles': (20, 50), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.0, 'epsilon_min': 0.05}\n",
    "    ]\n",
    "    \n",
    "    # Setup for periodic evaluation\n",
    "    eval_interval = 200  # Evaluate model every 200 episodes\n",
    "    eval_episodes = 20   # Number of episodes to use for evaluation\n",
    "    \n",
    "    # Validation environments for consistent evaluation\n",
    "    validation_envs = [\n",
    "        # Simple validation environments\n",
    "        (10, 5, 'random'),   # (grid_size, obstacles, pattern)\n",
    "        (15, 10, 'random'),\n",
    "        (20, 15, 'clusters'),\n",
    "        (30, 20, 'walls'),\n",
    "        (40, 30, 'random')\n",
    "    ]\n",
    "\n",
    "    # Define sync frequency for target network updates (steps)\n",
    "    sync_freq = 1000\n",
    "    \n",
    "    # Global step counter\n",
    "    global_step = 0\n",
    "    episode_count = 0\n",
    "    \n",
    "    print(\"Starting compound training with curriculum learning...\")\n",
    "    \n",
    "    # Loop through curriculum stages\n",
    "    for stage_idx, stage in enumerate(curriculum):\n",
    "        print(f\"\\n===== Starting Stage {stage_idx + 1}/{len(curriculum)} =====\")\n",
    "        print(f\"Grid sizes: {stage['grid_sizes']}\")\n",
    "        print(f\"Obstacles: {stage['obstacles']}\")\n",
    "        print(f\"Patterns: {stage['patterns']}\")\n",
    "        print(f\"Episodes: {stage['episodes']}\")\n",
    "        \n",
    "        # Update epsilon min for this stage\n",
    "        stage_epsilon_min = stage['epsilon_min']\n",
    "        \n",
    "        # Reset epsilon for new stage if needed (optional - keep this line if you want epsilon reset per stage)\n",
    "        epsilon = max(1.0 - stage_idx * 0.1, 0.5)  # Start with less exploration in later stages\n",
    "        \n",
    "        # Track episodes in this stage\n",
    "        stage_episodes = 0\n",
    "        \n",
    "        # Continue until we've completed the designated episodes for this stage\n",
    "        while stage_episodes < stage['episodes'] and episode_count < epochs:\n",
    "            # Select random parameters for this episode\n",
    "            grid_size = random.choice(stage['grid_sizes'])\n",
    "            num_obstacles = random.randint(stage['obstacles'][0], stage['obstacles'][1])\n",
    "            pattern = random.choice(stage['patterns'])\n",
    "            episode_seed = episode_count + random.randint(10000, 50000)\n",
    "            \n",
    "            # Create environment for this episode\n",
    "            max_steps = int(grid_size * stage['max_steps_factor'])  # Scale max steps with grid size\n",
    "            game = Gridworld(size=grid_size, mode=pattern, num_obstacles=num_obstacles, max_steps=max_steps, random_seed=episode_seed)\n",
    "            \n",
    "            # Initialize state\n",
    "            state = game.reset()\n",
    "            state = torch.from_numpy(state).float().unsqueeze(0)  # Add batch dimension\n",
    "            \n",
    "            done = False\n",
    "            steps = 0\n",
    "            episode_reward = 0\n",
    "            success = False\n",
    "            \n",
    "            # Display info periodically\n",
    "            should_render = (episode_count % render_interval == 0)\n",
    "            \n",
    "            if episode_count % 50 == 0:\n",
    "                print(f\"Episode {episode_count}/{epochs} (Stage {stage_idx+1}, Ep {stage_episodes}/{stage['episodes']})\")\n",
    "                print(f\"Grid: {grid_size}x{grid_size}, Obstacles: {num_obstacles}, Pattern: {pattern}\")\n",
    "                print(f\"Epsilon: {epsilon:.4f}, Memory: {len(replay)}/{memory_size}\")\n",
    "            \n",
    "            # Run episode\n",
    "            while not done and steps < max_steps:\n",
    "                steps += 1\n",
    "                global_step += 1\n",
    "                \n",
    "                # Epislon-greedy action selection\n",
    "                if random.random() < epsilon:\n",
    "                    action = random.randint(0, 3)  # Random action\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        q_values = model(state)\n",
    "                        action = torch.argmax(q_values).item()  # Greedy action\n",
    "                \n",
    "                # Take action in environment\n",
    "                next_state, reward, done, info = game.step(action)\n",
    "                next_state = torch.from_numpy(next_state).float().unsqueeze(0)\n",
    "                \n",
    "                # Record success if goal reached\n",
    "                if reward > 0:  # Assuming positive reward means goal reached\n",
    "                    success = True\n",
    "                \n",
    "                # Store in replay memory\n",
    "                replay.append((state, action, reward, next_state, done))\n",
    "                \n",
    "                # Update state and accumulate reward\n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "                \n",
    "                # Render if needed\n",
    "                if should_render and steps % 5 == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    game.render()\n",
    "                    plt.title(f\"Stage {stage_idx+1}, Episode {episode_count}, Step {steps}, Reward: {episode_reward:.2f}\")\n",
    "                    plt.pause(0.1)\n",
    "                \n",
    "                # Training step (if we have enough samples)\n",
    "                if len(replay) >= batch_size:\n",
    "                    # Sample mini-batch\n",
    "                    minibatch = random.sample(replay, batch_size)\n",
    "                    \n",
    "                    # Extract batch components\n",
    "                    state_batch = torch.cat([s1 for (s1, _, _, _, _) in minibatch])\n",
    "                    action_batch = torch.tensor([a for (_, a, _, _, _) in minibatch], dtype=torch.long)\n",
    "                    reward_batch = torch.tensor([r for (_, _, r, _, _) in minibatch], dtype=torch.float)\n",
    "                    next_state_batch = torch.cat([s2 for (_, _, _, s2, _) in minibatch])\n",
    "                    done_batch = torch.tensor([d for (_, _, _, _, d) in minibatch], dtype=torch.float)\n",
    "                    \n",
    "                    # Compute current Q values\n",
    "                    current_Q = model(state_batch).gather(1, action_batch.unsqueeze(1)).squeeze(1)\n",
    "                    \n",
    "                    # Double DQN: Use online network to select actions, target network to evaluate\n",
    "                    with torch.no_grad():\n",
    "                        # Find best actions using online model\n",
    "                        best_actions = model(next_state_batch).max(1)[1].unsqueeze(1)\n",
    "                        # Evaluate those actions using target model\n",
    "                        next_Q = model2(next_state_batch).gather(1, best_actions).squeeze(1)\n",
    "                        # Compute target Q values\n",
    "                        target_Q = reward_batch + gamma * next_Q * (1 - done_batch)\n",
    "                    \n",
    "                    # Compute loss and update model\n",
    "                    loss = loss_fn(current_Q, target_Q)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # Gradient clipping to prevent exploding gradients\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # Store loss\n",
    "                    losses.append(loss.item())\n",
    "                \n",
    "                # Update target network\n",
    "                if global_step % sync_freq == 0:\n",
    "                    model2.load_state_dict(model.state_dict())\n",
    "                    print(f\"Target network updated at step {global_step}\")\n",
    "            \n",
    "            # Episode completed\n",
    "            all_rewards.append(episode_reward)\n",
    "            \n",
    "            # Calculate running average reward\n",
    "            window_size = min(100, len(all_rewards))\n",
    "            avg_reward = sum(all_rewards[-window_size:]) / window_size\n",
    "            avg_rewards.append(avg_reward)\n",
    "            \n",
    "            # Print episode results\n",
    "            if success:\n",
    "                print(f\"Episode {episode_count}: Success! Reward: {episode_reward:.2f}, Steps: {steps}\")\n",
    "            elif episode_count % 50 == 0:\n",
    "                print(f\"Episode {episode_count}: Failed. Reward: {episode_reward:.2f}, Steps: {steps}\")\n",
    "            \n",
    "            # Evaluate periodically\n",
    "            if episode_count % eval_interval == 0 and episode_count > 0:\n",
    "                print(\"\\nRunning evaluation...\")\n",
    "                eval_success_rate, eval_avg_reward = evaluate_model(model, validation_envs, episodes_per_env=eval_episodes)\n",
    "                success_rates.append(eval_success_rate)\n",
    "                \n",
    "                print(f\"Evaluation - Success rate: {eval_success_rate:.2f}, Avg reward: {eval_avg_reward:.2f}\")\n",
    "                \n",
    "                # Save best model\n",
    "                eval_score = eval_success_rate * 10 + eval_avg_reward  # Combined metric\n",
    "                if eval_score > best_eval_score:\n",
    "                    best_eval_score = eval_score\n",
    "                    best_model_state = model.state_dict().copy()\n",
    "                    print(f\"New best model with eval score {eval_score:.2f}!\")\n",
    "                    \n",
    "                    # Save best model\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'epsilon': epsilon,\n",
    "                        'episode': episode_count,\n",
    "                        'eval_score': eval_score,\n",
    "                        'success_rate': eval_success_rate,\n",
    "                        'avg_reward': eval_avg_reward,\n",
    "                    }, 'models/dqn_best.pth')\n",
    "            \n",
    "            # Checkpoint model periodically\n",
    "            if episode_count % 500 == 0 and episode_count > 0:\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'epsilon': epsilon,\n",
    "                    'episode': episode_count,\n",
    "                    'stage': stage_idx,\n",
    "                    'all_rewards': all_rewards,\n",
    "                    'avg_rewards': avg_rewards,\n",
    "                    'losses': losses,\n",
    "                }, f'models/dqn_checkpoint_ep{episode_count}.pth')\n",
    "                print(f\"Checkpoint saved at episode {episode_count}\")\n",
    "            \n",
    "            # Decay epsilon - but respect the minimum for this stage\n",
    "            epsilon = max(stage_epsilon_min, epsilon * epsilon_decay_rate)\n",
    "            \n",
    "            # Increment counters\n",
    "            episode_count += 1\n",
    "            stage_episodes += 1\n",
    "        \n",
    "        # End of stage - evaluate and save stage model\n",
    "        print(f\"\\n===== Completed Stage {stage_idx + 1}/{len(curriculum)} =====\")\n",
    "        stage_eval_success, stage_eval_reward = evaluate_model(model, validation_envs, episodes_per_env=eval_episodes)\n",
    "        \n",
    "        print(f\"Stage {stage_idx+1} Evaluation - Success rate: {stage_eval_success:.2f}, Avg reward: {stage_eval_reward:.2f}\")\n",
    "        \n",
    "        # Save stage model\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epsilon': epsilon,\n",
    "            'episode': episode_count,\n",
    "            'stage': stage_idx,\n",
    "            'success_rate': stage_eval_success,\n",
    "            'avg_reward': stage_eval_reward,\n",
    "        }, f'models/dqn_stage{stage_idx+1}.pth')\n",
    "    \n",
    "    # Training complete - final evaluation with best model\n",
    "    print(\"\\n===== Training Complete =====\")\n",
    "    \n",
    "    # Load best model for final evaluation\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model for final evaluation\")\n",
    "    \n",
    "    # Comprehensive final evaluation\n",
    "    print(\"\\nRunning final evaluation...\")\n",
    "    final_success_rate, final_avg_reward = evaluate_model(model, validation_envs, episodes_per_env=50)  # More episodes for final eval\n",
    "    \n",
    "    print(f\"Final Evaluation - Success rate: {final_success_rate:.2f}, Avg reward: {final_avg_reward:.2f}\")\n",
    "    \n",
    "    # Plot training metrics\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(all_rewards)\n",
    "    plt.title('Episode Rewards')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(avg_rewards)\n",
    "    plt.title('Average Reward (100 episodes)')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Reward')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(losses[-10000:])  # Plot last 10000 losses to see recent trends\n",
    "    plt.title('Training Loss (last 10000 updates)')\n",
    "    plt.xlabel('Update Step')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    if success_rates:\n",
    "        plt.subplot(2, 2, 4)\n",
    "        # Generate x values that match exactly with the length of success_rates\n",
    "        eval_points = np.arange(eval_interval, eval_interval * (len(success_rates) + 1), eval_interval)[:len(success_rates)]\n",
    "        plt.plot(eval_points, success_rates)\n",
    "        plt.title('Evaluation Success Rate')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Success Rate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('models/training_curves.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epsilon': epsilon,\n",
    "        'episode': episode_count,\n",
    "        'final_success_rate': final_success_rate,\n",
    "        'final_avg_reward': final_avg_reward,\n",
    "    }, 'models/dqn_final.pth')\n",
    "    \n",
    "    # Return relevant data for analysis\n",
    "    return {\n",
    "        'model': model,\n",
    "        'rewards': all_rewards,\n",
    "        'avg_rewards': avg_rewards,\n",
    "        'losses': losses,\n",
    "        'success_rates': success_rates,\n",
    "        'final_success_rate': final_success_rate,\n",
    "        'final_avg_reward': final_avg_reward,\n",
    "        'best_eval_score': best_eval_score\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, env_configs, episodes_per_env=10):\n",
    "    \"\"\"\n",
    "    Evaluate model on multiple environment configurations\n",
    "    \n",
    "    Args:\n",
    "        model: The DQN model to evaluate\n",
    "        env_configs: List of tuples (grid_size, num_obstacles, pattern)\n",
    "        episodes_per_env: Number of episodes to run for each environment config\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (success_rate, average_reward)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    success_count = 0\n",
    "    total_rewards = []\n",
    "    total_episodes = len(env_configs) * episodes_per_env\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for grid_size, num_obstacles, pattern in env_configs:\n",
    "            print(f\"Evaluating on grid {grid_size}x{grid_size}, {num_obstacles} obstacles, {pattern} pattern\")\n",
    "            \n",
    "            for ep in range(episodes_per_env):\n",
    "                # Create environment\n",
    "                max_steps = grid_size * 2\n",
    "                game = Gridworld(size=grid_size, mode=pattern, num_obstacles=num_obstacles, max_steps=max_steps)\n",
    "                \n",
    "                state = game.reset()\n",
    "                state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "                \n",
    "                done = False\n",
    "                steps = 0\n",
    "                episode_reward = 0\n",
    "                success = False\n",
    "                \n",
    "                while not done and steps < max_steps:\n",
    "                    steps += 1\n",
    "                    \n",
    "                    # Get action from model - no exploration during evaluation\n",
    "                    q_values = model(state)\n",
    "                    action = torch.argmax(q_values).item()\n",
    "                    \n",
    "                    # Take action\n",
    "                    next_state, reward, done, info = game.step(action)\n",
    "                    next_state = torch.from_numpy(next_state).float().unsqueeze(0)\n",
    "                    \n",
    "                    # Update state and reward\n",
    "                    state = next_state\n",
    "                    episode_reward += reward\n",
    "                    \n",
    "                    # Check for success\n",
    "                    if reward > 0:  # Positive reward means goal reached\n",
    "                        success = True\n",
    "                        break\n",
    "                \n",
    "                # Record results\n",
    "                if success:\n",
    "                    success_count += 1\n",
    "                total_rewards.append(episode_reward)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    success_rate = success_count / total_episodes\n",
    "    avg_reward = sum(total_rewards) / len(total_rewards)\n",
    "    \n",
    "    model.train()  # Set model back to training mode\n",
    "    return success_rate, avg_reward\n",
    "\n",
    "epochs = 24000\n",
    "results = train_compound(epochs=epochs, batch_size=64, memory_size=50000, render_interval=500)\n",
    "model = results['model']\n",
    "\n",
    "# Save final model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epsilon': epsilon,\n",
    "    'episode': epochs,\n",
    "}, 'models/dqn_final.pth')\n",
    "print(\"Training completed. Final model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TEST RESULTS =====\n",
      "Agent Type: DQN\n",
      "Random Seed: 1\n",
      "Goal Reached: Yes\n",
      "Total Timesteps: 16\n",
      "Total Distance: 16\n",
      "Unique Locations: 17\n",
      "Revisited Locations: 0\n",
      "Shannon Entropy (states): 0.956\n",
      "Grid Dimensions: 40x40\n",
      "\n",
      "Action distribution:\n",
      "  UP: 11 times (68.8%)\n",
      "  RIGHT: 5 times (31.2%)\n",
      "\n",
      "Most visited states:\n",
      "  (25, 26): 1 visits\n",
      "  (25, 25): 1 visits\n",
      "  (25, 24): 1 visits\n",
      "  (25, 23): 1 visits\n",
      "  (25, 22): 1 visits\n",
      "Episode 2:  SUCCESS - Seed: 2, Timesteps: 39, Distance: 39, Shannon Entropy: 0.95\n",
      "Episode 3:  SUCCESS - Seed: 3, Timesteps: 51, Distance: 51, Shannon Entropy: 0.95\n",
      "Episode 4:  SUCCESS - Seed: 4, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 5:  SUCCESS - Seed: 5, Timesteps: 21, Distance: 21, Shannon Entropy: 0.96\n",
      "Episode 6:  FAILED - Seed: 6, Timesteps: 1000, Distance: 6, Shannon Entropy: 1.80\n",
      "Episode 7:  FAILED - Seed: 7, Timesteps: 1000, Distance: 9, Shannon Entropy: 1.79\n",
      "Episode 8:  FAILED - Seed: 8, Timesteps: 1000, Distance: 29, Shannon Entropy: 1.72\n",
      "Episode 9:  SUCCESS - Seed: 9, Timesteps: 47, Distance: 47, Shannon Entropy: 0.95\n",
      "Episode 10:  SUCCESS - Seed: 10, Timesteps: 9, Distance: 9, Shannon Entropy: 0.96\n",
      "Episode 11:  SUCCESS - Seed: 11, Timesteps: 25, Distance: 25, Shannon Entropy: 0.95\n",
      "Episode 12:  FAILED - Seed: 12, Timesteps: 1000, Distance: 3, Shannon Entropy: 1.82\n",
      "Episode 13:  SUCCESS - Seed: 13, Timesteps: 29, Distance: 29, Shannon Entropy: 0.95\n",
      "Episode 14:  FAILED - Seed: 14, Timesteps: 1000, Distance: 24, Shannon Entropy: 1.73\n",
      "Episode 15:  FAILED - Seed: 15, Timesteps: 1000, Distance: 2, Shannon Entropy: 1.82\n",
      "Episode 16:  FAILED - Seed: 16, Timesteps: 1000, Distance: 9, Shannon Entropy: 1.79\n",
      "Episode 17:  FAILED - Seed: 17, Timesteps: 1000, Distance: 25, Shannon Entropy: 1.73\n",
      "Episode 18:  SUCCESS - Seed: 18, Timesteps: 5, Distance: 5, Shannon Entropy: 0.96\n",
      "Episode 19:  SUCCESS - Seed: 19, Timesteps: 9, Distance: 9, Shannon Entropy: 0.96\n",
      "Episode 20:  SUCCESS - Seed: 20, Timesteps: 27, Distance: 27, Shannon Entropy: 0.95\n",
      "Episode 21:  SUCCESS - Seed: 21, Timesteps: 23, Distance: 23, Shannon Entropy: 0.95\n",
      "Episode 22:  FAILED - Seed: 22, Timesteps: 1000, Distance: 3, Shannon Entropy: 1.82\n",
      "Episode 23:  SUCCESS - Seed: 23, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.46\n",
      "Episode 24:  FAILED - Seed: 24, Timesteps: 1000, Distance: 3, Shannon Entropy: 1.82\n",
      "Episode 25:  FAILED - Seed: 25, Timesteps: 1000, Distance: 2, Shannon Entropy: 1.82\n",
      "Episode 26:  FAILED - Seed: 26, Timesteps: 1000, Distance: 9, Shannon Entropy: 1.79\n",
      "Episode 27:  SUCCESS - Seed: 27, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 28:  SUCCESS - Seed: 28, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 29:  FAILED - Seed: 29, Timesteps: 1000, Distance: 22, Shannon Entropy: 1.74\n",
      "Episode 30:  SUCCESS - Seed: 30, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 31:  SUCCESS - Seed: 31, Timesteps: 35, Distance: 35, Shannon Entropy: 0.95\n",
      "Episode 32:  SUCCESS - Seed: 32, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 33:  SUCCESS - Seed: 33, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 34:  SUCCESS - Seed: 34, Timesteps: 13, Distance: 13, Shannon Entropy: 0.96\n",
      "Episode 35:  SUCCESS - Seed: 35, Timesteps: 37, Distance: 37, Shannon Entropy: 0.95\n",
      "Episode 36:  SUCCESS - Seed: 36, Timesteps: 24, Distance: 24, Shannon Entropy: 0.95\n",
      "Episode 37:  SUCCESS - Seed: 37, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 38:  SUCCESS - Seed: 38, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 39:  SUCCESS - Seed: 39, Timesteps: 45, Distance: 45, Shannon Entropy: 0.95\n",
      "Episode 40:  SUCCESS - Seed: 40, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 41:  SUCCESS - Seed: 41, Timesteps: 8, Distance: 8, Shannon Entropy: 0.96\n",
      "Episode 42:  SUCCESS - Seed: 42, Timesteps: 2, Distance: 2, Shannon Entropy: 0.96\n",
      "Episode 43:  SUCCESS - Seed: 43, Timesteps: 28, Distance: 28, Shannon Entropy: 0.95\n",
      "Episode 44:  SUCCESS - Seed: 44, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.46\n",
      "Episode 45:  SUCCESS - Seed: 45, Timesteps: 40, Distance: 40, Shannon Entropy: 0.95\n",
      "Episode 46:  SUCCESS - Seed: 46, Timesteps: 43, Distance: 43, Shannon Entropy: 0.95\n",
      "Episode 47:  FAILED - Seed: 47, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.47\n",
      "Episode 48:  SUCCESS - Seed: 48, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 49:  FAILED - Seed: 49, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.45\n",
      "Episode 50:  SUCCESS - Seed: 50, Timesteps: 14, Distance: 14, Shannon Entropy: 0.96\n",
      "Episode 51:  SUCCESS - Seed: 51, Timesteps: 23, Distance: 23, Shannon Entropy: 0.95\n",
      "Episode 52:  SUCCESS - Seed: 52, Timesteps: 40, Distance: 40, Shannon Entropy: 0.95\n",
      "Episode 53:  FAILED - Seed: 53, Timesteps: 1000, Distance: 14, Shannon Entropy: 1.77\n",
      "Episode 54:  SUCCESS - Seed: 54, Timesteps: 42, Distance: 42, Shannon Entropy: 0.95\n",
      "Episode 55:  SUCCESS - Seed: 55, Timesteps: 12, Distance: 12, Shannon Entropy: 0.96\n",
      "Episode 56:  FAILED - Seed: 56, Timesteps: 1000, Distance: 25, Shannon Entropy: 1.73\n",
      "Episode 57:  SUCCESS - Seed: 57, Timesteps: 6, Distance: 6, Shannon Entropy: 0.96\n",
      "Episode 58:  FAILED - Seed: 58, Timesteps: 1000, Distance: 19, Shannon Entropy: 1.75\n",
      "Episode 59:  SUCCESS - Seed: 59, Timesteps: 39, Distance: 39, Shannon Entropy: 0.95\n",
      "Episode 60:  SUCCESS - Seed: 60, Timesteps: 24, Distance: 24, Shannon Entropy: 0.95\n",
      "Episode 61:  SUCCESS - Seed: 61, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 62:  FAILED - Seed: 62, Timesteps: 1000, Distance: 3, Shannon Entropy: 1.82\n",
      "Episode 63:  SUCCESS - Seed: 63, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 64:  SUCCESS - Seed: 64, Timesteps: 47, Distance: 47, Shannon Entropy: 0.95\n",
      "Episode 65:  FAILED - Seed: 65, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.34\n",
      "Episode 66:  SUCCESS - Seed: 66, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 67:  SUCCESS - Seed: 67, Timesteps: 15, Distance: 15, Shannon Entropy: 0.96\n",
      "Episode 68:  SUCCESS - Seed: 68, Timesteps: 26, Distance: 26, Shannon Entropy: 0.95\n",
      "Episode 69:  SUCCESS - Seed: 69, Timesteps: 32, Distance: 32, Shannon Entropy: 0.95\n",
      "Episode 70:  FAILED - Seed: 70, Timesteps: 1000, Distance: 2, Shannon Entropy: 1.82\n",
      "Episode 71:  SUCCESS - Seed: 71, Timesteps: 25, Distance: 25, Shannon Entropy: 0.95\n",
      "Episode 72:  SUCCESS - Seed: 72, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 73:  FAILED - Seed: 73, Timesteps: 1000, Distance: 29, Shannon Entropy: 1.72\n",
      "Episode 74:  FAILED - Seed: 74, Timesteps: 1000, Distance: 5, Shannon Entropy: 1.81\n",
      "Episode 75:  SUCCESS - Seed: 75, Timesteps: 15, Distance: 15, Shannon Entropy: 0.96\n",
      "Episode 76:  SUCCESS - Seed: 76, Timesteps: 15, Distance: 15, Shannon Entropy: 0.96\n",
      "Episode 77:  SUCCESS - Seed: 77, Timesteps: 21, Distance: 21, Shannon Entropy: 0.96\n",
      "Episode 78:  SUCCESS - Seed: 78, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 79:  SUCCESS - Seed: 79, Timesteps: 28, Distance: 28, Shannon Entropy: 0.95\n",
      "Episode 80:  FAILED - Seed: 80, Timesteps: 1000, Distance: 3, Shannon Entropy: 1.82\n",
      "Episode 81:  SUCCESS - Seed: 81, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 82:  FAILED - Seed: 82, Timesteps: 1000, Distance: 5, Shannon Entropy: 1.81\n",
      "Episode 83:  SUCCESS - Seed: 83, Timesteps: 17, Distance: 17, Shannon Entropy: 0.96\n",
      "Episode 84:  SUCCESS - Seed: 84, Timesteps: 25, Distance: 25, Shannon Entropy: 0.95\n",
      "Episode 85:  FAILED - Seed: 85, Timesteps: 1000, Distance: 41, Shannon Entropy: 1.68\n",
      "Episode 86:  SUCCESS - Seed: 86, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 87:  SUCCESS - Seed: 87, Timesteps: 14, Distance: 14, Shannon Entropy: 0.96\n",
      "Episode 88:  SUCCESS - Seed: 88, Timesteps: 14, Distance: 14, Shannon Entropy: 0.96\n",
      "Episode 89:  SUCCESS - Seed: 89, Timesteps: 37, Distance: 37, Shannon Entropy: 0.95\n",
      "Episode 90:  FAILED - Seed: 90, Timesteps: 1000, Distance: 25, Shannon Entropy: 1.73\n",
      "Episode 91:  SUCCESS - Seed: 91, Timesteps: 40, Distance: 40, Shannon Entropy: 0.95\n",
      "Episode 92:  SUCCESS - Seed: 92, Timesteps: 48, Distance: 48, Shannon Entropy: 0.95\n",
      "Episode 93:  SUCCESS - Seed: 93, Timesteps: 35, Distance: 35, Shannon Entropy: 0.95\n",
      "Episode 94:  SUCCESS - Seed: 94, Timesteps: 3, Distance: 3, Shannon Entropy: 0.96\n",
      "Episode 95:  SUCCESS - Seed: 95, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 96:  SUCCESS - Seed: 96, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.44\n",
      "Episode 97:  FAILED - Seed: 97, Timesteps: 1000, Distance: 50, Shannon Entropy: 1.65\n",
      "Episode 98:  SUCCESS - Seed: 98, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 99:  FAILED - Seed: 99, Timesteps: 1000, Distance: 8, Shannon Entropy: 1.79\n",
      "Episode 100:  SUCCESS - Seed: 100, Timesteps: 3, Distance: 3, Shannon Entropy: 0.96\n",
      "Episode 101:  SUCCESS - Seed: 101, Timesteps: 15, Distance: 15, Shannon Entropy: 0.96\n",
      "Episode 102:  SUCCESS - Seed: 102, Timesteps: 25, Distance: 25, Shannon Entropy: 0.95\n",
      "Episode 103:  SUCCESS - Seed: 103, Timesteps: 31, Distance: 31, Shannon Entropy: 0.95\n",
      "Episode 104:  SUCCESS - Seed: 104, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 105:  SUCCESS - Seed: 105, Timesteps: 36, Distance: 36, Shannon Entropy: 0.95\n",
      "Episode 106:  SUCCESS - Seed: 106, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 107:  FAILED - Seed: 107, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.46\n",
      "Episode 108:  SUCCESS - Seed: 108, Timesteps: 22, Distance: 22, Shannon Entropy: 0.95\n",
      "Episode 109:  SUCCESS - Seed: 109, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 110:  SUCCESS - Seed: 110, Timesteps: 21, Distance: 21, Shannon Entropy: 0.96\n",
      "Episode 111:  SUCCESS - Seed: 111, Timesteps: 18, Distance: 18, Shannon Entropy: 0.96\n",
      "Episode 112:  SUCCESS - Seed: 112, Timesteps: 6, Distance: 6, Shannon Entropy: 0.96\n",
      "Episode 113:  SUCCESS - Seed: 113, Timesteps: 44, Distance: 44, Shannon Entropy: 0.95\n",
      "Episode 114:  FAILED - Seed: 114, Timesteps: 1000, Distance: 5, Shannon Entropy: 1.81\n",
      "Episode 115:  SUCCESS - Seed: 115, Timesteps: 3, Distance: 3, Shannon Entropy: 0.96\n",
      "Episode 116:  SUCCESS - Seed: 116, Timesteps: 17, Distance: 17, Shannon Entropy: 0.96\n",
      "Episode 117:  SUCCESS - Seed: 117, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.47\n",
      "Episode 118:  FAILED - Seed: 118, Timesteps: 1000, Distance: 13, Shannon Entropy: 1.77\n",
      "Episode 119:  SUCCESS - Seed: 119, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.34\n",
      "Episode 120:  FAILED - Seed: 120, Timesteps: 1000, Distance: 15, Shannon Entropy: 1.76\n",
      "Episode 121:  SUCCESS - Seed: 121, Timesteps: 26, Distance: 26, Shannon Entropy: 0.95\n",
      "Episode 122:  FAILED - Seed: 122, Timesteps: 1000, Distance: 44, Shannon Entropy: 1.67\n",
      "Episode 123:  SUCCESS - Seed: 123, Timesteps: 28, Distance: 28, Shannon Entropy: 0.95\n",
      "Episode 124:  SUCCESS - Seed: 124, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 125:  SUCCESS - Seed: 125, Timesteps: 17, Distance: 17, Shannon Entropy: 0.96\n",
      "Episode 126:  SUCCESS - Seed: 126, Timesteps: 5, Distance: 5, Shannon Entropy: 0.96\n",
      "Episode 127:  SUCCESS - Seed: 127, Timesteps: 5, Distance: 5, Shannon Entropy: 0.96\n",
      "Episode 128:  FAILED - Seed: 128, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.46\n",
      "Episode 129:  SUCCESS - Seed: 129, Timesteps: 5, Distance: 5, Shannon Entropy: 0.96\n",
      "Episode 130:  SUCCESS - Seed: 130, Timesteps: 4, Distance: 4, Shannon Entropy: 0.96\n",
      "Episode 131:  SUCCESS - Seed: 131, Timesteps: 23, Distance: 23, Shannon Entropy: 0.95\n",
      "Episode 132:  FAILED - Seed: 132, Timesteps: 1000, Distance: 5, Shannon Entropy: 1.81\n",
      "Episode 133:  SUCCESS - Seed: 133, Timesteps: 18, Distance: 18, Shannon Entropy: 0.96\n",
      "Episode 134:  SUCCESS - Seed: 134, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 135:  FAILED - Seed: 135, Timesteps: 1000, Distance: 37, Shannon Entropy: 1.69\n",
      "Episode 136:  SUCCESS - Seed: 136, Timesteps: 35, Distance: 35, Shannon Entropy: 0.95\n",
      "Episode 137:  SUCCESS - Seed: 137, Timesteps: 26, Distance: 26, Shannon Entropy: 0.95\n",
      "Episode 138:  SUCCESS - Seed: 138, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 139:  SUCCESS - Seed: 139, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.46\n",
      "Episode 140:  FAILED - Seed: 140, Timesteps: 1000, Distance: 5, Shannon Entropy: 1.81\n",
      "Episode 141:  SUCCESS - Seed: 141, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.45\n",
      "Episode 142:  FAILED - Seed: 142, Timesteps: 1000, Distance: 1000, Shannon Entropy: 1.46\n",
      "Episode 143:  SUCCESS - Seed: 143, Timesteps: 27, Distance: 27, Shannon Entropy: 0.95\n",
      "Episode 144:  FAILED - Seed: 144, Timesteps: 1000, Distance: 20, Shannon Entropy: 1.75\n",
      "Episode 145:  FAILED - Seed: 145, Timesteps: 1000, Distance: 42, Shannon Entropy: 1.67\n",
      "Episode 146:  SUCCESS - Seed: 146, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 147:  SUCCESS - Seed: 147, Timesteps: 42, Distance: 42, Shannon Entropy: 0.95\n",
      "Episode 148:  SUCCESS - Seed: 148, Timesteps: 33, Distance: 33, Shannon Entropy: 0.95\n",
      "Episode 149:  SUCCESS - Seed: 149, Timesteps: 12, Distance: 12, Shannon Entropy: 0.96\n",
      "Episode 150:  SUCCESS - Seed: 150, Timesteps: 42, Distance: 42, Shannon Entropy: 0.95\n",
      "\n",
      "===== BATCH TEST RESULTS =====\n",
      "Success Rate: 0.73 (109/150)\n",
      "Average Timesteps: 334.81\n",
      "Average Distance: 105.22\n",
      "Average Shannon Entropy: 1.19\n",
      "Detailed results saved to results/results.csv\n",
      "\n",
      "Key metrics from saved data:\n",
      "Success rate: 0.73\n",
      "Avg Total Distance: 105.22\n",
      "Avg Unique Locations: 21.38\n",
      "Avg Shannon Entropy: 1.19\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Try to import the Gridworld environment\n",
    "try:\n",
    "    from Gridworld import Gridworld\n",
    "except ImportError:\n",
    "    try:\n",
    "        from New_RL.Gridworld import Gridworld\n",
    "    except ImportError:\n",
    "        print(\"Error: Couldn't import Gridworld. Please check your import paths.\")\n",
    "\n",
    "# Define DQN model architecture (simplified)\n",
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=29, output_dim=4):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def load_model(model_path, input_dim=29, output_dim=4, device='cpu'):\n",
    "    \"\"\"\n",
    "    Load a DQN model from a checkpoint file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the model with specified dimensions\n",
    "        model = DQN(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "        \n",
    "        # Load the checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # Extract model state from checkpoint\n",
    "        if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
    "            model_state = checkpoint[\"model_state_dict\"]\n",
    "            print(f\"Model checkpoint contains: {list(checkpoint.keys())}\")\n",
    "            if \"episode\" in checkpoint:\n",
    "                print(f\"Model was trained for {checkpoint['episode']} episodes\")\n",
    "        else:\n",
    "            model_state = checkpoint\n",
    "            print(\"Model state loaded directly\")\n",
    "        \n",
    "        # Load state dict into model\n",
    "        model.load_state_dict(model_state)\n",
    "        model.eval()  # Set to evaluation mode\n",
    "        \n",
    "        print(f\"Successfully loaded model from {model_path}\")\n",
    "        return model\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Model file not found at {model_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def balanced_exploration_metric(distribution, state_space_size, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Balanced exploration metric that penalizes both:\n",
    "    - Visiting too few states repeatedly (low entropy)\n",
    "    - Visiting too many different states (high dispersion)\n",
    "    \n",
    "    Returns the reciprocal of the score so LOWER values indicate BETTER performance.\n",
    "    \n",
    "    Parameters:\n",
    "    - distribution: Dictionary mapping states to visit counts\n",
    "    - state_space_size: Total number of possible states in the environment\n",
    "    - alpha: Balance parameter between entropy and state count (0-1)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # Calculate entropy component (rewards uniform exploration)\n",
    "    total_visits = sum(distribution.values())\n",
    "    entropy = 0\n",
    "    for count in distribution.values():\n",
    "        probability = count / total_visits\n",
    "        if probability > 0:\n",
    "            entropy -= probability * math.log2(probability)\n",
    "    \n",
    "    # Normalize entropy by max possible entropy (log2 of state count)\n",
    "    max_entropy = math.log2(len(distribution)) if distribution else 0\n",
    "    normalized_entropy = entropy / max_entropy if max_entropy > 0 else 0\n",
    "    \n",
    "    # Calculate state coverage penalty (penalizes visiting too many states)\n",
    "    coverage_ratio = len(distribution) / state_space_size\n",
    "    coverage_penalty = 1 - math.exp(-(coverage_ratio - 0.5)**2 / 0.1)\n",
    "    \n",
    "    # Combine metrics (higher raw_score is better)\n",
    "    raw_score = alpha * normalized_entropy - (1 - alpha) * coverage_penalty\n",
    "    \n",
    "    # Add a small epsilon to avoid division by zero or negative values\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    # Return reciprocal so lower values are better\n",
    "    # We add 1 to make all values positive\n",
    "    return 1 / (raw_score + 1 + epsilon)\n",
    "\n",
    "def test_model(model, random_seed=None, grid_size=40, max_steps=1000, render=True, pause_time=0.2):\n",
    "    \"\"\"\n",
    "    Test a DQN model on a Gridworld environment with requested metrics.\n",
    "    \"\"\"\n",
    "    # Create environment\n",
    "    env = Gridworld(\n",
    "        size=grid_size,\n",
    "        mode='random',\n",
    "        max_steps=max_steps,\n",
    "        random_seed=random_seed\n",
    "    )\n",
    "    \n",
    "    if random_seed is not None:\n",
    "        # Set random seed for reproducibility\n",
    "        env.random_seed = random_seed\n",
    "        random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    # Initialize state\n",
    "    state = env.reset()\n",
    "    \n",
    "    # Track metrics\n",
    "    total_timesteps = 0\n",
    "    total_reward = 0\n",
    "    path_history = [env.player_position]\n",
    "    actions_taken = []\n",
    "    \n",
    "    # Track state visits for entropy and location counts\n",
    "    state_visits = Counter()\n",
    "    state_visits[tuple(env.player_position)] = 1\n",
    "    \n",
    "    # Action names for display\n",
    "    action_names = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]\n",
    "    \n",
    "    # Print initial state\n",
    "    if render:\n",
    "        print(f\"\\nTesting on {grid_size}x{grid_size} grid (seed: {random_seed})\")\n",
    "        print(f\"Start: {env.player_position}, Goal: {env.goal_position}\")\n",
    "        \n",
    "        # Initial render\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        env.render()\n",
    "        plt.title(f\"Initial state - Agent at {env.player_position}, Goal at {env.goal_position}\")\n",
    "        plt.pause(pause_time)\n",
    "    \n",
    "    # Run episode\n",
    "    done = False\n",
    "    goal_reached = False\n",
    "    \n",
    "    while not done and total_timesteps < max_steps:\n",
    "        # Convert state to tensor\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        \n",
    "        # Get action from model\n",
    "        with torch.no_grad():\n",
    "            q_values = model(state_tensor)\n",
    "            action = torch.argmax(q_values).item()\n",
    "            actions_taken.append(action)\n",
    "            \n",
    "            # Get action name for display\n",
    "            action_name = action_names[action] if action < len(action_names) else f\"UNKNOWN({action})\"\n",
    "        \n",
    "        # Take action in environment\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Update metrics\n",
    "        total_timesteps += 1\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        \n",
    "        # Track path\n",
    "        path_history.append(env.player_position)\n",
    "        \n",
    "        # Track state visits (increment counter for this position)\n",
    "        state_visits[tuple(env.player_position)] += 1\n",
    "        \n",
    "        # Check for success\n",
    "        if reward > 0 and done:\n",
    "            goal_reached = True\n",
    "        \n",
    "        # Render if requested\n",
    "        if render and (total_timesteps % 3 == 0 or done):\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            env.render()\n",
    "            \n",
    "            # Draw path\n",
    "            path_x = [pos[1] for pos in path_history]\n",
    "            path_y = [pos[0] for pos in path_history]\n",
    "            plt.plot(path_x, path_y, '-', color='blue', alpha=0.7, linewidth=2)\n",
    "            plt.plot(path_x[-1], path_y[-1], 'o', color='blue', markersize=10)\n",
    "            \n",
    "            status = \"SUCCESS!\" if goal_reached else (\"FAILED!\" if done else f\"Step {total_timesteps}\")\n",
    "            plt.title(f\"Action: {action_name}, Reward: {total_reward:.1f}\\nStatus: {status}\")\n",
    "            plt.pause(pause_time)\n",
    "    \n",
    "    # Calculate total distance traveled\n",
    "    total_distance = 0\n",
    "    for i in range(1, len(path_history)):\n",
    "        total_distance += abs(path_history[i][0] - path_history[i-1][0]) + abs(path_history[i][1] - path_history[i-1][1])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    unique_locations = len(state_visits)\n",
    "    revisited_locations = sum(state_visits.values()) - unique_locations\n",
    "    \n",
    "    # Calculate Shannon entropy based on state visit distribution\n",
    "    shannon_entropy = balanced_exploration_metric(state_visits, state_space_size=1600, alpha=0.5)\n",
    "    \n",
    "    grid_dims = f\"{grid_size}x{grid_size}\"\n",
    "    \n",
    "    # Final status message\n",
    "    if render:\n",
    "        print(\"\\n===== TEST RESULTS =====\")\n",
    "        print(f\"Agent Type: DQN\")\n",
    "        print(f\"Random Seed: {random_seed}\")\n",
    "        print(f\"Goal Reached: {'Yes' if goal_reached else 'No'}\")\n",
    "        print(f\"Total Timesteps: {total_timesteps}\")\n",
    "        print(f\"Total Distance: {total_distance}\")\n",
    "        print(f\"Unique Locations: {unique_locations}\")\n",
    "        print(f\"Revisited Locations: {revisited_locations}\")\n",
    "        print(f\"Shannon Entropy (states): {shannon_entropy:.3f}\")\n",
    "        print(f\"Grid Dimensions: {grid_dims}\")\n",
    "        \n",
    "        # Show action distribution\n",
    "        print(\"\\nAction distribution:\")\n",
    "        for a in sorted(Counter(actions_taken).keys()):\n",
    "            name = action_names[a] if a < len(action_names) else f\"Action {a}\"\n",
    "            count = Counter(actions_taken)[a]\n",
    "            print(f\"  {name}: {count} times ({count/len(actions_taken):.1%})\")\n",
    "        \n",
    "        # Show most visited states\n",
    "        print(\"\\nMost visited states:\")\n",
    "        for state, count in state_visits.most_common(5):\n",
    "            print(f\"  {state}: {count} visits\")\n",
    "    \n",
    "    # Return metrics with the exact requested field names for CSV\n",
    "    return {\n",
    "        \"agent_type\": \"DQN\",\n",
    "        \"random_seed\": random_seed,\n",
    "        \"total_timesteps\": total_timesteps,\n",
    "        \"total_distance\": total_distance,\n",
    "        \"goal_reached\": 1 if goal_reached else 0,  # Use 1/0 for boolean in CSV\n",
    "        \"unique_locations\": unique_locations,\n",
    "        \"revisited_locations\": revisited_locations,\n",
    "        \"shannon_entropy\": shannon_entropy,  # Changed from action_entropy to shannon_entropy\n",
    "        \"grid_dims\": grid_dims\n",
    "    }\n",
    "\n",
    "def run_test_batch(model_path, num_episodes=10, seeds=None, render_first=True):\n",
    "    \"\"\"\n",
    "    Run a batch of test episodes and collect statistics.\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    # Generate seeds if not provided\n",
    "    if seeds is None:\n",
    "        seeds = [random.randint(1, 10000) for _ in range(num_episodes)]\n",
    "    elif len(seeds) < num_episodes:\n",
    "        seeds = seeds + [random.randint(1, 10000) for _ in range(num_episodes - len(seeds))]\n",
    "    \n",
    "    results = []\n",
    "    successes = 0\n",
    "    \n",
    "    print(f\"Running {num_episodes} test episodes...\")\n",
    "    for i in range(num_episodes):        \n",
    "        # Run test\n",
    "        result = test_model(\n",
    "            model=model,\n",
    "            random_seed=seeds[i],\n",
    "            render=render_first and i == 0\n",
    "        )\n",
    "        \n",
    "        results.append(result)\n",
    "        if result[\"goal_reached\"]:\n",
    "            successes += 1\n",
    "        \n",
    "        # Print brief result with metrics\n",
    "        if not (render_first and i == 0):\n",
    "            status = \" SUCCESS\" if result[\"goal_reached\"] else \" FAILED\"\n",
    "            print(f\"Episode {i+1}: {status} - Seed: {result['random_seed']}, \" +\n",
    "                  f\"Timesteps: {result['total_timesteps']}, \" + \n",
    "                  f\"Distance: {result['total_distance']}, \" +\n",
    "                  f\"Shannon Entropy: {result['shannon_entropy']:.2f}\")\n",
    "    \n",
    "    # Calculate aggregate statistics\n",
    "    success_rate = successes / num_episodes\n",
    "    avg_timesteps = sum(r[\"total_timesteps\"] for r in results) / num_episodes\n",
    "    avg_distance = sum(r[\"total_distance\"] for r in results) / num_episodes\n",
    "    avg_entropy = sum(r[\"shannon_entropy\"] for r in results) / num_episodes\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n===== BATCH TEST RESULTS =====\")\n",
    "    print(f\"Success Rate: {success_rate:.2f} ({successes}/{num_episodes})\")\n",
    "    print(f\"Average Timesteps: {avg_timesteps:.2f}\")\n",
    "    print(f\"Average Distance: {avg_distance:.2f}\")\n",
    "    print(f\"Average Shannon Entropy: {avg_entropy:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        \"success_rate\": success_rate,\n",
    "        \"successes\": successes,\n",
    "        \"episodes\": num_episodes,\n",
    "        \"avg_timesteps\": avg_timesteps,\n",
    "        \"avg_distance\": avg_distance,\n",
    "        \"avg_entropy\": avg_entropy,\n",
    "        \"seeds\": seeds[:num_episodes],\n",
    "        \"detailed_results\": results\n",
    "    }\n",
    "\n",
    "MODEL_PATH = 'models/dqn_final.pth'\n",
    "SEEDS = list(range(1, 151))  # Seeds 1-100\n",
    "\n",
    "# Run batch test\n",
    "batch_results = run_test_batch(\n",
    "    model_path=MODEL_PATH,\n",
    "    num_episodes=150,\n",
    "    seeds=SEEDS,\n",
    "    render_first=True\n",
    ")\n",
    "\n",
    "# Save results to CSV\n",
    "if batch_results:\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Extract detailed results\n",
    "    df = pd.DataFrame(batch_results[\"detailed_results\"])\n",
    "    \n",
    "    # Ensure all requested metrics are in the DataFrame\n",
    "    required_metrics = [\n",
    "        \"agent_type\", \"random_seed\", \"total_timesteps\", \"total_distance\", \n",
    "        \"goal_reached\", \"unique_locations\", \"revisited_locations\", \n",
    "        \"shannon_entropy\", \"grid_dims\"  # Changed from action_entropy to shannon_entropy\n",
    "    ]\n",
    "    \n",
    "    for metric in required_metrics:\n",
    "        if metric not in df.columns:\n",
    "            print(f\"Warning: Metric '{metric}' missing from results\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    csv_path = f\"results/results.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Detailed results saved to {csv_path}\")\n",
    "    \n",
    "    # Show key metrics from the saved data\n",
    "    print(\"\\nKey metrics from saved data:\")\n",
    "    print(f\"Success rate: {df['goal_reached'].mean():.2f}\")\n",
    "    print(f\"Avg Total Distance: {df['total_distance'].mean():.2f}\")\n",
    "    print(f\"Avg Unique Locations: {df['unique_locations'].mean():.2f}\")\n",
    "    print(f\"Avg Shannon Entropy: {df['shannon_entropy'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
