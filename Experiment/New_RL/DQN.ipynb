{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-learning for GridWorld - Complete code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from Gridworld import Gridworld\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_set = {\n",
    "    0: 'u',\n",
    "    1: 'd',\n",
    "    2: 'l',\n",
    "    3: 'r',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced DQN model - lighter regularization\n",
    "class BalancedDQN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=29, output_dim=4):\n",
    "        super(BalancedDQN, self).__init__()\n",
    "        # First layer with lighter dropout\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 128)\n",
    "        self.dropout1 = torch.nn.Dropout(0.1)  # Reduced dropout (10%)\n",
    "        \n",
    "        # Second layer with lighter dropout\n",
    "        self.fc2 = torch.nn.Linear(128, 128)\n",
    "        self.dropout2 = torch.nn.Dropout(0.1)  # Reduced dropout (10%)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc3 = torch.nn.Linear(128, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # No batch normalization, which can be destabilizing for RL\n",
    "        # Simple clean forward pass with minimal regularization\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        # Only use dropout during training\n",
    "        if self.training:\n",
    "            x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        if self.training:\n",
    "            x = self.dropout2(x)\n",
    "            \n",
    "        return self.fc3(x)\n",
    "    \n",
    "model = BalancedDQN(input_dim=29, output_dim=4)\n",
    "    \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "gamma = 0.9\n",
    "epsilon = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Target network to handle learning instability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Training with Experience Replay and Target Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main network and target network\n",
    "model2 = copy.deepcopy(model)  # Target network\n",
    "\n",
    "# Loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training hyperparameters\n",
    "gamma = 0.99      # Discount factor\n",
    "epsilon = 1.0     # Initial exploration rate\n",
    "epsilon_min = 0.1 # Minimum exploration rate\n",
    "epsilon_decay = 0.995  # Decay rate for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAAKqCAYAAAC0M9/AAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJj1JREFUeJzt3QuQ3eVZwOF3SSShkIRyBwnXFRAiIFcjl0KbghERaquIKCliHRWwNEVLxhGIAwZbRVQoZWoh3hBaFHBaASktQSwMEEQTKgwbIaRyCTAlm0QJNFnn/Y+77m6S5t2QzZ49+zwzZ5Jz9uw539lvd/PL97+cjp6enp4AAIBN2GZTdwAAgCQcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcgQE+/vGPx3777bfJ+7344ovR0dER8+fPj1aSY7rqqqs2eb+8T963leU85HwAtArhCG3ihRdeiIsvvjgOOuigeN/73tdcDj300Ljooovi3//934f9+T/72c82Ifav//qvA27PdzV9//vf33wsx9jf22+/HRMmTIhf+IVfiFaV4ZZj39Bl4sSJIz28MeXll19ugv/pp58e6aHAmDV+pAcAvHdf/epX45xzzonx48fHeeedF0cccURss8028eyzz8bf//3fx0033dRE27777rvJx/riF78Y69atG/IYTjzxxObPRx55JH70R3+07/Znnnkm3nrrrWZs//Iv/xL7779/38eeeOKJeOedd/o+t1Vl3P75n//5erePGzduWJ/3ueeea+aR/w/HuXPnNiuxRx555EgPB8Yk4Qij3JIlS+Lnf/7nmyh88MEHY8899xzw8T/4gz+Iz3/+85sMkNWrV8f2228fP/ADP7BZ4zjmmGOaFbgMx0suuaTv9ozFnXfeufl4fuwXf/EX+z6W19N7DccM3QzQ4VoBzOjtP+6tGayb0jtvAFuD/8rCKJebiDMebr311vWisTd6fvM3fzOmTp06YPPrDjvs0ETnT/7kT8akSZOalcqN7eOYK4Z5+5QpU2LHHXeMWbNmNbf1t+2228axxx7bhGJ/eX369OlxwgknbPBj+XjTpk1rrufr+PSnP92MNaPp4IMPjj/8wz9sNnf3l5uJc7P83/zN38Rhhx3W3Pe+++7b6NcoAzXHlmF54IEHxs033xxbWu7rmePK1zR79uzYddddm6D7yEc+Eq+//nrf/X7qp34qDjjggA0+Rn6dMrA3to9j73MsWLAgfuM3fiN222232Hvvvfs+nv9B6P167LXXXs1uCoPn6ZRTTmm+3t/+9rfj1FNPbXZp+MEf/MHm+6i/hx56qHmuL3/5y80qX94nv08+9rGPxYoVK2LNmjVx6aWXNmPI76ULLriguW2wv/7rv46jjz46tttuu9hpp52a/+QsW7ZsyGPK8eQcpnyu3t0FWm0fW2h3VhyhDTZTd3Z2xvHHHz+kz/ve974Xp59+erPal3GW/1hvSEbbWWed1cTXr/3ar8UP//APx1133dXE42D5WP/8z//cHDjTG58ZUr/yK78Sxx13XFx55ZVNyGQs5uN+61vfamIpV0Pz+k//9E/HN7/5zbjwwgubTZH3339//NZv/Vb813/9V/zxH//xgOf6xje+0URNBuQuu+yy0QN6Fi1aFKeddloTcrl/XL7uHMfuu+8+pK/XG2+8sd5tGcuTJ08ecFuutuY+nfkc+XW4/vrrmzHecccdzcdzl4Lzzz+/2UzfG0Jp6dKl8dhjj8XnPve5TY4lozFfzxVXXNHEdsrXloE3Y8aM+PVf//VmM3fuopDPk3PQfyX5u9/9bvzET/xE/MzP/Ez83M/9XNx5553xmc98Jn7kR34kZs6cOeC55s2b10Tf5ZdfHl1dXfFnf/ZnzWPlnOXj5PPmuDPgcjeEHFOva665Jn73d3+3eY78HsiAzs8/+eSTm31h8/ugOqb8vvu93/u95vF/9Vd/NU466aTm8378x3+8NH/AFtIDjForVqzIpbies88+e72Pffe73+15/fXX+y7//d//3fexWbNmNZ93+eWXr/d5+bF999237/rdd9/d3Pezn/1s323f+973ek466aTm9ltvvbXv9q997WvNbX/1V3/VXH/llVea6wsWLOhZuXJlz7hx45r7pMWLFzcfu+aaawY8z9VXXz1gPB/72Md6Ojo6erq6uvpuy/tts802Pc8888x648+PXXnllX3X82szceLEnqVLl/bd9u1vf7sZS+VXYO/XakOX008/ve9++XXI22bMmNGzbt26vts/9alPNc/11ltv9c3ZhAkTej796U8PeJ78+ubr7D/OnId8/sHPceKJJzZz0Gv58uU92267bc9pp53Ws3bt2r7bb7jhhub+t9xyS99tH/jAB5rb/vIv/7LvtjVr1vTssccePR/96Ef7bvvmN7/Z3G/atGk977zzTt/t5557bjPOmTNnDhj/9OnTB3zfvPjii83r7p3fXosWLeoZP378gNurY3riiSfW+54Dti6bqmEU6+7ubv7MTYWD5ea/XJXqvdx4443r3SdXpjblH//xH5vN3f3vmweF9N+PsVeu/uRKVO++i70rXbmylmM8/PDD+zZX9/7Zu39jPk8+bm5W7y83XWcP3nvvvQNu/8AHPtAcNf79rF27tlm1PPvss2Offfbpuz1Xr3K1tSo3cT/wwAPrXa699tr17purYf1P85MrYzmOXFFMuUKZK2i5Wtp/E3yuSP7Yj/3YgHFuzCc+8YkBB+Z8/etfb/bxzE3H/fdlzfvl833ta18b8Pk5F/332cyV01wR/s///M/1nitXR/uvVubKdo77l3/5lwfcL2/PTdC5opvyoKzc9zRXD3O1tveyxx57xA/90A81K8ubOyZg5NhUDaNY7nOWVq1atd7Hcj++lStXxmuvvbbBAzsyBvvvH7cxGTy57+TgOM39DwfLTY+5j13/OMwjrHNTZ29Y9v9Ybxz0Pk/ul9f7mvpHXu/H++t/dPbG5KbR//mf/2lCZbAcf8ZqRUZabgKuGBx+udm6d1Nsr9xcfffdd8ejjz7afE1yX9OFCxc2m7UrBr/23q/N4DnJr2/uTzn4a5fzPvgcljnODZ22afDryf1cU/99Zntvz1DM/R/zYKjnn3++CcwNfe3T4IOwhjImYOQIRxjF8h/rjLrFixev97HefR5zP7sNyQMohuNUL7mC+IUvfKHZlzHjsP8+aPn3W265Jd59991mVTIPmtjcI6F7Y7TVbOwUPf1XF88888xmn9JcdcyvSf6Zc/GzP/uzW+W1V8a4qftu6jEyIjMEc6V4Q/cd/B+RoYwJGDk2VcMod8YZZzQHLTz++OPD8vh5mp9XXnllvVXNPPhiY+GY/9jn5tM8ACKPpu6VkZQrgLnpNDdB9j8NTz5PnqcvV0n7y3NR9n58qHITfUZWrn4NtrHxbw15tHUeXf2Vr3ylCazcTJ2btHPFdXP0fm0Gv6bcfF09f+eWlkev5/dBro7mau3gS26WH6pWf6cfGAuEI4xyv/3bv92sXuU+Z7lZekuv2OTpenK/tTxCt1fus5dHx25Ibwxed911zcpi/xXHPPI5V0h7T7PSPxzzefJxb7jhhgGPl0dTZzAMPtq3Ilexcl/G3Cz80ksv9d3+H//xH82+jyMpN1dnKOeJxf/t3/6tub65MsRys/Sf/umfDpjvL33pS82m4/zPxdaWR0fn1z+P9B78PZjX33zzzSE/Zu/5KgefYgjYemyqhlEu9yG77bbb4txzz232cet955j8xzlXm/JjuRm0sj/jhuRm1Vw1zNOx5GbvPCAlD3zIINmQ3Ccu93/L/fcyFAevomVI/t3f/V0Tg/1XI/N58hx+v/M7v9M8T76Gf/qnf4p77rmnOegjV7A2R4ZLnuMxV/TyNDYZwRm9uS9mdf+5/Jw8H+GG5HkaN+cE3L3nz7zsssuawProRz8amytXVufMmdO81jylTZ7WKFcf87yOeWDSSJy8POfr6quvbsaV85kHKOXrze/JPJ1THkSUr32oj5n70eauEPlY+XXPXTIq+7sCW4ZwhDaQ51nM8xX+0R/9URNbuR9hhlluoszVpjz/YobY5sjo/Id/+Icm3jKe8nEzTPK5+r+1YH+5kvi3f/u3GzzHXsZihuMhhxzSHEQx+HnyPH256TZPaJ7hmec1zCOrN1ceyZ2ri3lS7nzsDOgMrNz8Xg3HPLH1L/3SL23wYxlCmxOOuW9nfh3zJOa5Ypgn0n4v8nyKGZC5YvupT32qOdl2xtnv//7vb/a7Ab1X+Z+NfO/0XDXOr3nK/1TkeTXztQ9Vvo6/+Iu/aGI0v6cz6PP7RDjC1tOR5+TZis8HAMAoZR9HAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgDQmudxzLfXyndLyJO3evsoAICRl2dnzLd8zTdtyPPqtkw4ZjTmCWABAGgty5Yt+77vNLbVwzFXGtOyiJgco9+SfBuskR4EG2RuWpN5aV3mpnWZm9a0pI3mpTvf2alfp7VMOPZunp7cJuE4qU1eRzsyN63JvLQuc9O6zE1rmtSG87Kp3QgdHAMAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAGL5wvPHGG2O//faLiRMnxvHHHx+PP/745jwMAADtHI533HFHzJ49O6688sp46qmn4ogjjojTTz89li9fPjwjBABgdIbjddddF5/4xCfiggsuiEMPPTS+8IUvxPve97645ZZbhmeEAACMvnB85513YuHChTFjxoz/f4BttmmuP/roo8MxPgAAWsT4odz5jTfeiLVr18buu+8+4Pa8/uyzz27wc9asWdNcenV3d2/uWAEAGC3huDnmzZsXc+fOXe/2JRExKUa/pSM9ADbK3LQm89K6zE3rMjetaWm0j5XDEY677LJLjBs3Ll577bUBt+f1PfbYY4OfM2fOnOZgmv4rjlOnTo0DI2JytIfOkR4AG2VuWpN5aV3mpnWZm9bUGe2hezj2cdx2223j6KOPjgcffLDvtnXr1jXXp0+fvsHPmTBhQkyePHnABQCAMbCpOlcPZ82aFcccc0wcd9xxcf3118fq1aubo6wBAGhfQw7Hc845J15//fW44oor4tVXX40jjzwy7rvvvvUOmAEAoL1s1sExF198cXMBAGDs8F7VAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAIAS4QgAQIlwBACgRDgCAFAiHAEAKBGOAACUCEcAAEqEIwAAJcIRAICS8bW7MWb09ETb6OqK6Owc6VEwmHlpXeamdbXT3HR0jPQIeA+sOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCADA8ITjww8/HGeeeWbstdde0dHREXffffdQHwIAgLEQjqtXr44jjjgibrzxxuEZEQAALWn8UD9h5syZzQUAgLFlyOE4VGvWrGkuvbq7u4f7KQEAGI3hOG/evJg7d+56ty+JiEkx+i2NNtPVFe1i6dK2m522YF5al7lpXeamNS2N9rGyVcJxzpw5MXv27AErjlOnTo0DI2JytIfOaCOdbfVqorPNXk+7MC+ty9y0LnPTmjqjPXS3SjhOmDChuQAAMLo5jyMAAMOz4rhq1aro6rcf3AsvvBBPP/107LTTTrHPPvsM9eEAAGjXcHzyySfj1FNP7bveu//irFmzYv78+Vt2dAAAjN5wPOWUU6Knp2d4RgMAQMuyjyMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoGR87W6MGR0dIz0CGF16ekZ6BGyEX2etyU/M6GbFEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAbPlwnDdvXhx77LExadKk2G233eLss8+O5557bigPAQDAWAjHBQsWxEUXXRSPPfZYPPDAA/Huu+/GaaedFqtXrx6+EQIA0BLGD+XO991334Dr8+fPb1YeFy5cGCeffPKWHhsAAO2yj+OKFSuaP3faaactNR4AANphxbG/devWxaWXXhonnHBCTJs2baP3W7NmTXPp1d3dvblPCQDAaAzH3Ndx8eLF8cgjj2zygJq5c+eud/uSiJgUo9/SkR4AG2VuWlPbzUtXV7SLpUvbbnbaSPvMTfv8xEQbzUrEyuL9Onp6enqG+uAXX3xx3HPPPfHwww/H/vvv/33vu6EVx6lTp0Zu5J4c7fED0DnSg2CDzE1rart5Gfqv0JbV1dUVnZ3tMzsdHdFG2ucnpyfaZ2K62mZWInJ78JT/2w1x8uTJW2bFMRvzkksuibvuuiseeuihTUZjmjBhQnMBAGB0Gz/UzdO33XZbs9qY53J89dVXm9unTJkS22233XCNEQCA0XZU9U033dQsYZ5yyimx55579l3uuOOO4RshAAAtYcibqgEAGJu8VzUAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQMr52NwAYZXo6om10RURntIc2mpaxyIojAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQDY8uF40003xeGHHx6TJ09uLtOnT4977713KA8BAMBYCMe99947rr322li4cGE8+eST8cEPfjDOOuuseOaZZ4ZvhAAAtITxQ7nzmWeeOeD6Nddc06xCPvbYY3HYYYdt6bEBADBaw7G/tWvXxle+8pVYvXp1s8kaAID2NuRwXLRoUROKb7/9duywww5x1113xaGHHrrR+69Zs6a59Oru7t780QIAMHrC8eCDD46nn346VqxYEXfeeWfMmjUrFixYsNF4nDdvXsydO3e925dExKQY/ZaO9ADYKHPTmtpuXrq6ol0sXdp2s9M+2mhq2ucnJtppWmJl8X4dPT09Pe/liWbMmBEHHnhg3HzzzeUVx6lTp8aKiJgc7fED0DnSg2CDzE1rart5eW+/QltKV1dXdHa2z+x0REe0jTb6wekxLS0ptwdPiWgWBvPMOVt8H8de69atGxCGg02YMKG5AAAwug0pHOfMmRMzZ86MffbZJ1auXBm33XZbPPTQQ3H//fcP3wgBABh94bh8+fI4//zz45VXXokpU6Y0JwPPaPzwhz88fCMEAGD0heOXvvSl4RsJAAAtzXtVAwBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKxtfuxpjR0xNto6srorNzpEfBYOaFraQn2uf3WVd0RWe0y89Nx0gPgPfAiiMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAADH84XnvttdHR0RGXXnrpe3kYAADaORyfeOKJuPnmm+Pwww/fsiMCAKB9wnHVqlVx3nnnxRe/+MV4//vfv+VHBQBAe4TjRRddFGeccUbMmDFjk/dds2ZNdHd3D7gAADD6jB/qJ9x+++3x1FNPNZuqK+bNmxdz585d7/YlETEpRr+l0Wa6uqJdLF3adrPTFsxL6zI3rcvctKal0T5WDkc4Llu2LD75yU/GAw88EBMnTix9zpw5c2L27Nl913PFcerUqXFgREyO9tAZbaSzrV5NdLbZ62kX5qV1mZvWZW5aU2e0h+7hCMeFCxfG8uXL46ijjuq7be3atfHwww/HDTfc0GyWHjdu3IDPmTBhQnMBAGB0G1I4fuhDH4pFixYNuO2CCy6IQw45JD7zmc+sF40AAIzRcJw0aVJMmzZtwG3bb7997LzzzuvdDgBAe/HOMQAADM9R1YM99NBD7/UhAAAYBaw4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKxtfuxpjR0THSIwAAWpQVRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAsOXD8aqrroqOjo4Bl0MOOWQoDwEAwCg1fqifcNhhh8XXv/71/3+A8UN+CAAARqEhV1+G4h577DE8owEAoH32cXz++edjr732igMOOCDOO++8eOmll4ZnZAAAjN4Vx+OPPz7mz58fBx98cLzyyisxd+7cOOmkk2Lx4sUxadKkDX7OmjVrmkuv7u7u9z5qAAC2uo6enp6ezf3kt956K/bdd9+47rrr4sILL9zoATUZmIM9FREbTs3RZWlE7DvSg2CDzE1rMi+ty9y0LnPTmpa20bysjIijImLFihUxefLkjd7vPR3ZsuOOO8ZBBx0UXV1dG73PnDlzYvbs2QNWHKdOnRoHRsTGhzW6dI70ANgoc9OazEvrMjety9y0ps5oD91b4zyOq1atiiVLlsSee+650ftMmDChKdf+FwAARp8hheNll10WCxYsiBdffDG+9a1vxUc+8pEYN25cnHvuucM3QgAAWsKQNlV/5zvfaSLxzTffjF133TVOPPHEeOyxx5q/AwDQ3oYUjrfffvvwjQQAgJbmvaoBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXCEQCAEuEIAECJcAQAoEQ4AgBQIhwBACgRjgAAlAhHAABKhCMAACXjYyvr6elp/uyO9rCyjV5LuzE3rcm8tC5z07rMTWta2Ubz0j2o01omHFeuzC9zxNSt/cQAAGyy06ZMmbLRj3f0bCott7B169bFyy+/HJMmTYqOjo4Yzbq7u2Pq1KmxbNmymDx58kgPh37MTWsyL63L3LQuc9OauttsXjIHMxr32muv2GabbVpnxTEHs/fee0c7yW+YdvimaUfmpjWZl9ZlblqXuWlNk9toXr7fSmMvB8cAAFAiHAEAKBGO78GECRPiyiuvbP6ktZib1mReWpe5aV3mpjVNGKPzstUPjgEAYHSy4ggAQIlwBACgRDgCAFAiHAEAKBGOm+nGG2+M/fbbLyZOnBjHH398PP744yM9JCLi4YcfjjPPPLM5832+M9Hdd9890kMiIubNmxfHHnts845Ru+22W5x99tnx3HPPjfSwiIibbropDj/88L6TGE+fPj3uvffekR4Wg1x77bXN77RLL710pIcy5l111VXNXPS/HHLIITFWCMfNcMcdd8Ts2bObw/CfeuqpOOKII+L000+P5cuXj/TQxrzVq1c385FhT+tYsGBBXHTRRfHYY4/FAw88EO+++26cdtppzXwxsvKdvDJKFi5cGE8++WR88IMfjLPOOiueeeaZkR4a/+eJJ56Im2++uQl8WsNhhx0Wr7zySt/lkUceibHC6Xg2Q64w5urJDTfc0Pf+2/l+lZdccklcfvnlIz08/k/+L/Cuu+5qVrdoLa+//nqz8phBefLJJ4/0cBhkp512is997nNx4YUXjvRQxrxVq1bFUUcdFZ///Ofj6quvjiOPPDKuv/76kR5WjPUVx7vvvjuefvrpGIusOA7RO++80/zPfMaMGQPefzuvP/rooyM6NhgtVqxY0RcotI61a9fG7bff3qwE5yZrRl6u1J9xxhkD/s1h5D3//PPNLlEHHHBAnHfeefHSSy/FWDF+pAcw2rzxxhvNL9fdd999wO15/dlnnx2xccFokSv0uZ/WCSecENOmTRvp4RARixYtakLx7bffjh122KFZqT/00ENHelhjXkZ87g6Vm6ppra2O8+fPj4MPPrjZTD137tw46aSTYvHixc1+3O1OOAJbfQUlf8GOpX2CWl3+A5ib3XIl+M4774xZs2Y1uxGIx5GzbNmy+OQnP9nsE5wHYdI6Zs6c2ff33O80Q3LfffeNL3/5y2Ni9w7hOES77LJLjBs3Ll577bUBt+f1PfbYY8TGBaPBxRdfHF/96lebo9/zoAxaw7bbbhudnZ3N348++uhmhetP/uRPmgMyGBm5S1QecJn7N/bKrV35s5P7169Zs6b5t4iRt+OOO8ZBBx0UXV1dMRbYx3EzfsHmL9YHH3xwwKa3vG6fINiwPAYvozE3gX7jG9+I/ffff6SHxPeRv9MyTBg5H/rQh5pdCHIluPdyzDHHNPvT5d9FY2sdwLRkyZLYc889Yyyw4rgZ8lQ8uSknf4iPO+645gi33Jn8ggsuGOmhjXn5A9z/f30vvPBC80s2D8LYZ599RnRsY33z9G233Rb33HNPsw/Qq6++2tw+ZcqU2G677UZ6eGPanDlzmk1v+fOxcuXKZp4eeuihuP/++0d6aGNa/pwM3gd4++23j5133tm+wSPssssua84XnJunX3755ebUfBny5557bowFwnEznHPOOc3pRK644ormH8A8PcJ999233gEzbH15HrpTTz11QOSnDP3cmZmRO8l0OuWUUwbcfuutt8bHP/7xERoVKTeHnn/++c1O/hnyuc9WRuOHP/zhkR4atKTvfOc7TSS++eabseuuu8aJJ57YnKM2/z4WOI8jAAAl9nEEAKBEOAIAUCIcAQAoEY4AAJQIRwAASoQjAAAlwhEAgBLhCABAiXAEAKBEOAIAUCIcAQAoEY4AAETF/wJjxBYDHjfEMgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGzCAYAAAAIWpzfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMOBJREFUeJzt3Ql4VPW9//EvBEKkmqAiBBBFUURls2wCUqtF02JRe2ulYAG5CqLItXCrgAiIG4pAaTVIRVDbiqAWrVdoFFGutWCpILdoAYuoQVs2F6CgBML5P5/f/znTM5NJyIRsv+T9ep4R5+Rsc9bP/JYzdYIgCAwAAMADdat6BQAAAEqL4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAiT46KOPrE6dOvbEE09U6nK//e1vuxdQm+m80/mn8xBIhuBSja1fv96uuuoqO/XUUy0jI8NatGhhl1xyiT300ENx49133332wgsvWHW3ceNGu+2226xTp0523HHHWbNmzeyyyy6zt99++6jmq4tcca8RI0ZYbXXnnXcm3SY6lpKZN2+enX322e7vZ555ZpHjLPTpp5/a1VdfbY0aNbLMzEy74oorbMuWLUe1rm+++aZ973vfc8e4ln/KKadYv379bMGCBbFx9u/f7z7TihUrrKr885//tHHjxtlFF13kjmFtz+LWRyE02fb/7ne/W+blJ87zmGOOsQ4dOtisWbPs8OHDR/HJaoeVK1faBRdcYA0bNrTs7Gz7r//6L/vXv/51xOm2bt1qU6ZMsW7dutnxxx9vjRs3dvvi1VdfTTr+l19+acOHD7eTTjrJvvGNb7jjZe3atRXwiWqnelW9Aij+BNPBrgv4sGHD3Emmk+ett96yX/ziFzZq1Ki44KKAc+WVV1p19thjj7mb4w9/+EO76aabbPfu3farX/3Kzj//fMvLy7M+ffqUed4KdIMHDy4yvE2bNinPS0Hxq6++svr161tN8Mgjj9ixxx4be5+WllZkHO0HhTztmzFjxtgf//hHd1FXWBg7dmxsPF3kdVxq391+++1uG/385z+3Cy+80NatW2cnnnhiyuv37LPPWv/+/V2gveWWW9yN4cMPP7Q33njD5s6dawMHDnTjaV1085CqKpnatGmTPfDAAy7YtW/f3latWlXi+CeffLJNnTo1bljz5s2Pah2i89y1a5cLd6NHj7adO3favffee1Tzrsl0fH7nO99x4XzmzJn2ySef2PTp0+3vf/+7/eEPfyhx2t///vduv+saO2TIEDt06JD9+te/dted+fPn29ChQ2PjKkDqC9n//d//2a233upCzuzZs90xu2bNGnfs4CjpRxZR/fTt2zc46aSTgi+++KLI37Zv3x73/hvf+EYwZMiQoLp7++23g71798YN27Vrl/ucvXr1KvN8dRiPHDky8N2FF17oXuVl8uTJbtvs3LmzxPH2798fnHjiicFll10WN/yaa65xx9bnn38eG/bAAw+4ea5evTo2bMOGDUFaWlowfvz4Mq3nOeecE5x77rnBgQMHSjzW9Tm0bH2uqrJnz57gs88+c///7LPPuvV5/fXXk46rfanPVZ6SzfOrr74KTj311OC4444LDh06FFR3hYWFbp2L8/jjj7vt+uGHH5brcr/3ve8FzZo1C3bv3h0bNnfuXLesl19+ucRp33333SLn0ddffx20bds2OPnkk+OGL1q0yM1Tx0dox44dQaNGjYIBAwaU2+epzagqqqY++OADO/fcc11xfKImTZrE/l/Fxfv27bMnn3wyVnx87bXXur99/PHHrmTjrLPOckXK+jb8ox/9KGnd8V//+lf3rVnj6RvdPffcY48//njSumZ9O+ndu7crAlVxub5dvPfee0f8TJ07d4775i9aJ81rw4YNVtH0jaddu3buW0/Pnj3dZz3ttNNszpw5R2zjsm3bNvetStumQYMGrppLVSSJ20bfrLTfNI6+WY8cOdIVGyd69NFHrXXr1m4dVPysEo5kDhw4YJMnT7YzzjjDzbNly5auuk3DS0vZbs+ePe7fZF5//XX77LPP3LESpXXXsbVkyZLYsOeee866du3qXqG2bdu6b7LPPPOMlfVY1/zS09OLPda1nVXsLip1CY91VR1FqyJV8njCCSe46qYuXbrYiy++mLT9hEpzbrjhBnf8qbpLpXVffPHFEddVx7vmnwp9Oy9NdURZ6bNq++3du9d27NgR97ff/va37rzTcab1/vGPf+xKbkO//OUvXQlc9BidMWOG20YqeQsVFha6zx4tfVNphc4jbUPNX8vR8ZFI87r55pvtqaeeip0bKmEVXTcuvvjiuOtOsiovlfBp/+rfstDxv2zZMvvJT37i9ndI+13XpCMdu1pvlZxE6XP07dvXldxo24e0DZo2bWr/8R//ERumY1fVqyq5SeXcRXIEl2pK1RW6wb777rsljveb3/zGnUC6+ev/9dIFWf7yl7+4KiddrHSBUlXA8uXL3Q1cxe7RNgsq/tdFZPz48a7YWRcZVUklW56Cik52FZ1OnDjR/va3v7l647I2plMoSLwopOrrr792xeaJr4KCgrjxdHPSxUYX2WnTprmL5Y033uiKe0uiKpTnn3/ehReFE1Wj6GKVn58fG0c3Ud3sFVh08dc0qoK59NJL7eDBg7HxVF2mfaTqP61Dr1697PLLL4+7oYgu4BquG4Tae6jNiYqqVTWjqpXSOv300y0rK8vdeHTh3r59e9zf33nnHfevbvRR2kZ169aN/V3ro4CbOJ4ofCmARC/gqRzrOi51AyiOLvyq8pIf/OAHsWM9vDno2FWVowKw2qBo+ytYa3tpvyXSjVTjap/p5qXjXeMWF+7K6v33348FfO1vnS/RY6G8hGE7+kVH1Ub6bKqaUNXIT3/6U7edv/Wtb8WCiq4b2q9qYxRSiNZ+j4ZpHQMKX5o2pOvDeeedZ3fddZerrq5Xr577YhQNuqHXXnvNXVd03Gq6Vq1aufNe1x1V4Wifaf1U/ZLsuqN9qCqeZPuytO0FFSATj12FZVVRhsd4qvQZ1F5Gr5Dm9c1vftNtw8RzRNddHRM4SlVd5IPkXnnlFVf8rlePHj2C2267zRVnFhQUFBm3uKoiVQEkWrVqlSvG/PWvfx0bNmrUqKBOnTrBO++8Exum4vATTjghrshW1Twq7hw2bFjcPLdt2xZkZWUVGV4ab7zxhlv2xIkTg7LSOhb3evrpp+OK2TVsxowZsWGqnujUqVPQpEmT2LbV59V4KrIWVdfp/YMPPljsOqgoOD09Pbj00ktdUXjo4YcfdtPOnz/fvdcytCwtM1o18uijj7rxolVFv/nNb4K6desGf/zjH+OWNWfOHDfun/70pxK3y6xZs4Kbb745eOqpp4LnnnsuuOWWW4J69eoFZ555ZlxxuarZdJwlo2q8H//4x3FVNXfddVeR8XJzc93fNm7cGKRq3rx5blptv4suusgdC/rM0e14pKqi73znO0H79u1d8X3o8OHDQc+ePd3nTayG6Ny5c9y5NG3aNDf897//fanX+0hVRf/5n/8Z3HnnncHvfvc7d75dfvnlbvyrr746KCsdH6qe0LbQS9v71ltvdfONVvV99NFHbp/ee++9cdOvX7/eHQPhcG3jzMxMd30Jt5mqDX/0ox+56cOq3ZkzZ7pjMVp1nXh90fZs165dcPHFF8cN17pp2vfeey9u+E9/+lP3tz//+c9x55GuJYlVReF+C8/JVIX7StebRPqs2dnZKc/z73//e5CRkREMGjSoyPVY+z7RkiVL3Drk5eWlvCzEI7hUY2pH8IMf/CBo2LBh7EasG0nixbU0bVx0UVF7El3sFD500Qjpwq4LfCIFmugFZPHixe79a6+9Frtwhi/dsM8444yUPp/aL6h++PTTTy/S9iUVWqcrrrgiWLZsWZGXQlX0oq+L9r/+9a+46R955BE3D4W6ZMFFN0PdVHVjiLb3iFqwYIGbZunSpXHDFU50Y/jhD3/o3q9cudKNp/CRuH90wY4GF93o1J4hcVu///77bh733HNPyttKIUbTTp06NTZMF9ljjjkm6fgtW7Z021by8/PdtGrnUlz4iIbfVOhirmOofv36sWNdx0U0nBUXXBSyFX7vvvvuIttqypQpbppPPvkk7gb4q1/9Km4eOv50bNxwww3lFlySUbiPHmupCsN34kvHSrQNhoKGtoluronb5Oyzzw769OkTG/e73/1ucP7557v/V7jQ/NasWePChr5Aia5DHTp0KHa9dF5o3jfeeKO7vkRpfgqkidq0aRNbbtRNN91U7m1cFBwTQ1JIwUPnXir27dvnvnwcf/zxwaeffhr3N203bYdEy5cvd+vw/PPPl+ETIIqqompM9daLFy921RurV6921Tgqilc9vqpnjkQ9YyZNmuTaRag6SdUxKnJXMXG0rlhtYdSGIlHiMLW+F9VJaz7R1yuvvFKkfr0kajvx/e9/330e1fsmtn1Jlap81Csp8aW65ihV46joPlnPo+KqurTtVC2mtj2an4rLVcWjYuLoNhS1J0osilZVTfj38N/EngXqnaPxEre3qkASt3W4vqls75B66KjKItqNU+0LEqvUolVw+ns4niSro9d40XFSlZOTYy+//LI7NtX+RFVu2lY6Ro70OTdv3uyqeFQNk7it1D5IEueRuP11/KndUkU/O+S///u/3b/FdaMtDVWzqL2GtpeqLdWFXD2Kot3cdexom+hzJm4TVZFFt4eqi1QtreuFqoe0HVTV0bFjx1h1kaqSNF7USy+95KrntFy1nwmr85K1Q1FbskTav8l62CSeQ6nQsnVehq/PP/+8VMduKset2vuo+l3XYLVnSewlpnlVxDmCf6M7tAd08wsbROqmpXYW6kIaXpSLoy7TamCruuMePXq4dg6qB9dJV5ZnPoTTqG2Bbn6JVMddGrpJqm2C2kvo4qsGs9WdtqHameh5OVpn3STVJVV196rnrwja3upyq/YJySiQloWmCy/oohuVLsa6mUUbfms/qdFueGHWzUkhTs8ySRQOO9quvmoroBukXgraaoirwKguqEc6Ln/2s5+5AJRMsmBeFcJ9Ft3+qVLwjj46QG2kFDTUPV1t2cJtonNd2y5Z9/foFwW1T1O7G3XtVlAJA4r+1Xs1ilUwigYXDVf7K4V4hScdQwrfut5En70TqqybtbrTq6NCSB0O9JwdrZ8Ud+ymctzq8RQKbWoXpS9xibSsijxHQHDxTti4LHpi6AKVjL4N6IKvhorR1J/Yy0WNI/WtNVHiMPWCEd3cyvrMFV1Q1WBQjQTVkl8Xlsr0j3/8w5X2REtdwsZy+iZbEn1+fWPWS99o1ahP21Y9N7QNw+d8REtOdPPXM0nC7RWOp+mjFz3dODSevuVGl6dnQajHTnH7OFX6Fq5ShWjY0ucQPQhQDZdDeq/9Ff5djQ0VpJI9MPDPf/6z+9xqhFpRx3px2yDc3rpxlva41PZXw9CQGp5qOdHPXxHCB/WFPaTKgx5Ap0bXagiu8KZnP+nY0b5WSceRnmWkRqP6cqQwopeePSIKJXqOjs7V8H3od7/7nStpUYhXmA0puJSWzoWwFDdK51BZqcedtkVIzwQSfTnSFysdu+rdEz0/1Tg4Oqwk2jb6jHrg34ABA5KOo/NF21HnTrSBrs4RBfOyPFsKCeIqjlBtqB2JGsolCp+joTrsUNOmTWPtEKLUuPbaa6+NGxY2Qoy2iVEDztI0zlWDTrXXUD17skbCalh3JGH9dWIbg6NR2ue4lNQ4V22Himucq/rsxOdOqFGjtvtVV10V1zhX7QWi+2327NlFGudqWaVpnPvEE08Uu63UMDKxrU5p9kfYiDZ6/Ghe2tff//7348b9yU9+4tpXhc8tkfvvv99N/5e//CU2TA1E1ZBz7NixQVm8+uqrSYernYCWpbZV4XrqvRoZJ/r2t7/tPsM//vGPErfDkRrnvvDCC+XSxkXnSrShsOi46N+/f6wNSVkU92wYtU3RORxum82bN7t9MnDgwCLXEb1Xe7coPUfprLPOcuu2bt26WBs0vVdblNatW8eNP2bMGHds6NwI6bwJ2+OV5vxMpXHul19+6Z4XpH/LSuemnuOiZ/GEHnvsMbesP/zhD7Fh+kxaVuJzW8Jj5Pbbby9xOQsXLizyHJewbaH2P44ewaWa0sXptNNOcxcI3dTUO0UXIV2MWrVqFde6Xw+rUwNd3ZDVi+att95ywwcPHuzG18VMNz+FGDWGVa+BaHBRo0udVI0bN3aNGadPn+56LujmqhNQPRSijTvV+Ey9B9Q4VPOdMGGCG/dI4eHnP/+5m596SanHTOIreiPWzaC0DxvTeJdccknSeYaNC8OLfvPmzV2vHjU8fuihh4ILLrjATa9tHEoMLgp0uimOGDEi+OUvf+nCiJancdRbJ/GBb2pkqv2lZWj7d+3aNe4mqW2m8XSz0PxGjx7ttr8ao0aDi8KR9q1uSOrZo/VVTyGth9YnGh6SUYNb7XMdFwoseviV5qV9Fb3hRAONgpgeyqVjR+8Te6Xooq+bmLahLuTap2rAq+2aGJTCoHgkOnZ1POkBdrqR/OIXvwj69evnptW2O3jwYNzD6tQDROurY129ZMIbtxpK6tgeN26c259qrKvtF21UGgYX9UDq3bu326YK7jqmdSwk+7KQSPPVS/tE81Lj5nBY9PjVemrfal11Tml/a/zhw4cXmWdiaC1OSQ+1U+NxbcswlKgBtuarhvfaV2qErt5Daoyf2ENO20zjKjREe3OFYSbxC1DY0FTbUPPVdUPHhLZ1aYOLQqb2l/abel9pnbRu4TzKs1eRKCw2aNAgOO+889w667qlXkE6X6OSXXvCjglav2TXmWgnAD0EUI2Ojz32WLddtP+1z/SAwLL0ukNRBJdqSt8AdEFUgNAJoG/z6rWjm2Hik3N1MnzrW99yN6poaYrCzdChQ10g0TxycnLcuHrKZmIvJN2cdRHSia1wo4uebqqaX/SkDE9szUsXOZ34upHpwqYn45ZEyyyp63L0QvU///M/SXvfJFPSPKM3g/Cir/VUeNK6a1soZEQlBhfdCHTh1b7QjUGfu3v37sEzzzxTZF00L42n3jEqkVGpQbKnHyv8KJhqe3fp0sV100z25FwFHpWyab01ri7yKi3QBTHapTmZ66+/3t3odcHU+uj4UalI9BtnlG72ulHpWNM+VShJdiPfunWrCzgqfdNxpZIa9V5JpPUsTTdTBRCFAC1Tx7D2i9ZbN5bEdVWvLM1X65h4c/nggw9c4NIy9XlbtGjh1i0aLsMb4P/+7/+6AKHtqc+gpwRHS5bKeryFtmzZ4rrZ6kuGPo9KIrTeOp4Tt6l6NGnasNt5WYPLihUrimwTdcVWINNxq5eOTR3LmzZtStpVV0+XTTyGNFy9xhJpmG7kOi41X23bMLwnbq/ivtT89a9/dZ9J20j7S+Ev7KFW3sFF1M1eQU7LU8mn1ivxGEsWXMLPVdwrsdRNvayuu+46F8y07/UZj/RFA6VXR/9JrD4CwgapqjdX/X+yBn4VSXXVTz/9tGtnE61DPxp68J4eSnekh/rh6Km3mBrzqi2AeghVF3pyrhq36+GMyR6kVxWWLl3qek+pPZPaEAEoGd2h4agrZJR6k6j3kHocVHZoCR9Dr5475RVaULnUpVnddNUDA0c+1tXTj9AClA69iuCou7RKJPRYbT0SXo+l1+97KDxUBX0jhr/0sxB64cgefPDBql4FwCsEFzjqBqru0/rxP3U71XMhFF6iXSABAKhqKbdxURGwviHoSYt67oF+9Eo/TlYSPQBIvzSqp4DqAUx33HFH7BeMAQAAKqyNix7epYdk5ebmlmp8PVRLRcbhr4Cqwef111/vHlwEAACQiqPqVaQqhSOVuIwdO9b9zHm0J4caounprXl5eWVdNAAAqIUqvI2Lfv8i8THc+j0RlbwURz9QFf2RKj06Wb/tceKJJ5bbo88BAEDFUtmIHo+g32iK/gRCtQ4u+oXOxF/o1Xv1WFEX3GQ/vqUfr9OPqwEAAP9t3brVTj755Jrbq2j8+PGuMW/0p8r1w2H64JmZmVW6bgAAoHRUSKFOOeX5A6wVHlyys7Pdc0Gi9F4BpLifOtdDx5I9eEzTEFwAAPBLeTbzqFsZDzYLfxY9tGzZMjccAACgQoOLfrdG3Zr1Crs76//z8/Nj1TyDBw+OjT9ixAjbsmWL++2ZjRs32uzZs+2ZZ56x0aNHp7poAABQy6UcXN5++20777zz3EvUFkX/P2nSJPdeD6ULQ4ycdtpprju0Sln0/JcZM2bYY4895noWAQAApMKLX4dW456srCzXSJc2LgAA+KEi7t/8OjQAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAACgZgeX3Nxca9WqlWVkZFj37t1t9erVJY4/a9YsO+uss+yYY46xli1b2ujRo+3rr78u6zoDAIBaKuXgsmjRIhszZoxNnjzZ1q5dax07drScnBzbsWNH0vEXLFhg48aNc+Nv2LDB5s2b5+Zx++23l8f6AwCAWiTl4DJz5kwbNmyYDR061M455xybM2eONWzY0ObPn590/JUrV1qvXr1s4MCBrpTm0ksvtQEDBhyxlAYAAOCogktBQYGtWbPG+vTp8+8Z1K3r3q9atSrpND179nTThEFly5YttnTpUuvbt2+xyzlw4IDt2bMn7gUAAFAvlZF37dplhYWF1rRp07jher9x48ak06ikRdNdcMEFFgSBHTp0yEaMGFFiVdHUqVNtypQpqawaAACoBSq8V9GKFSvsvvvus9mzZ7s2MYsXL7YlS5bY3XffXew048ePt927d8deW7durejVBAAANa3EpXHjxpaWlmbbt2+PG6732dnZSaeZOHGiDRo0yK6//nr3vn379rZv3z4bPny4TZgwwVU1JWrQoIF7AQAAlLnEJT093Tp37mzLly+PDTt8+LB736NHj6TT7N+/v0g4UfgRVR0BAABUSImLqCv0kCFDrEuXLtatWzf3jBaVoKiXkQwePNhatGjh2qlIv379XE+k8847zz3zZfPmza4URsPDAAMAAFAhwaV///62c+dOmzRpkm3bts06depkeXl5sQa7+fn5cSUsd9xxh9WpU8f9++mnn9pJJ53kQsu9996b6qIBAEAtVyfwoL5G3aGzsrJcQ93MzMyqXh0AAFBF929+qwgAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgjTIFl9zcXGvVqpVlZGRY9+7dbfXq1SWO/+WXX9rIkSOtWbNm1qBBA2vTpo0tXbq0rOsMAABqqXqpTrBo0SIbM2aMzZkzx4WWWbNmWU5Ojm3atMmaNGlSZPyCggK75JJL3N+ee+45a9GihX388cfWqFGj8voMAACglqgTBEGQygQKK127drWHH37YvT98+LC1bNnSRo0aZePGjSsyvgLOgw8+aBs3brT69euXaSX37NljWVlZtnv3bsvMzCzTPAAAQOWqiPt3SlVFKj1Zs2aN9enT598zqFvXvV+1alXSaV588UXr0aOHqypq2rSptWvXzu677z4rLCwsdjkHDhxwHzb6AgAASCm47Nq1ywUOBZAovd+2bVvSabZs2eKqiDSd2rVMnDjRZsyYYffcc0+xy5k6dapLaOFLJToAAAAV3qtIVUlq3/Loo49a586drX///jZhwgRXhVSc8ePHu2Kl8LV169aKXk0AAFDTGuc2btzY0tLSbPv27XHD9T47OzvpNOpJpLYtmi509tlnuxIaVT2lp6cXmUY9j/QCAAAoc4mLQoZKTZYvXx5XoqL3aseSTK9evWzz5s1uvND777/vAk2y0AIAAFBuVUXqCj137lx78sknbcOGDXbjjTfavn37bOjQoe7vgwcPdlU9If39888/t1tuucUFliVLlrjGuWqsCwAAUKHPcVEblZ07d9qkSZNcdU+nTp0sLy8v1mA3Pz/f9TQKqWHtyy+/bKNHj7YOHTq457goxIwdOzbVRQMAgFou5ee4VAWe4wIAgH+q/DkuAAAAVYngAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAFCzg0tubq61atXKMjIyrHv37rZ69epSTbdw4UKrU6eOXXnllWVZLAAAqOVSDi6LFi2yMWPG2OTJk23t2rXWsWNHy8nJsR07dpQ43UcffWQ/+9nPrHfv3kezvgAAoBZLObjMnDnThg0bZkOHDrVzzjnH5syZYw0bNrT58+cXO01hYaFdc801NmXKFDv99NOPuIwDBw7Ynj174l4AAAApBZeCggJbs2aN9enT598zqFvXvV+1alWx0911113WpEkTu+6660q1nKlTp1pWVlbs1bJly1RWEwAA1FApBZddu3a50pOmTZvGDdf7bdu2JZ3mzTfftHnz5tncuXNLvZzx48fb7t27Y6+tW7emspoAAKCGqleRM9+7d68NGjTIhZbGjRuXeroGDRq4FwAAQJmDi8JHWlqabd++PW643mdnZxcZ/4MPPnCNcvv16xcbdvjw4f+/4Hr1bNOmTda6detUVgEAANRiKVUVpaenW+fOnW358uVxQUTve/ToUWT8tm3b2vr1623dunWx1+WXX24XXXSR+3/argAAgAqtKlJX6CFDhliXLl2sW7duNmvWLNu3b5/rZSSDBw+2Fi1auAa2es5Lu3bt4qZv1KiR+zdxOAAAQLkHl/79+9vOnTtt0qRJrkFup06dLC8vL9ZgNz8/3/U0AgAAKG91giAIrJrTc1zULVo9jDIzM6t6dQAAQBXdvykaAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAANTs4JKbm2utWrWyjIwM6969u61evbrYcefOnWu9e/e2448/3r369OlT4vgAAADlFlwWLVpkY8aMscmTJ9vatWutY8eOlpOTYzt27Eg6/ooVK2zAgAH2+uuv26pVq6xly5Z26aWX2qeffprqogEAQC1XJwiCIJUJVMLStWtXe/jhh937w4cPuzAyatQoGzdu3BGnLywsdCUvmn7w4MFJxzlw4IB7hfbs2eOWsXv3bsvMzExldQEAQBXR/TsrK6tc798plbgUFBTYmjVrXHVPbAZ167r3Kk0pjf3799vBgwfthBNOKHacqVOnug8avhRaAAAAUgouu3btciUmTZs2jRuu99u2bSvVPMaOHWvNmzePCz+Jxo8f79JZ+Nq6dWsqqwkAAGqoepW5sPvvv98WLlzo2r2oYW9xGjRo4F4AAABlDi6NGze2tLQ02759e9xwvc/Ozi5x2unTp7vg8uqrr1qHDh1SWSwAAEDqVUXp6enWuXNnW758eWyYGufqfY8ePYqdbtq0aXb33XdbXl6edenSJZVFAgAAlL2qSF2hhwwZ4gJIt27dbNasWbZv3z4bOnSo+7t6CrVo0cI1sJUHHnjAJk2aZAsWLHDPfgnbwhx77LHuBQAAUGHBpX///rZz504XRhRCOnXq5EpSwga7+fn5rqdR6JFHHnG9ka666qq4+eg5MHfeeWeqiwcAALVYys9xqSn9wAEAQA1/jgsAAEBVIrgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAGwQXAADgDYILAADwBsEFAAB4g+ACAAC8QXABAADeILgAAABvEFwAAIA3CC4AAMAbBBcAAOANggsAAPAGwQUAAHiD4AIAALxBcAEAAN4guAAAAG8QXAAAgDcILgAAwBsEFwAA4A2CCwAAqNnBJTc311q1amUZGRnWvXt3W716dYnjP/vss9a2bVs3fvv27W3p0qVlXV8AAFCLpRxcFi1aZGPGjLHJkyfb2rVrrWPHjpaTk2M7duxIOv7KlSttwIABdt1119k777xjV155pXu9++675bH+AACgFqkTBEGQygQqYenatas9/PDD7v3hw4etZcuWNmrUKBs3blyR8fv372/79u2zl156KTbs/PPPt06dOtmcOXNKtcw9e/ZYVlaW7d692zIzM1NZXQAAUEUq4v5dL5WRCwoKbM2aNTZ+/PjYsLp161qfPn1s1apVSafRcJXQRKmE5oUXXih2OQcOHHCvkD5wuAEAAIAfwvt2imUk5Rdcdu3aZYWFhda0adO44Xq/cePGpNNs27Yt6fgaXpypU6falClTigxXyQ4AAPDLZ5995kpeKj24VBaV6ERLab788ks79dRTLT8/v9w+OMqenhUgt27dSrVdFWNfVB/si+qF/VF9qMbklFNOsRNOOKHc5plScGncuLGlpaXZ9u3b44brfXZ2dtJpNDyV8aVBgwbulUihhYOwetB+YF9UD+yL6oN9Ub2wP6oPNSspt3mlMnJ6erp17tzZli9fHhumxrl636NHj6TTaHh0fFm2bFmx4wMAAJRbVZGqcIYMGWJdunSxbt262axZs1yvoaFDh7q/Dx482Fq0aOHaqcgtt9xiF154oc2YMcMuu+wyW7hwob399tv26KOPprpoAABQy6UcXNS9eefOnTZp0iTXwFbdmvPy8mINcNUOJVok1LNnT1uwYIHdcccddvvtt9uZZ57pehS1a9eu1MtUtZGeG5Os+giVi31RfbAvqg/2RfXC/qjZ+yLl57gAAABUFX6rCAAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACAN6pNcMnNzbVWrVpZRkaG+wXq1atXlzj+s88+a23btnXjt2/f3pYuXVpp61rTpbIv5s6da71797bjjz/evfSDm0fad6i48yKk5yXVqVPHrrzyygpfx9oi1X2hnyoZOXKkNWvWzHUFbdOmDdepKtoXet7YWWedZcccc4z7KYDRo0fb119/XWnrW1O98cYb1q9fP2vevLm73pT048mhFStW2De/+U13Tpxxxhn2xBNPpL7goBpYuHBhkJ6eHsyfPz947733gmHDhgWNGjUKtm/fnnT8P/3pT0FaWlowbdq04G9/+1twxx13BPXr1w/Wr19f6ete06S6LwYOHBjk5uYG77zzTrBhw4bg2muvDbKysoJPPvmk0te9tu+L0Icffhi0aNEi6N27d3DFFVdU2vrWZKnuiwMHDgRdunQJ+vbtG7z55ptun6xYsSJYt25dpa97bd8XTz31VNCgQQP3r/bDyy+/HDRr1iwYPXp0pa97TbN06dJgwoQJweLFi/VYleD5558vcfwtW7YEDRs2DMaMGePu3Q899JC7l+fl5aW03GoRXLp16xaMHDky9r6wsDBo3rx5MHXq1KTjX3311cFll10WN6x79+7BDTfcUOHrWtOlui8SHTp0KDjuuOOCJ598sgLXsnYoy77Q9u/Zs2fw2GOPBUOGDCG4VNG+eOSRR4LTTz89KCgoqMS1rB1S3Rca9+KLL44bphtnr169KnxdaxMrRXC57bbbgnPPPTduWP/+/YOcnJyUllXlVUUFBQW2Zs0aV8UQ0pN39X7VqlVJp9Hw6PiSk5NT7PiouH2RaP/+/Xbw4MFy/SXQ2qis++Kuu+6yJk2a2HXXXVdJa1rzlWVfvPjii+732FRVpKeK60nh9913nxUWFlbimtc8ZdkXenq7pgmrk7Zs2eKq7Pr27Vtp643yvXen/Mj/8rZr1y53Moc/GRDS+40bNyadRj81kGx8DUfl7otEY8eOdfWdiQcnKn5fvPnmmzZv3jxbt25dJa1l7VCWfaGb42uvvWbXXHONu0lu3rzZbrrpJhfq9fhzVN6+GDhwoJvuggsuUA2DHTp0yEaMGOF+ggaVq7h79549e+yrr75ybZBKo8pLXFBz3H///a5R6PPPP+8azaHy7N271wYNGuQaSzdu3LiqV6fWO3z4sCv50o/Jdu7c2f3G24QJE2zOnDlVvWq1jhqDqrRr9uzZtnbtWlu8eLEtWbLE7r777qpeNZRRlZe46CKblpZm27dvjxuu99nZ2Umn0fBUxkfF7YvQ9OnTXXB59dVXrUOHDhW8pjVfqvvigw8+sI8++si18I/ePKVevXq2adMma926dSWsec1TlvNCPYnq16/vpgudffbZ7hunqjvS09MrfL1rorLsi4kTJ7pQf/3117v36oW6b98+Gz58uAuT0R8FRsUq7t6dmZlZ6tIWqfI9phNY30iWL18ed8HVe9URJ6Ph0fFl2bJlxY6PitsXMm3aNPftRb8S3qVLl0pa25ot1X2hRwOsX7/eVROFr8svv9wuuugi9//qAorKOy969erlqofC8Cjvv/++CzSElsrdF2p3lxhOwkDJbwxXrnK7dwfVpHubuqs98cQTrovU8OHDXfe2bdu2ub8PGjQoGDduXFx36Hr16gXTp093XXAnT55Md+gq2hf333+/65r43HPPBf/85z9jr71791bhp6id+yIRvYqqbl/k5+e73nU333xzsGnTpuCll14KmjRpEtxzzz1V+Clq577Q/UH74umnn3bdcV955ZWgdevWrncqjo6u83oUhl6KEzNnznT///HHH7u/az9ofyR2h7711lvdvVuP0vC2O7SoP/cpp5ziboLq7vbWW2/F/nbhhRe6i3DUM888E7Rp08aNr+5VS5YsqYK1rplS2RennnqqO2ATX7pYoPLPiyiCS9Xui5UrV7rHNOgmq67R9957r+uujsrdFwcPHgzuvPNOF1YyMjKCli1bBjfddFPwxRdfVNHa1xyvv/560ut/uP31r/ZH4jSdOnVy+07nxeOPP57ycuvoP+VbGAQAAFAxqryNCwAAQGkRXAAAgDcILgAAwBsEFwAA4A2CCwAA8AbBBQAAeIPgAgAAvEFwAQAA3iC4AAAAbxBcAACANwguAADAfPH/ANdh+73OPhFfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500: Success! Reward: 9.40, Steps: 19\n",
      "Checkpoint saved at episode 500\n",
      "Episode 501: Success! Reward: 10.20, Steps: 7\n",
      "Episode 502: Success! Reward: -3.60, Steps: 21\n",
      "Episode 503: Success! Reward: 9.00, Steps: 15\n",
      "Episode 504: Success! Reward: 8.60, Steps: 18\n",
      "Episode 505: Success! Reward: 10.40, Steps: 2\n",
      "Episode 506: Success! Reward: 9.80, Steps: 8\n",
      "Episode 507: Success! Reward: -2.60, Steps: 21\n",
      "Episode 508: Success! Reward: 9.60, Steps: 15\n",
      "Episode 509: Success! Reward: 9.80, Steps: 2\n",
      "Episode 510: Success! Reward: 9.80, Steps: 17\n",
      "Episode 511: Success! Reward: -2.60, Steps: 21\n",
      "Episode 512: Success! Reward: -3.60, Steps: 21\n",
      "Episode 513: Success! Reward: -3.20, Steps: 21\n",
      "Episode 514: Success! Reward: -1.60, Steps: 21\n",
      "Episode 515: Success! Reward: -3.40, Steps: 21\n",
      "Episode 516: Success! Reward: 10.60, Steps: 5\n",
      "Episode 517: Success! Reward: 9.60, Steps: 4\n",
      "Episode 518: Success! Reward: -2.00, Steps: 21\n",
      "Episode 519: Success! Reward: 8.60, Steps: 15\n",
      "Episode 520: Success! Reward: 9.20, Steps: 7\n",
      "Episode 521: Success! Reward: 8.80, Steps: 11\n",
      "Episode 522: Success! Reward: 10.80, Steps: 6\n",
      "Episode 523: Success! Reward: -3.00, Steps: 21\n",
      "Episode 524: Success! Reward: 9.80, Steps: 2\n",
      "Episode 525: Success! Reward: 7.80, Steps: 17\n",
      "Episode 526: Success! Reward: -2.40, Steps: 21\n",
      "Episode 527: Success! Reward: 8.80, Steps: 12\n",
      "Episode 528: Success! Reward: 8.80, Steps: 9\n",
      "Episode 529: Success! Reward: -4.00, Steps: 21\n",
      "Episode 530: Success! Reward: -3.20, Steps: 21\n",
      "Episode 531: Success! Reward: 9.20, Steps: 13\n",
      "Episode 532: Success! Reward: -1.60, Steps: 21\n",
      "Episode 533: Success! Reward: -3.00, Steps: 21\n",
      "Episode 534: Success! Reward: 10.40, Steps: 2\n",
      "Episode 535: Success! Reward: 10.00, Steps: 1\n",
      "Episode 536: Success! Reward: -2.60, Steps: 21\n",
      "Episode 537: Success! Reward: 9.00, Steps: 16\n",
      "Episode 538: Success! Reward: 10.00, Steps: 1\n",
      "Episode 539: Success! Reward: 8.00, Steps: 21\n",
      "Episode 540: Success! Reward: 10.40, Steps: 2\n",
      "Episode 541: Success! Reward: 10.00, Steps: 1\n",
      "Episode 542: Success! Reward: -2.60, Steps: 21\n",
      "Episode 543: Success! Reward: 9.40, Steps: 8\n",
      "Episode 544: Success! Reward: -3.40, Steps: 21\n",
      "Episode 545: Success! Reward: 9.40, Steps: 18\n",
      "Episode 546: Success! Reward: 9.40, Steps: 4\n",
      "Episode 547: Success! Reward: 10.00, Steps: 1\n",
      "Episode 548: Success! Reward: 9.80, Steps: 2\n",
      "Episode 549: Success! Reward: -3.80, Steps: 21\n",
      "Episode 550/24000 (Stage 2, Ep 70/720)\n",
      "Grid: 6x6, Obstacles: 2, Pattern: random\n",
      "Epsilon: 0.8969, Memory: 5768/50000\n",
      "Episode 550: Success! Reward: 10.80, Steps: 8\n",
      "Episode 551: Success! Reward: 9.20, Steps: 8\n",
      "Episode 552: Success! Reward: -1.40, Steps: 21\n",
      "Episode 553: Success! Reward: 10.00, Steps: 1\n",
      "Episode 554: Success! Reward: -3.40, Steps: 21\n",
      "Episode 555: Success! Reward: -3.60, Steps: 21\n",
      "Episode 556: Success! Reward: -2.80, Steps: 21\n",
      "Episode 557: Success! Reward: 7.80, Steps: 19\n",
      "Episode 558: Success! Reward: 8.60, Steps: 13\n",
      "Episode 559: Success! Reward: -3.00, Steps: 21\n",
      "Episode 560: Success! Reward: 9.20, Steps: 15\n",
      "Episode 561: Success! Reward: -1.40, Steps: 21\n",
      "Episode 562: Success! Reward: 8.80, Steps: 10\n",
      "Episode 563: Success! Reward: -2.60, Steps: 21\n",
      "Episode 564: Success! Reward: 10.40, Steps: 2\n",
      "Episode 565: Success! Reward: 9.80, Steps: 3\n",
      "Target network updated at step 6000\n",
      "Episode 566: Success! Reward: -2.40, Steps: 21\n",
      "Episode 567: Success! Reward: 9.40, Steps: 6\n",
      "Episode 568: Success! Reward: -2.40, Steps: 21\n",
      "Episode 569: Success! Reward: 10.20, Steps: 12\n",
      "Episode 570: Success! Reward: -3.40, Steps: 21\n",
      "Episode 571: Success! Reward: -2.40, Steps: 21\n",
      "Episode 572: Success! Reward: 8.20, Steps: 13\n",
      "Episode 573: Success! Reward: 8.80, Steps: 19\n",
      "Episode 574: Success! Reward: 9.00, Steps: 13\n",
      "Episode 575: Success! Reward: 9.20, Steps: 5\n",
      "Episode 576: Success! Reward: 10.40, Steps: 2\n",
      "Episode 577: Success! Reward: 10.00, Steps: 1\n",
      "Episode 578: Success! Reward: 9.00, Steps: 14\n",
      "Episode 579: Success! Reward: 9.60, Steps: 14\n",
      "Episode 580: Success! Reward: 9.80, Steps: 7\n",
      "Episode 581: Success! Reward: 8.20, Steps: 16\n",
      "Episode 582: Success! Reward: 9.80, Steps: 10\n",
      "Episode 583: Success! Reward: -1.40, Steps: 21\n",
      "Episode 584: Success! Reward: 10.40, Steps: 2\n",
      "Episode 585: Success! Reward: -2.60, Steps: 21\n",
      "Episode 586: Success! Reward: 9.40, Steps: 8\n",
      "Episode 587: Success! Reward: 9.40, Steps: 20\n",
      "Episode 588: Success! Reward: 10.40, Steps: 6\n",
      "Episode 589: Success! Reward: 8.40, Steps: 18\n",
      "Episode 590: Success! Reward: -1.00, Steps: 21\n",
      "Episode 591: Success! Reward: 9.60, Steps: 7\n",
      "Episode 592: Success! Reward: 9.60, Steps: 4\n",
      "Episode 593: Success! Reward: 10.20, Steps: 3\n",
      "Episode 594: Success! Reward: 9.00, Steps: 12\n",
      "Episode 595: Success! Reward: 9.60, Steps: 11\n",
      "Episode 596: Success! Reward: 9.60, Steps: 9\n",
      "Episode 597: Success! Reward: 10.00, Steps: 6\n",
      "Episode 598: Success! Reward: 9.80, Steps: 9\n",
      "Episode 599: Success! Reward: -3.00, Steps: 21\n",
      "Episode 600/24000 (Stage 2, Ep 120/720)\n",
      "Grid: 6x6, Obstacles: 4, Pattern: random\n",
      "Epsilon: 0.8946, Memory: 6409/50000\n",
      "Episode 600: Success! Reward: -2.60, Steps: 21\n",
      "\n",
      "Running evaluation...\n",
      "Evaluating on grid 10x10, 5 obstacles, random pattern\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 446\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m success_rate, avg_reward\n\u001b[0;32m    445\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24000\u001b[39m\n\u001b[1;32m--> 446\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_compound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m model \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# Save final model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 248\u001b[0m, in \u001b[0;36mtrain_compound\u001b[1;34m(epochs, batch_size, memory_size, render_interval)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode_count \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m episode_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 248\u001b[0m     eval_success_rate, eval_avg_reward \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes_per_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_episodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m     success_rates\u001b[38;5;241m.\u001b[39mappend(eval_success_rate)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation - Success rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_success_rate\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Avg reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_avg_reward\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 417\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, env_configs, episodes_per_env)\u001b[0m\n\u001b[0;32m    414\u001b[0m steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# Get action from model - no exploration during evaluation\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(q_values)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Take action\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mBalancedDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Only use dropout during training\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Enhanced Compound Training Function\n",
    "def train_compound(epochs=24000, batch_size=64, memory_size=150000, render_interval=500):\n",
    "    # Initialize metrics tracking\n",
    "    losses = []\n",
    "    all_rewards = []\n",
    "    avg_rewards = []\n",
    "    success_rates = []\n",
    "    best_eval_score = float('-inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Create replay memory\n",
    "    replay = deque(maxlen=memory_size)\n",
    "    \n",
    "    # Create model checkpoint directory\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    # Initialize epsilon for exploration\n",
    "    epsilon = 1.0\n",
    "    epsilon_min = 0.05\n",
    "    epsilon_decay_rate = 0.99995  # Slower decay for more exploration\n",
    "    \n",
    "    # Enhanced curriculum with more intermediate stages and higher obstacle density\n",
    "    curriculum = [\n",
    "        # Stage 1: Very small grids (5x5) with minimal obstacles\n",
    "        {'episodes': int(epochs * 0.02), 'grid_sizes': [5], 'obstacles': (1, 3), 'patterns': ['random'], \n",
    "        'max_steps_factor': 3.5, 'epsilon_min': 0.2},\n",
    "        \n",
    "        # Stage 2: Small grids (6x6) with increasing obstacles\n",
    "        {'episodes': int(epochs * 0.03), 'grid_sizes': [6], 'obstacles': (2, 4), 'patterns': ['random'], \n",
    "        'max_steps_factor': 3.5, 'epsilon_min': 0.18},\n",
    "        \n",
    "        # Stage 3: Small grids (7x7, 8x8) with more obstacles\n",
    "        {'episodes': int(epochs * 0.04), 'grid_sizes': [7, 8], 'obstacles': (3, 6), 'patterns': ['random'], \n",
    "        'max_steps_factor': 3.2, 'epsilon_min': 0.16},\n",
    "        \n",
    "        # Stage 4: Early medium grids (9x9, 10x10) with moderate obstacles\n",
    "        {'episodes': int(epochs * 0.05), 'grid_sizes': [9, 10], 'obstacles': (4, 8), 'patterns': ['random'], \n",
    "        'max_steps_factor': 3.0, 'epsilon_min': 0.15},\n",
    "        \n",
    "        # Stage 5: Medium grids (11x11, 12x12) with clusters\n",
    "        {'episodes': int(epochs * 0.05), 'grid_sizes': [11, 12], 'obstacles': (5, 10), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.8, 'epsilon_min': 0.14},\n",
    "        \n",
    "        # Stage 6: Larger medium grids (13x13, 14x14) with more obstacles\n",
    "        {'episodes': int(epochs * 0.06), 'grid_sizes': [13, 14], 'obstacles': (8, 14), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.8, 'epsilon_min': 0.13},\n",
    "        \n",
    "        # Stage 7: Medium-large grids (15x15, 16x16) with substantial obstacles \n",
    "        {'episodes': int(epochs * 0.07), 'grid_sizes': [15, 16], 'obstacles': (10, 15), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.6, 'epsilon_min': 0.12},\n",
    "        \n",
    "        # Stage 8: Large medium grids (17x17, 18x18) introducing walls pattern\n",
    "        {'episodes': int(epochs * 0.07), 'grid_sizes': [17, 18], 'obstacles': (12, 16), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.6, 'epsilon_min': 0.11},\n",
    "        \n",
    "        # Stage 9: First large grids (19x19, 20x20) with challenging obstacles\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [19, 20], 'obstacles': (15, 18), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.5, 'epsilon_min': 0.10},\n",
    "        \n",
    "        # Stage 10: Growing large grids (22x22, 24x24) with dense obstacles\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [22, 24], 'obstacles': (18, 20), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.4, 'epsilon_min': 0.09},\n",
    "        \n",
    "        # Stage 11: Large grids (25x25, 27x27) with very high obstacle count\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [25, 27], 'obstacles': (21, 24), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.3, 'epsilon_min': 0.08},\n",
    "        \n",
    "        # Stage 12: Very large grids (30x30) with maze-like obstacles\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [30], 'obstacles': (24, 30), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.2, 'epsilon_min': 0.07},\n",
    "        \n",
    "        # Stage 13: Larger grids (33x33, 35x35) with high obstacle density\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [33, 35], 'obstacles': (25, 35), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.1, 'epsilon_min': 0.06},\n",
    "        \n",
    "        # Stage 14: Extremely large grids (38x38) with extreme obstacles\n",
    "        {'episodes': int(epochs * 0.08), 'grid_sizes': [38], 'obstacles': (30, 40), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.0, 'epsilon_min': 0.055},\n",
    "        \n",
    "        # Stage 15: Maximum challenge (40x40) with highest obstacle density\n",
    "        {'episodes': int(epochs * 0.13), 'grid_sizes': [40], 'obstacles': (20, 50), 'patterns': ['random'],\n",
    "        'max_steps_factor': 2.0, 'epsilon_min': 0.05}\n",
    "    ]\n",
    "    \n",
    "    # Setup for periodic evaluation\n",
    "    eval_interval = 200  # Evaluate model every 200 episodes\n",
    "    eval_episodes = 20   # Number of episodes to use for evaluation\n",
    "    \n",
    "    # Validation environments for consistent evaluation\n",
    "    validation_envs = [\n",
    "        # Simple validation environments\n",
    "        (10, 5, 'random'),   # (grid_size, obstacles, pattern)\n",
    "        (15, 10, 'random'),\n",
    "        (20, 15, 'clusters'),\n",
    "        (30, 20, 'walls'),\n",
    "        (40, 30, 'random')\n",
    "    ]\n",
    "\n",
    "    # Define sync frequency for target network updates (steps)\n",
    "    sync_freq = 1000\n",
    "    \n",
    "    # Global step counter\n",
    "    global_step = 0\n",
    "    episode_count = 0\n",
    "    \n",
    "    print(\"Starting compound training with curriculum learning...\")\n",
    "    \n",
    "    # Loop through curriculum stages\n",
    "    for stage_idx, stage in enumerate(curriculum):\n",
    "        print(f\"\\n===== Starting Stage {stage_idx + 1}/{len(curriculum)} =====\")\n",
    "        print(f\"Grid sizes: {stage['grid_sizes']}\")\n",
    "        print(f\"Obstacles: {stage['obstacles']}\")\n",
    "        print(f\"Patterns: {stage['patterns']}\")\n",
    "        print(f\"Episodes: {stage['episodes']}\")\n",
    "        \n",
    "        # Update epsilon min for this stage\n",
    "        stage_epsilon_min = stage['epsilon_min']\n",
    "        \n",
    "        # Reset epsilon for new stage if needed (optional - keep this line if you want epsilon reset per stage)\n",
    "        epsilon = max(1.0 - stage_idx * 0.1, 0.5)  # Start with less exploration in later stages\n",
    "        \n",
    "        # Track episodes in this stage\n",
    "        stage_episodes = 0\n",
    "        \n",
    "        # Continue until we've completed the designated episodes for this stage\n",
    "        while stage_episodes < stage['episodes'] and episode_count < epochs:\n",
    "            # Select random parameters for this episode\n",
    "            grid_size = random.choice(stage['grid_sizes'])\n",
    "            num_obstacles = random.randint(stage['obstacles'][0], stage['obstacles'][1])\n",
    "            pattern = random.choice(stage['patterns'])\n",
    "            episode_seed = episode_count + random.randint(10000, 50000)\n",
    "            \n",
    "            # Create environment for this episode\n",
    "            max_steps = int(grid_size * stage['max_steps_factor'])  # Scale max steps with grid size\n",
    "            game = Gridworld(size=grid_size, mode=pattern, num_obstacles=num_obstacles, max_steps=max_steps, random_seed=episode_seed)\n",
    "            \n",
    "            # Initialize state\n",
    "            state = game.reset()\n",
    "            state = torch.from_numpy(state).float().unsqueeze(0)  # Add batch dimension\n",
    "            \n",
    "            done = False\n",
    "            steps = 0\n",
    "            episode_reward = 0\n",
    "            success = False\n",
    "            \n",
    "            # Display info periodically\n",
    "            should_render = (episode_count % render_interval == 0)\n",
    "            \n",
    "            if episode_count % 50 == 0:\n",
    "                print(f\"Episode {episode_count}/{epochs} (Stage {stage_idx+1}, Ep {stage_episodes}/{stage['episodes']})\")\n",
    "                print(f\"Grid: {grid_size}x{grid_size}, Obstacles: {num_obstacles}, Pattern: {pattern}\")\n",
    "                print(f\"Epsilon: {epsilon:.4f}, Memory: {len(replay)}/{memory_size}\")\n",
    "            \n",
    "            # Run episode\n",
    "            while not done and steps < max_steps:\n",
    "                steps += 1\n",
    "                global_step += 1\n",
    "                \n",
    "                # Epislon-greedy action selection\n",
    "                if random.random() < epsilon:\n",
    "                    action = random.randint(0, 3)  # Random action\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        q_values = model(state)\n",
    "                        action = torch.argmax(q_values).item()  # Greedy action\n",
    "                \n",
    "                # Take action in environment\n",
    "                next_state, reward, done, info = game.step(action)\n",
    "                next_state = torch.from_numpy(next_state).float().unsqueeze(0)\n",
    "                \n",
    "                # Record success if goal reached\n",
    "                if reward > 0:  # Assuming positive reward means goal reached\n",
    "                    success = True\n",
    "                \n",
    "                # Store in replay memory\n",
    "                replay.append((state, action, reward, next_state, done))\n",
    "                \n",
    "                # Update state and accumulate reward\n",
    "                state = next_state\n",
    "                episode_reward += reward\n",
    "                \n",
    "                # Render if needed\n",
    "                if should_render and steps % 5 == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    game.render()\n",
    "                    plt.title(f\"Stage {stage_idx+1}, Episode {episode_count}, Step {steps}, Reward: {episode_reward:.2f}\")\n",
    "                    plt.pause(0.1)\n",
    "                \n",
    "                # Training step (if we have enough samples)\n",
    "                if len(replay) >= batch_size:\n",
    "                    # Sample mini-batch\n",
    "                    minibatch = random.sample(replay, batch_size)\n",
    "                    \n",
    "                    # Extract batch components\n",
    "                    state_batch = torch.cat([s1 for (s1, _, _, _, _) in minibatch])\n",
    "                    action_batch = torch.tensor([a for (_, a, _, _, _) in minibatch], dtype=torch.long)\n",
    "                    reward_batch = torch.tensor([r for (_, _, r, _, _) in minibatch], dtype=torch.float)\n",
    "                    next_state_batch = torch.cat([s2 for (_, _, _, s2, _) in minibatch])\n",
    "                    done_batch = torch.tensor([d for (_, _, _, _, d) in minibatch], dtype=torch.float)\n",
    "                    \n",
    "                    # Compute current Q values\n",
    "                    current_Q = model(state_batch).gather(1, action_batch.unsqueeze(1)).squeeze(1)\n",
    "                    \n",
    "                    # Double DQN: Use online network to select actions, target network to evaluate\n",
    "                    with torch.no_grad():\n",
    "                        # Find best actions using online model\n",
    "                        best_actions = model(next_state_batch).max(1)[1].unsqueeze(1)\n",
    "                        # Evaluate those actions using target model\n",
    "                        next_Q = model2(next_state_batch).gather(1, best_actions).squeeze(1)\n",
    "                        # Compute target Q values\n",
    "                        target_Q = reward_batch + gamma * next_Q * (1 - done_batch)\n",
    "                    \n",
    "                    # Compute loss and update model\n",
    "                    loss = loss_fn(current_Q, target_Q)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    # Gradient clipping to prevent exploding gradients\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # Store loss\n",
    "                    losses.append(loss.item())\n",
    "                \n",
    "                # Update target network\n",
    "                if global_step % sync_freq == 0:\n",
    "                    model2.load_state_dict(model.state_dict())\n",
    "                    print(f\"Target network updated at step {global_step}\")\n",
    "            \n",
    "            # Episode completed\n",
    "            all_rewards.append(episode_reward)\n",
    "            \n",
    "            # Calculate running average reward\n",
    "            window_size = min(100, len(all_rewards))\n",
    "            avg_reward = sum(all_rewards[-window_size:]) / window_size\n",
    "            avg_rewards.append(avg_reward)\n",
    "            \n",
    "            # Print episode results\n",
    "            if success:\n",
    "                print(f\"Episode {episode_count}: Success! Reward: {episode_reward:.2f}, Steps: {steps}\")\n",
    "            elif episode_count % 50 == 0:\n",
    "                print(f\"Episode {episode_count}: Failed. Reward: {episode_reward:.2f}, Steps: {steps}\")\n",
    "            \n",
    "            # Evaluate periodically\n",
    "            if episode_count % eval_interval == 0 and episode_count > 0:\n",
    "                print(\"\\nRunning evaluation...\")\n",
    "                eval_success_rate, eval_avg_reward = evaluate_model(model, validation_envs, episodes_per_env=eval_episodes)\n",
    "                success_rates.append(eval_success_rate)\n",
    "                \n",
    "                print(f\"Evaluation - Success rate: {eval_success_rate:.2f}, Avg reward: {eval_avg_reward:.2f}\")\n",
    "                \n",
    "                # Save best model\n",
    "                eval_score = eval_success_rate * 10 + eval_avg_reward  # Combined metric\n",
    "                if eval_score > best_eval_score:\n",
    "                    best_eval_score = eval_score\n",
    "                    best_model_state = model.state_dict().copy()\n",
    "                    print(f\"New best model with eval score {eval_score:.2f}!\")\n",
    "                    \n",
    "                    # Save best model\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'epsilon': epsilon,\n",
    "                        'episode': episode_count,\n",
    "                        'eval_score': eval_score,\n",
    "                        'success_rate': eval_success_rate,\n",
    "                        'avg_reward': eval_avg_reward,\n",
    "                    }, 'models/dqn_best.pth')\n",
    "            \n",
    "            # Checkpoint model periodically\n",
    "            if episode_count % 500 == 0 and episode_count > 0:\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'epsilon': epsilon,\n",
    "                    'episode': episode_count,\n",
    "                    'stage': stage_idx,\n",
    "                    'all_rewards': all_rewards,\n",
    "                    'avg_rewards': avg_rewards,\n",
    "                    'losses': losses,\n",
    "                }, f'models/dqn_checkpoint_ep{episode_count}.pth')\n",
    "                print(f\"Checkpoint saved at episode {episode_count}\")\n",
    "            \n",
    "            # Decay epsilon - but respect the minimum for this stage\n",
    "            epsilon = max(stage_epsilon_min, epsilon * epsilon_decay_rate)\n",
    "            \n",
    "            # Increment counters\n",
    "            episode_count += 1\n",
    "            stage_episodes += 1\n",
    "        \n",
    "        # End of stage - evaluate and save stage model\n",
    "        print(f\"\\n===== Completed Stage {stage_idx + 1}/{len(curriculum)} =====\")\n",
    "        stage_eval_success, stage_eval_reward = evaluate_model(model, validation_envs, episodes_per_env=eval_episodes)\n",
    "        \n",
    "        print(f\"Stage {stage_idx+1} Evaluation - Success rate: {stage_eval_success:.2f}, Avg reward: {stage_eval_reward:.2f}\")\n",
    "        \n",
    "        # Save stage model\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epsilon': epsilon,\n",
    "            'episode': episode_count,\n",
    "            'stage': stage_idx,\n",
    "            'success_rate': stage_eval_success,\n",
    "            'avg_reward': stage_eval_reward,\n",
    "        }, f'models/dqn_stage{stage_idx+1}.pth')\n",
    "    \n",
    "    # Training complete - final evaluation with best model\n",
    "    print(\"\\n===== Training Complete =====\")\n",
    "    \n",
    "    # Load best model for final evaluation\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model for final evaluation\")\n",
    "    \n",
    "    # Comprehensive final evaluation\n",
    "    print(\"\\nRunning final evaluation...\")\n",
    "    final_success_rate, final_avg_reward = evaluate_model(model, validation_envs, episodes_per_env=50)  # More episodes for final eval\n",
    "    \n",
    "    print(f\"Final Evaluation - Success rate: {final_success_rate:.2f}, Avg reward: {final_avg_reward:.2f}\")\n",
    "    \n",
    "    # Plot training metrics\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(all_rewards)\n",
    "    plt.title('Episode Rewards')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(avg_rewards)\n",
    "    plt.title('Average Reward (100 episodes)')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Reward')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(losses[-10000:])  # Plot last 10000 losses to see recent trends\n",
    "    plt.title('Training Loss (last 10000 updates)')\n",
    "    plt.xlabel('Update Step')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    if success_rates:\n",
    "        plt.subplot(2, 2, 4)\n",
    "        # Generate x values that match exactly with the length of success_rates\n",
    "        eval_points = np.arange(eval_interval, eval_interval * (len(success_rates) + 1), eval_interval)[:len(success_rates)]\n",
    "        plt.plot(eval_points, success_rates)\n",
    "        plt.title('Evaluation Success Rate')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Success Rate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('models/training_curves.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epsilon': epsilon,\n",
    "        'episode': episode_count,\n",
    "        'final_success_rate': final_success_rate,\n",
    "        'final_avg_reward': final_avg_reward,\n",
    "    }, 'models/dqn_final.pth')\n",
    "    \n",
    "    # Return relevant data for analysis\n",
    "    return {\n",
    "        'model': model,\n",
    "        'rewards': all_rewards,\n",
    "        'avg_rewards': avg_rewards,\n",
    "        'losses': losses,\n",
    "        'success_rates': success_rates,\n",
    "        'final_success_rate': final_success_rate,\n",
    "        'final_avg_reward': final_avg_reward,\n",
    "        'best_eval_score': best_eval_score\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, env_configs, episodes_per_env=10):\n",
    "    \"\"\"\n",
    "    Evaluate model on multiple environment configurations\n",
    "    \n",
    "    Args:\n",
    "        model: The DQN model to evaluate\n",
    "        env_configs: List of tuples (grid_size, num_obstacles, pattern)\n",
    "        episodes_per_env: Number of episodes to run for each environment config\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (success_rate, average_reward)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    success_count = 0\n",
    "    total_rewards = []\n",
    "    total_episodes = len(env_configs) * episodes_per_env\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for grid_size, num_obstacles, pattern in env_configs:\n",
    "            print(f\"Evaluating on grid {grid_size}x{grid_size}, {num_obstacles} obstacles, {pattern} pattern\")\n",
    "            \n",
    "            for ep in range(episodes_per_env):\n",
    "                # Create environment\n",
    "                max_steps = grid_size * 2\n",
    "                game = Gridworld(size=grid_size, mode=pattern, num_obstacles=num_obstacles, max_steps=max_steps)\n",
    "                \n",
    "                state = game.reset()\n",
    "                state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "                \n",
    "                done = False\n",
    "                steps = 0\n",
    "                episode_reward = 0\n",
    "                success = False\n",
    "                \n",
    "                while not done and steps < max_steps:\n",
    "                    steps += 1\n",
    "                    \n",
    "                    # Get action from model - no exploration during evaluation\n",
    "                    q_values = model(state)\n",
    "                    action = torch.argmax(q_values).item()\n",
    "                    \n",
    "                    # Take action\n",
    "                    next_state, reward, done, info = game.step(action)\n",
    "                    next_state = torch.from_numpy(next_state).float().unsqueeze(0)\n",
    "                    \n",
    "                    # Update state and reward\n",
    "                    state = next_state\n",
    "                    episode_reward += reward\n",
    "                    \n",
    "                    # Check for success\n",
    "                    if reward > 0:  # Positive reward means goal reached\n",
    "                        success = True\n",
    "                        break\n",
    "                \n",
    "                # Record results\n",
    "                if success:\n",
    "                    success_count += 1\n",
    "                total_rewards.append(episode_reward)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    success_rate = success_count / total_episodes\n",
    "    avg_reward = sum(total_rewards) / len(total_rewards)\n",
    "    \n",
    "    model.train()  # Set model back to training mode\n",
    "    return success_rate, avg_reward\n",
    "\n",
    "epochs = 24000\n",
    "results = train_compound(epochs=epochs, batch_size=64, memory_size=50000, render_interval=500)\n",
    "model = results['model']\n",
    "\n",
    "# Save final model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epsilon': epsilon,\n",
    "    'episode': epochs,\n",
    "}, 'models/dqn_final.pth')\n",
    "print(\"Training completed. Final model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TEST RESULTS =====\n",
      "Agent Type: DQN\n",
      "Random Seed: 1\n",
      "Goal Reached: Yes\n",
      "Total Timesteps: 16\n",
      "Total Distance: 16\n",
      "Unique Locations: 17\n",
      "Revisited Locations: 0\n",
      "Shannon Entropy (states): 0.956\n",
      "Grid Dimensions: 40x40\n",
      "\n",
      "Action distribution:\n",
      "  UP: 11 times (68.8%)\n",
      "  RIGHT: 5 times (31.2%)\n",
      "\n",
      "Most visited states:\n",
      "  (25, 26): 1 visits\n",
      "  (25, 25): 1 visits\n",
      "  (25, 24): 1 visits\n",
      "  (25, 23): 1 visits\n",
      "  (25, 22): 1 visits\n",
      "Episode 2:  SUCCESS - Seed: 2, Timesteps: 39, Distance: 39, Shannon Entropy: 0.95\n",
      "Episode 3:  SUCCESS - Seed: 3, Timesteps: 51, Distance: 51, Shannon Entropy: 0.95\n",
      "Episode 4:  SUCCESS - Seed: 4, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 5:  SUCCESS - Seed: 5, Timesteps: 21, Distance: 21, Shannon Entropy: 0.96\n",
      "Episode 6:  FAILED - Seed: 6, Timesteps: 200, Distance: 6, Shannon Entropy: 1.69\n",
      "Episode 7:  FAILED - Seed: 7, Timesteps: 200, Distance: 9, Shannon Entropy: 1.65\n",
      "Episode 8:  FAILED - Seed: 8, Timesteps: 200, Distance: 29, Shannon Entropy: 1.47\n",
      "Episode 9:  SUCCESS - Seed: 9, Timesteps: 47, Distance: 47, Shannon Entropy: 0.95\n",
      "Episode 10:  SUCCESS - Seed: 10, Timesteps: 9, Distance: 9, Shannon Entropy: 0.96\n",
      "Episode 11:  SUCCESS - Seed: 11, Timesteps: 25, Distance: 25, Shannon Entropy: 0.95\n",
      "Episode 12:  FAILED - Seed: 12, Timesteps: 200, Distance: 3, Shannon Entropy: 1.74\n",
      "Episode 13:  SUCCESS - Seed: 13, Timesteps: 29, Distance: 29, Shannon Entropy: 0.95\n",
      "Episode 14:  FAILED - Seed: 14, Timesteps: 200, Distance: 24, Shannon Entropy: 1.51\n",
      "Episode 15:  FAILED - Seed: 15, Timesteps: 200, Distance: 2, Shannon Entropy: 1.75\n",
      "Episode 16:  FAILED - Seed: 16, Timesteps: 200, Distance: 9, Shannon Entropy: 1.65\n",
      "Episode 17:  FAILED - Seed: 17, Timesteps: 200, Distance: 25, Shannon Entropy: 1.50\n",
      "Episode 18:  SUCCESS - Seed: 18, Timesteps: 5, Distance: 5, Shannon Entropy: 0.96\n",
      "Episode 19:  SUCCESS - Seed: 19, Timesteps: 9, Distance: 9, Shannon Entropy: 0.96\n",
      "Episode 20:  SUCCESS - Seed: 20, Timesteps: 27, Distance: 27, Shannon Entropy: 0.95\n",
      "Episode 21:  SUCCESS - Seed: 21, Timesteps: 23, Distance: 23, Shannon Entropy: 0.95\n",
      "Episode 22:  FAILED - Seed: 22, Timesteps: 200, Distance: 3, Shannon Entropy: 1.74\n",
      "Episode 23:  SUCCESS - Seed: 23, Timesteps: 200, Distance: 200, Shannon Entropy: 1.34\n",
      "Episode 24:  FAILED - Seed: 24, Timesteps: 200, Distance: 3, Shannon Entropy: 1.74\n",
      "Episode 25:  FAILED - Seed: 25, Timesteps: 200, Distance: 2, Shannon Entropy: 1.75\n",
      "Episode 26:  FAILED - Seed: 26, Timesteps: 200, Distance: 9, Shannon Entropy: 1.65\n",
      "Episode 27:  SUCCESS - Seed: 27, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 28:  SUCCESS - Seed: 28, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 29:  FAILED - Seed: 29, Timesteps: 200, Distance: 22, Shannon Entropy: 1.52\n",
      "Episode 30:  SUCCESS - Seed: 30, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 31:  SUCCESS - Seed: 31, Timesteps: 35, Distance: 35, Shannon Entropy: 0.95\n",
      "Episode 32:  SUCCESS - Seed: 32, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 33:  SUCCESS - Seed: 33, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 34:  SUCCESS - Seed: 34, Timesteps: 13, Distance: 13, Shannon Entropy: 0.96\n",
      "Episode 35:  SUCCESS - Seed: 35, Timesteps: 37, Distance: 37, Shannon Entropy: 0.95\n",
      "Episode 36:  SUCCESS - Seed: 36, Timesteps: 24, Distance: 24, Shannon Entropy: 0.95\n",
      "Episode 37:  SUCCESS - Seed: 37, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 38:  SUCCESS - Seed: 38, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 39:  SUCCESS - Seed: 39, Timesteps: 45, Distance: 45, Shannon Entropy: 0.95\n",
      "Episode 40:  SUCCESS - Seed: 40, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 41:  SUCCESS - Seed: 41, Timesteps: 8, Distance: 8, Shannon Entropy: 0.96\n",
      "Episode 42:  SUCCESS - Seed: 42, Timesteps: 2, Distance: 2, Shannon Entropy: 0.96\n",
      "Episode 43:  SUCCESS - Seed: 43, Timesteps: 28, Distance: 28, Shannon Entropy: 0.95\n",
      "Episode 44:  SUCCESS - Seed: 44, Timesteps: 200, Distance: 200, Shannon Entropy: 1.35\n",
      "Episode 45:  SUCCESS - Seed: 45, Timesteps: 40, Distance: 40, Shannon Entropy: 0.95\n",
      "Episode 46:  SUCCESS - Seed: 46, Timesteps: 43, Distance: 43, Shannon Entropy: 0.95\n",
      "Episode 47:  FAILED - Seed: 47, Timesteps: 200, Distance: 200, Shannon Entropy: 1.29\n",
      "Episode 48:  SUCCESS - Seed: 48, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 49:  FAILED - Seed: 49, Timesteps: 200, Distance: 200, Shannon Entropy: 1.35\n",
      "Episode 50:  SUCCESS - Seed: 50, Timesteps: 14, Distance: 14, Shannon Entropy: 0.96\n",
      "Episode 51:  SUCCESS - Seed: 51, Timesteps: 23, Distance: 23, Shannon Entropy: 0.95\n",
      "Episode 52:  SUCCESS - Seed: 52, Timesteps: 40, Distance: 40, Shannon Entropy: 0.95\n",
      "Episode 53:  FAILED - Seed: 53, Timesteps: 200, Distance: 14, Shannon Entropy: 1.60\n",
      "Episode 54:  SUCCESS - Seed: 54, Timesteps: 42, Distance: 42, Shannon Entropy: 0.95\n",
      "Episode 55:  SUCCESS - Seed: 55, Timesteps: 12, Distance: 12, Shannon Entropy: 0.96\n",
      "Episode 56:  FAILED - Seed: 56, Timesteps: 200, Distance: 25, Shannon Entropy: 1.50\n",
      "Episode 57:  SUCCESS - Seed: 57, Timesteps: 6, Distance: 6, Shannon Entropy: 0.96\n",
      "Episode 58:  FAILED - Seed: 58, Timesteps: 200, Distance: 19, Shannon Entropy: 1.55\n",
      "Episode 59:  SUCCESS - Seed: 59, Timesteps: 39, Distance: 39, Shannon Entropy: 0.95\n",
      "Episode 60:  SUCCESS - Seed: 60, Timesteps: 24, Distance: 24, Shannon Entropy: 0.95\n",
      "Episode 61:  SUCCESS - Seed: 61, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 62:  FAILED - Seed: 62, Timesteps: 200, Distance: 3, Shannon Entropy: 1.74\n",
      "Episode 63:  SUCCESS - Seed: 63, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 64:  SUCCESS - Seed: 64, Timesteps: 47, Distance: 47, Shannon Entropy: 0.95\n",
      "Episode 65:  FAILED - Seed: 65, Timesteps: 200, Distance: 200, Shannon Entropy: 1.30\n",
      "Episode 66:  SUCCESS - Seed: 66, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 67:  SUCCESS - Seed: 67, Timesteps: 15, Distance: 15, Shannon Entropy: 0.96\n",
      "Episode 68:  SUCCESS - Seed: 68, Timesteps: 26, Distance: 26, Shannon Entropy: 0.95\n",
      "Episode 69:  SUCCESS - Seed: 69, Timesteps: 32, Distance: 32, Shannon Entropy: 0.95\n",
      "Episode 70:  FAILED - Seed: 70, Timesteps: 200, Distance: 2, Shannon Entropy: 1.75\n",
      "Episode 71:  SUCCESS - Seed: 71, Timesteps: 25, Distance: 25, Shannon Entropy: 0.95\n",
      "Episode 72:  SUCCESS - Seed: 72, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 73:  FAILED - Seed: 73, Timesteps: 200, Distance: 29, Shannon Entropy: 1.47\n",
      "Episode 74:  FAILED - Seed: 74, Timesteps: 200, Distance: 5, Shannon Entropy: 1.71\n",
      "Episode 75:  SUCCESS - Seed: 75, Timesteps: 15, Distance: 15, Shannon Entropy: 0.96\n",
      "Episode 76:  SUCCESS - Seed: 76, Timesteps: 15, Distance: 15, Shannon Entropy: 0.96\n",
      "Episode 77:  SUCCESS - Seed: 77, Timesteps: 21, Distance: 21, Shannon Entropy: 0.96\n",
      "Episode 78:  SUCCESS - Seed: 78, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 79:  SUCCESS - Seed: 79, Timesteps: 28, Distance: 28, Shannon Entropy: 0.95\n",
      "Episode 80:  FAILED - Seed: 80, Timesteps: 200, Distance: 3, Shannon Entropy: 1.74\n",
      "Episode 81:  SUCCESS - Seed: 81, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 82:  FAILED - Seed: 82, Timesteps: 200, Distance: 5, Shannon Entropy: 1.71\n",
      "Episode 83:  SUCCESS - Seed: 83, Timesteps: 17, Distance: 17, Shannon Entropy: 0.96\n",
      "Episode 84:  SUCCESS - Seed: 84, Timesteps: 25, Distance: 25, Shannon Entropy: 0.95\n",
      "Episode 85:  FAILED - Seed: 85, Timesteps: 200, Distance: 41, Shannon Entropy: 1.39\n",
      "Episode 86:  SUCCESS - Seed: 86, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 87:  SUCCESS - Seed: 87, Timesteps: 14, Distance: 14, Shannon Entropy: 0.96\n",
      "Episode 88:  SUCCESS - Seed: 88, Timesteps: 14, Distance: 14, Shannon Entropy: 0.96\n",
      "Episode 89:  SUCCESS - Seed: 89, Timesteps: 37, Distance: 37, Shannon Entropy: 0.95\n",
      "Episode 90:  FAILED - Seed: 90, Timesteps: 200, Distance: 25, Shannon Entropy: 1.50\n",
      "Episode 91:  SUCCESS - Seed: 91, Timesteps: 40, Distance: 40, Shannon Entropy: 0.95\n",
      "Episode 92:  SUCCESS - Seed: 92, Timesteps: 48, Distance: 48, Shannon Entropy: 0.95\n",
      "Episode 93:  SUCCESS - Seed: 93, Timesteps: 35, Distance: 35, Shannon Entropy: 0.95\n",
      "Episode 94:  SUCCESS - Seed: 94, Timesteps: 3, Distance: 3, Shannon Entropy: 0.96\n",
      "Episode 95:  SUCCESS - Seed: 95, Timesteps: 16, Distance: 16, Shannon Entropy: 0.96\n",
      "Episode 96:  SUCCESS - Seed: 96, Timesteps: 200, Distance: 200, Shannon Entropy: 1.35\n",
      "Episode 97:  FAILED - Seed: 97, Timesteps: 200, Distance: 50, Shannon Entropy: 1.33\n",
      "Episode 98:  SUCCESS - Seed: 98, Timesteps: 20, Distance: 20, Shannon Entropy: 0.96\n",
      "Episode 99:  FAILED - Seed: 99, Timesteps: 200, Distance: 8, Shannon Entropy: 1.67\n",
      "Episode 100:  SUCCESS - Seed: 100, Timesteps: 3, Distance: 3, Shannon Entropy: 0.96\n",
      "Episode 101:  SUCCESS - Seed: 101, Timesteps: 15, Distance: 15, Shannon Entropy: 0.96\n",
      "Episode 102:  SUCCESS - Seed: 102, Timesteps: 25, Distance: 25, Shannon Entropy: 0.95\n",
      "Episode 103:  SUCCESS - Seed: 103, Timesteps: 31, Distance: 31, Shannon Entropy: 0.95\n",
      "Episode 104:  SUCCESS - Seed: 104, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 105:  SUCCESS - Seed: 105, Timesteps: 36, Distance: 36, Shannon Entropy: 0.95\n",
      "Episode 106:  SUCCESS - Seed: 106, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 107:  FAILED - Seed: 107, Timesteps: 200, Distance: 200, Shannon Entropy: 1.25\n",
      "Episode 108:  SUCCESS - Seed: 108, Timesteps: 22, Distance: 22, Shannon Entropy: 0.95\n",
      "Episode 109:  SUCCESS - Seed: 109, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 110:  SUCCESS - Seed: 110, Timesteps: 21, Distance: 21, Shannon Entropy: 0.96\n",
      "Episode 111:  SUCCESS - Seed: 111, Timesteps: 18, Distance: 18, Shannon Entropy: 0.96\n",
      "Episode 112:  SUCCESS - Seed: 112, Timesteps: 6, Distance: 6, Shannon Entropy: 0.96\n",
      "Episode 113:  SUCCESS - Seed: 113, Timesteps: 44, Distance: 44, Shannon Entropy: 0.95\n",
      "Episode 114:  FAILED - Seed: 114, Timesteps: 200, Distance: 5, Shannon Entropy: 1.71\n",
      "Episode 115:  SUCCESS - Seed: 115, Timesteps: 3, Distance: 3, Shannon Entropy: 0.96\n",
      "Episode 116:  SUCCESS - Seed: 116, Timesteps: 17, Distance: 17, Shannon Entropy: 0.96\n",
      "Episode 117:  SUCCESS - Seed: 117, Timesteps: 200, Distance: 200, Shannon Entropy: 1.29\n",
      "Episode 118:  FAILED - Seed: 118, Timesteps: 200, Distance: 13, Shannon Entropy: 1.61\n",
      "Episode 119:  SUCCESS - Seed: 119, Timesteps: 200, Distance: 200, Shannon Entropy: 1.30\n",
      "Episode 120:  FAILED - Seed: 120, Timesteps: 200, Distance: 15, Shannon Entropy: 1.59\n",
      "Episode 121:  SUCCESS - Seed: 121, Timesteps: 26, Distance: 26, Shannon Entropy: 0.95\n",
      "Episode 122:  FAILED - Seed: 122, Timesteps: 200, Distance: 44, Shannon Entropy: 1.37\n",
      "Episode 123:  SUCCESS - Seed: 123, Timesteps: 28, Distance: 28, Shannon Entropy: 0.95\n",
      "Episode 124:  SUCCESS - Seed: 124, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 125:  SUCCESS - Seed: 125, Timesteps: 17, Distance: 17, Shannon Entropy: 0.96\n",
      "Episode 126:  SUCCESS - Seed: 126, Timesteps: 5, Distance: 5, Shannon Entropy: 0.96\n",
      "Episode 127:  SUCCESS - Seed: 127, Timesteps: 5, Distance: 5, Shannon Entropy: 0.96\n",
      "Episode 128:  FAILED - Seed: 128, Timesteps: 200, Distance: 200, Shannon Entropy: 1.28\n",
      "Episode 129:  SUCCESS - Seed: 129, Timesteps: 5, Distance: 5, Shannon Entropy: 0.96\n",
      "Episode 130:  SUCCESS - Seed: 130, Timesteps: 4, Distance: 4, Shannon Entropy: 0.96\n",
      "Episode 131:  SUCCESS - Seed: 131, Timesteps: 23, Distance: 23, Shannon Entropy: 0.95\n",
      "Episode 132:  FAILED - Seed: 132, Timesteps: 200, Distance: 5, Shannon Entropy: 1.71\n",
      "Episode 133:  SUCCESS - Seed: 133, Timesteps: 18, Distance: 18, Shannon Entropy: 0.96\n",
      "Episode 134:  SUCCESS - Seed: 134, Timesteps: 10, Distance: 10, Shannon Entropy: 0.96\n",
      "Episode 135:  FAILED - Seed: 135, Timesteps: 200, Distance: 37, Shannon Entropy: 1.41\n",
      "Episode 136:  SUCCESS - Seed: 136, Timesteps: 35, Distance: 35, Shannon Entropy: 0.95\n",
      "Episode 137:  SUCCESS - Seed: 137, Timesteps: 26, Distance: 26, Shannon Entropy: 0.95\n",
      "Episode 138:  SUCCESS - Seed: 138, Timesteps: 11, Distance: 11, Shannon Entropy: 0.96\n",
      "Episode 139:  SUCCESS - Seed: 139, Timesteps: 200, Distance: 200, Shannon Entropy: 1.34\n",
      "Episode 140:  FAILED - Seed: 140, Timesteps: 200, Distance: 5, Shannon Entropy: 1.71\n",
      "Episode 141:  SUCCESS - Seed: 141, Timesteps: 200, Distance: 200, Shannon Entropy: 1.35\n",
      "Episode 142:  FAILED - Seed: 142, Timesteps: 200, Distance: 200, Shannon Entropy: 1.35\n",
      "Episode 143:  SUCCESS - Seed: 143, Timesteps: 27, Distance: 27, Shannon Entropy: 0.95\n",
      "Episode 144:  FAILED - Seed: 144, Timesteps: 200, Distance: 20, Shannon Entropy: 1.54\n",
      "Episode 145:  FAILED - Seed: 145, Timesteps: 200, Distance: 42, Shannon Entropy: 1.38\n",
      "Episode 146:  SUCCESS - Seed: 146, Timesteps: 19, Distance: 19, Shannon Entropy: 0.96\n",
      "Episode 147:  SUCCESS - Seed: 147, Timesteps: 42, Distance: 42, Shannon Entropy: 0.95\n",
      "Episode 148:  SUCCESS - Seed: 148, Timesteps: 33, Distance: 33, Shannon Entropy: 0.95\n",
      "Episode 149:  SUCCESS - Seed: 149, Timesteps: 12, Distance: 12, Shannon Entropy: 0.96\n",
      "Episode 150:  SUCCESS - Seed: 150, Timesteps: 42, Distance: 42, Shannon Entropy: 0.95\n",
      "\n",
      "===== BATCH TEST RESULTS =====\n",
      "Success Rate: 0.73 (109/150)\n",
      "Average Timesteps: 78.81\n",
      "Average Distance: 35.89\n",
      "Average Shannon Entropy: 1.14\n",
      "Detailed results saved to results/results.csv\n",
      "\n",
      "Key metrics from saved data:\n",
      "Success rate: 0.73\n",
      "Avg Total Distance: 35.89\n",
      "Avg Unique Locations: 21.38\n",
      "Avg Shannon Entropy: 1.14\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Try to import the Gridworld environment\n",
    "try:\n",
    "    from Gridworld import Gridworld\n",
    "except ImportError:\n",
    "    try:\n",
    "        from New_RL.Gridworld import Gridworld\n",
    "    except ImportError:\n",
    "        print(\"Error: Couldn't import Gridworld. Please check your import paths.\")\n",
    "\n",
    "# Define DQN model architecture (simplified)\n",
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=29, output_dim=4):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def load_model(model_path, input_dim=29, output_dim=4, device='cpu'):\n",
    "    \"\"\"\n",
    "    Load a DQN model from a checkpoint file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the model with specified dimensions\n",
    "        model = DQN(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "        \n",
    "        # Load the checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        \n",
    "        # Extract model state from checkpoint\n",
    "        if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
    "            model_state = checkpoint[\"model_state_dict\"]\n",
    "            print(f\"Model checkpoint contains: {list(checkpoint.keys())}\")\n",
    "            if \"episode\" in checkpoint:\n",
    "                print(f\"Model was trained for {checkpoint['episode']} episodes\")\n",
    "        else:\n",
    "            model_state = checkpoint\n",
    "            print(\"Model state loaded directly\")\n",
    "        \n",
    "        # Load state dict into model\n",
    "        model.load_state_dict(model_state)\n",
    "        model.eval()  # Set to evaluation mode\n",
    "        \n",
    "        print(f\"Successfully loaded model from {model_path}\")\n",
    "        return model\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Model file not found at {model_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def balanced_exploration_metric(distribution, state_space_size, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Balanced exploration metric that penalizes both:\n",
    "    - Visiting too few states repeatedly (low entropy)\n",
    "    - Visiting too many different states (high dispersion)\n",
    "    \n",
    "    Returns the reciprocal of the score so LOWER values indicate BETTER performance.\n",
    "    \n",
    "    Parameters:\n",
    "    - distribution: Dictionary mapping states to visit counts\n",
    "    - state_space_size: Total number of possible states in the environment\n",
    "    - alpha: Balance parameter between entropy and state count (0-1)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    \n",
    "    # Calculate entropy component (rewards uniform exploration)\n",
    "    total_visits = sum(distribution.values())\n",
    "    entropy = 0\n",
    "    for count in distribution.values():\n",
    "        probability = count / total_visits\n",
    "        if probability > 0:\n",
    "            entropy -= probability * math.log2(probability)\n",
    "    \n",
    "    # Normalize entropy by max possible entropy (log2 of state count)\n",
    "    max_entropy = math.log2(len(distribution)) if distribution else 0\n",
    "    normalized_entropy = entropy / max_entropy if max_entropy > 0 else 0\n",
    "    \n",
    "    # Calculate state coverage penalty (penalizes visiting too many states)\n",
    "    coverage_ratio = len(distribution) / state_space_size\n",
    "    coverage_penalty = 1 - math.exp(-(coverage_ratio - 0.5)**2 / 0.1)\n",
    "    \n",
    "    # Combine metrics (higher raw_score is better)\n",
    "    raw_score = alpha * normalized_entropy - (1 - alpha) * coverage_penalty\n",
    "    \n",
    "    # Add a small epsilon to avoid division by zero or negative values\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    # Return reciprocal so lower values are better\n",
    "    # We add 1 to make all values positive\n",
    "    return 1 / (raw_score + 1 + epsilon)\n",
    "\n",
    "def test_model(model, random_seed=None, grid_size=40, max_steps=200, render=True, pause_time=0.2):\n",
    "    \"\"\"\n",
    "    Test a DQN model on a Gridworld environment with requested metrics.\n",
    "    \"\"\"\n",
    "    # Create environment\n",
    "    env = Gridworld(\n",
    "        size=grid_size,\n",
    "        mode='random',\n",
    "        max_steps=max_steps,\n",
    "        random_seed=random_seed\n",
    "    )\n",
    "    \n",
    "    if random_seed is not None:\n",
    "        # Set random seed for reproducibility\n",
    "        env.random_seed = random_seed\n",
    "        random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    # Initialize state\n",
    "    state = env.reset()\n",
    "    \n",
    "    # Track metrics\n",
    "    total_timesteps = 0\n",
    "    total_reward = 0\n",
    "    path_history = [env.player_position]\n",
    "    actions_taken = []\n",
    "    \n",
    "    # Track state visits for entropy and location counts\n",
    "    state_visits = Counter()\n",
    "    state_visits[tuple(env.player_position)] = 1\n",
    "    \n",
    "    # Action names for display\n",
    "    action_names = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]\n",
    "    \n",
    "    # Print initial state\n",
    "    if render:\n",
    "        print(f\"\\nTesting on {grid_size}x{grid_size} grid (seed: {random_seed})\")\n",
    "        print(f\"Start: {env.player_position}, Goal: {env.goal_position}\")\n",
    "        \n",
    "        # Initial render\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        env.render()\n",
    "        plt.title(f\"Initial state - Agent at {env.player_position}, Goal at {env.goal_position}\")\n",
    "        plt.pause(pause_time)\n",
    "    \n",
    "    # Run episode\n",
    "    done = False\n",
    "    goal_reached = False\n",
    "    \n",
    "    while not done and total_timesteps < max_steps:\n",
    "        # Convert state to tensor\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        \n",
    "        # Get action from model\n",
    "        with torch.no_grad():\n",
    "            q_values = model(state_tensor)\n",
    "            action = torch.argmax(q_values).item()\n",
    "            actions_taken.append(action)\n",
    "            \n",
    "            # Get action name for display\n",
    "            action_name = action_names[action] if action < len(action_names) else f\"UNKNOWN({action})\"\n",
    "        \n",
    "        # Take action in environment\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Update metrics\n",
    "        total_timesteps += 1\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        \n",
    "        # Track path\n",
    "        path_history.append(env.player_position)\n",
    "        \n",
    "        # Track state visits (increment counter for this position)\n",
    "        state_visits[tuple(env.player_position)] += 1\n",
    "        \n",
    "        # Check for success\n",
    "        if reward > 0 and done:\n",
    "            goal_reached = True\n",
    "        \n",
    "        # Render if requested\n",
    "        if render and (total_timesteps % 3 == 0 or done):\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            env.render()\n",
    "            \n",
    "            # Draw path\n",
    "            path_x = [pos[1] for pos in path_history]\n",
    "            path_y = [pos[0] for pos in path_history]\n",
    "            plt.plot(path_x, path_y, '-', color='blue', alpha=0.7, linewidth=2)\n",
    "            plt.plot(path_x[-1], path_y[-1], 'o', color='blue', markersize=10)\n",
    "            \n",
    "            status = \"SUCCESS!\" if goal_reached else (\"FAILED!\" if done else f\"Step {total_timesteps}\")\n",
    "            plt.title(f\"Action: {action_name}, Reward: {total_reward:.1f}\\nStatus: {status}\")\n",
    "            plt.pause(pause_time)\n",
    "    \n",
    "    # Calculate total distance traveled\n",
    "    total_distance = 0\n",
    "    for i in range(1, len(path_history)):\n",
    "        total_distance += abs(path_history[i][0] - path_history[i-1][0]) + abs(path_history[i][1] - path_history[i-1][1])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    unique_locations = len(state_visits)\n",
    "    revisited_locations = sum(state_visits.values()) - unique_locations\n",
    "    \n",
    "    # Calculate Shannon entropy based on state visit distribution\n",
    "    shannon_entropy = balanced_exploration_metric(state_visits, state_space_size=1600, alpha=0.5)\n",
    "    \n",
    "    grid_dims = f\"{grid_size}x{grid_size}\"\n",
    "    \n",
    "    # Final status message\n",
    "    if render:\n",
    "        print(\"\\n===== TEST RESULTS =====\")\n",
    "        print(f\"Agent Type: DQN\")\n",
    "        print(f\"Random Seed: {random_seed}\")\n",
    "        print(f\"Goal Reached: {'Yes' if goal_reached else 'No'}\")\n",
    "        print(f\"Total Timesteps: {total_timesteps}\")\n",
    "        print(f\"Total Distance: {total_distance}\")\n",
    "        print(f\"Unique Locations: {unique_locations}\")\n",
    "        print(f\"Revisited Locations: {revisited_locations}\")\n",
    "        print(f\"Shannon Entropy (states): {shannon_entropy:.3f}\")\n",
    "        print(f\"Grid Dimensions: {grid_dims}\")\n",
    "        \n",
    "        # Show action distribution\n",
    "        print(\"\\nAction distribution:\")\n",
    "        for a in sorted(Counter(actions_taken).keys()):\n",
    "            name = action_names[a] if a < len(action_names) else f\"Action {a}\"\n",
    "            count = Counter(actions_taken)[a]\n",
    "            print(f\"  {name}: {count} times ({count/len(actions_taken):.1%})\")\n",
    "        \n",
    "        # Show most visited states\n",
    "        print(\"\\nMost visited states:\")\n",
    "        for state, count in state_visits.most_common(5):\n",
    "            print(f\"  {state}: {count} visits\")\n",
    "    \n",
    "    # Return metrics with the exact requested field names for CSV\n",
    "    return {\n",
    "        \"agent_type\": \"DQN\",\n",
    "        \"random_seed\": random_seed,\n",
    "        \"total_timesteps\": total_timesteps,\n",
    "        \"total_distance\": total_distance,\n",
    "        \"goal_reached\": 1 if goal_reached else 0,  # Use 1/0 for boolean in CSV\n",
    "        \"unique_locations\": unique_locations,\n",
    "        \"revisited_locations\": revisited_locations,\n",
    "        \"shannon_entropy\": shannon_entropy,  # Changed from action_entropy to shannon_entropy\n",
    "        \"grid_dims\": grid_dims\n",
    "    }\n",
    "\n",
    "def run_test_batch(model_path, num_episodes=10, seeds=None, render_first=True):\n",
    "    \"\"\"\n",
    "    Run a batch of test episodes and collect statistics.\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    # Generate seeds if not provided\n",
    "    if seeds is None:\n",
    "        seeds = [random.randint(1, 10000) for _ in range(num_episodes)]\n",
    "    elif len(seeds) < num_episodes:\n",
    "        seeds = seeds + [random.randint(1, 10000) for _ in range(num_episodes - len(seeds))]\n",
    "    \n",
    "    results = []\n",
    "    successes = 0\n",
    "    \n",
    "    print(f\"Running {num_episodes} test episodes...\")\n",
    "    for i in range(num_episodes):        \n",
    "        # Run test\n",
    "        result = test_model(\n",
    "            model=model,\n",
    "            random_seed=seeds[i],\n",
    "            render=render_first and i == 0\n",
    "        )\n",
    "        \n",
    "        results.append(result)\n",
    "        if result[\"goal_reached\"]:\n",
    "            successes += 1\n",
    "        \n",
    "        # Print brief result with metrics\n",
    "        if not (render_first and i == 0):\n",
    "            status = \" SUCCESS\" if result[\"goal_reached\"] else \" FAILED\"\n",
    "            print(f\"Episode {i+1}: {status} - Seed: {result['random_seed']}, \" +\n",
    "                  f\"Timesteps: {result['total_timesteps']}, \" + \n",
    "                  f\"Distance: {result['total_distance']}, \" +\n",
    "                  f\"Shannon Entropy: {result['shannon_entropy']:.2f}\")\n",
    "    \n",
    "    # Calculate aggregate statistics\n",
    "    success_rate = successes / num_episodes\n",
    "    avg_timesteps = sum(r[\"total_timesteps\"] for r in results) / num_episodes\n",
    "    avg_distance = sum(r[\"total_distance\"] for r in results) / num_episodes\n",
    "    avg_entropy = sum(r[\"shannon_entropy\"] for r in results) / num_episodes\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n===== BATCH TEST RESULTS =====\")\n",
    "    print(f\"Success Rate: {success_rate:.2f} ({successes}/{num_episodes})\")\n",
    "    print(f\"Average Timesteps: {avg_timesteps:.2f}\")\n",
    "    print(f\"Average Distance: {avg_distance:.2f}\")\n",
    "    print(f\"Average Shannon Entropy: {avg_entropy:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        \"success_rate\": success_rate,\n",
    "        \"successes\": successes,\n",
    "        \"episodes\": num_episodes,\n",
    "        \"avg_timesteps\": avg_timesteps,\n",
    "        \"avg_distance\": avg_distance,\n",
    "        \"avg_entropy\": avg_entropy,\n",
    "        \"seeds\": seeds[:num_episodes],\n",
    "        \"detailed_results\": results\n",
    "    }\n",
    "\n",
    "MODEL_PATH = 'models/dqn_final.pth'\n",
    "SEEDS = list(range(1, 151))  # Seeds 1-100\n",
    "\n",
    "# Run batch test\n",
    "batch_results = run_test_batch(\n",
    "    model_path=MODEL_PATH,\n",
    "    num_episodes=150,\n",
    "    seeds=SEEDS,\n",
    "    render_first=True\n",
    ")\n",
    "\n",
    "# Save results to CSV\n",
    "if batch_results:\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Extract detailed results\n",
    "    df = pd.DataFrame(batch_results[\"detailed_results\"])\n",
    "    \n",
    "    # Ensure all requested metrics are in the DataFrame\n",
    "    required_metrics = [\n",
    "        \"agent_type\", \"random_seed\", \"total_timesteps\", \"total_distance\", \n",
    "        \"goal_reached\", \"unique_locations\", \"revisited_locations\", \n",
    "        \"shannon_entropy\", \"grid_dims\"  # Changed from action_entropy to shannon_entropy\n",
    "    ]\n",
    "    \n",
    "    for metric in required_metrics:\n",
    "        if metric not in df.columns:\n",
    "            print(f\"Warning: Metric '{metric}' missing from results\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    csv_path = f\"results/results.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Detailed results saved to {csv_path}\")\n",
    "    \n",
    "    # Show key metrics from the saved data\n",
    "    print(\"\\nKey metrics from saved data:\")\n",
    "    print(f\"Success rate: {df['goal_reached'].mean():.2f}\")\n",
    "    print(f\"Avg Total Distance: {df['total_distance'].mean():.2f}\")\n",
    "    print(f\"Avg Unique Locations: {df['unique_locations'].mean():.2f}\")\n",
    "    print(f\"Avg Shannon Entropy: {df['shannon_entropy'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
