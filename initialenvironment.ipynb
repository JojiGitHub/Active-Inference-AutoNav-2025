{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment: Gridworld\n",
    "\n",
    "Task: Get to some point X (given). Avoid red spots (some points are red and the agent doesn’t wanna go on those).\n",
    "\n",
    "### Info:\n",
    "GRID: 7 by 5 \\\n",
    "Number of red spots: 4 \\\n",
    "Positions of red spots: red1, red2, red3, red4 = (randomly define locations for each one) \\\n",
    "Red_spots = [(1, 2), (6, 1), (3, 2), (4, 4)]\n",
    "\n",
    "### S\n",
    "Location of Agent \\\n",
    "    Agent_pos = (x, y)\n",
    "\n",
    "Locations of Red Spots: \\\n",
    "Agent Map = Belixef of Possible Locations on Grid \\\n",
    "    Possible_locations = dict((1,1) : False) \\\n",
    "        1st component = location \\\n",
    "        2nd component encodes whether it’s a red spot (true) or safe (false)\n",
    "\n",
    "### T\n",
    "Location of Agent \\\n",
    "    Environmental Constraints \\\n",
    "        If agent_pos[0] == 0: P(a = LEFT) = 0  \\\n",
    "        If agent_pos[1] == 0: P(a = DOWN) = 0  \\\n",
    "        If agent_pos[0] ==  6: P(a = RIGHT) = 0  \\\n",
    "        If agent_pos[1] == 4: P(a = UP) = 0 \\\n",
    "If a == RIGHT: agent_pos[0] += 1 \\\n",
    "If a == LEFT: agent_pos[0] -= 1 \\\n",
    "If a == UP: agent_pos[1] += 1 \\\n",
    "If a == DOWN: agent_pos[1] -= 1\n",
    "\n",
    "### R\n",
    "Reward_points = 0 \\\n",
    "Redspot: If agent_pos in redspots: reward_points -= 5 \\\n",
    "Endgoal \\\n",
    "    If agent_pos == (4, 6): reward_points += 20\n",
    "\n",
    "\n",
    "### set of observations (dimensionality of 2)\n",
    "Observation \\\n",
    "    Observed_spot \\\n",
    "        ((x, y), True/False) \\\n",
    "    Possible_locations.append(observed_spot)\n",
    "\n",
    "O is set of conditional observation probabilities (prior preference) \\\n",
    "    C = C matrix \\\n",
    "    C[(4,6)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pymdp\n",
    "from pymdp import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(grid_locations, num_x = 3, num_y = 3 ):\n",
    "    \"\"\"\n",
    "    Plots the spatial coordinates of GridWorld as a heatmap, with each (X, Y) coordinate \n",
    "    labeled with its linear index (its `state id`)\n",
    "    \"\"\"\n",
    "\n",
    "    grid_heatmap = np.zeros((num_x, num_y))\n",
    "    for linear_idx, location in enumerate(grid_locations):\n",
    "      y, x = location\n",
    "      grid_heatmap[y, x] = linear_idx\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.heatmap(grid_heatmap, annot=True, cbar = False, fmt='.0f', cmap='crest')\n",
    "\n",
    "def plot_likelihood(matrix, title_str = \"Likelihood distribution (A)\"):\n",
    "    \"\"\"\n",
    "    Plots a 2-D likelihood matrix as a heatmap\n",
    "    \"\"\"\n",
    "\n",
    "    if not np.isclose(matrix.sum(axis=0), 1.0).all():\n",
    "      raise ValueError(\"Distribution not column-normalized! Please normalize (ensure matrix.sum(axis=0) == 1.0 for all columns)\")\n",
    "    \n",
    "    fig = plt.figure(figsize = (6,6))\n",
    "    ax = sns.heatmap(matrix, cmap = 'gray', cbar = False, vmin = 0.0, vmax = 1.0)\n",
    "    plt.title(title_str)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_beliefs(belief_dist, title_str=\"\"):\n",
    "    \"\"\"\n",
    "    Plot a categorical distribution or belief distribution, stored in the 1-D numpy vector `belief_dist`\n",
    "    \"\"\"\n",
    "\n",
    "    if not np.isclose(belief_dist.sum(), 1.0):\n",
    "      raise ValueError(\"Distribution not normalized! Please normalize\")\n",
    "\n",
    "    plt.grid(zorder=0)\n",
    "    plt.bar(range(belief_dist.shape[0]), belief_dist, color='r', zorder=3)\n",
    "    plt.xticks(range(belief_dist.shape[0]))\n",
    "    plt.title(title_str)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_dimensions\n",
    "grid_dims = [7,5]\n",
    "num_grid_points = np.prod(grid_dims) # total number of grid locations (rows X columns)\n",
    "\n",
    "# setup matrix\n",
    "grid = np.arange(num_grid_points).reshape(grid_dims) # arange -> creates list; reshape -> makes it in the shape specified by grid_dims\n",
    "\n",
    "# define red spots\n",
    "grid[(1, 2)] = 1\n",
    "grid[(3, 2)] = 1\n",
    "grid[(4, 4)] = 1\n",
    "grid[(6, 1)] = 1\n",
    "\n",
    "# list of grid positiions\n",
    "grid_locations = []\n",
    "it = np.nditer(grid, flags=[\"multi_index\"]) # set up the iterator to go throgh the matrix\n",
    "while not it.finished:\n",
    "    grid_locations.append(it.multi_index)\n",
    "    it.iternext()\n",
    "\n",
    "grid, grid_locations\n",
    "\n",
    "redspots = [(1,2), (3,2), (4,4), (6,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the agent hidden state\n",
    "agent_pos = (0,0)\n",
    "\n",
    "goal_location = (6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual gridworld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up figure & grid\n",
    "fig: The entire figure (canvas) where the grid and visual elements will be plotted; ax: The specific axis (plot area) for drawing the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to create the visual grid. \\\n",
    "np.meshgrid defines/creates it. \\\n",
    "The other functions are purely visuals. \\\n",
    "FIGURE OUT WHY WE HAVE TO REDEFINE IT LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8, 6))  # Properly sized figure\n",
    "\n",
    "# # Create grid\n",
    "# X, Y = np.meshgrid(np.arange(grid_dims[1] + 1), np.arange(grid_dims[0] + 1))  # 5x7 grid\n",
    "# h = ax.pcolormesh(X, Y, np.zeros(grid_dims), edgecolors='k', linewidth=3, cmap='coolwarm')  # Base grid\n",
    "\n",
    "# # Add goal (green square)\n",
    "# ax.add_patch(\n",
    "#     plt.Rectangle((4, 6), width=1, height=1, color='green')  # Adjusted coordinates for grid alignment\n",
    "# )\n",
    "\n",
    "# # Add red obstacles\n",
    "# red_obstacles = [(2, 1), (1, 6), (2, 3), (4, 4)]  # List of (x, y) coordinates for red obstacles\n",
    "# for red in red_obstacles:\n",
    "#     ax.add_patch(\n",
    "#         plt.Rectangle((red[0], red[1]), width=1, height=1, color='red')\n",
    "#     )\n",
    "\n",
    "# # Add entry point (white square)\n",
    "# ax.add_patch(\n",
    "#     plt.Rectangle((0, 0), width=1, height=1, color='white')\n",
    "# )\n",
    "\n",
    "# # Add agent (black circle)\n",
    "# ax.add_patch(\n",
    "#     plt.Circle((agent_pos[0] + 0.5, agent_pos[1] + 0.5), radius=0.25, color='black')\n",
    "# )\n",
    "\n",
    "# # Set grid limits and labels\n",
    "# ax.set_xlim(0, grid_dims[1])\n",
    "# ax.set_ylim(0, grid_dims[0])\n",
    "# ax.set_aspect('equal')\n",
    "# ax.set_xticks(np.arange(grid_dims[1]) + 0.5)\n",
    "# ax.set_yticks(np.arange(grid_dims[0]) + 0.5)\n",
    "# ax.set_xticklabels(np.arange(grid_dims[1]))\n",
    "# ax.set_yticklabels(np.arange(grid_dims[0]))\n",
    "# plt.gca().invert_yaxis()  # Invert y-axis to match typical grid orientation\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 6)) # idk why we need to redefine this. FIGURE IT OUT LATER\n",
    "\n",
    "# # create grid\n",
    "# X, Y = np.meshgrid(np.arange(grid_dims[1]+1), np.arange(grid_dims[0]+1))\n",
    "# print(X, Y)\n",
    "# # grid visuals\n",
    "# h = ax.pcolormesh(X, Y, np.ones([5, 7]), edgecolors='k', vmin = 0, vmax = 30, linewidth=3, cmap = 'coolwarm')\n",
    "\n",
    "# # goal\n",
    "# desired_location = ax.add_patch(\n",
    "#     plt.Rectangle((4, 6), width=1, height=1, color='green')\n",
    "# )\n",
    "\n",
    "# # red spots\n",
    "# red1 = ax.add_patch(\n",
    "#     plt.Rectangle((1, 2), width=1, height=1, color='red')\n",
    "# )\n",
    "# red2 = ax.add_patch(\n",
    "#     plt.Rectangle((6, 1), width=1, height=1, color='red')\n",
    "# )\n",
    "# red3 = ax.add_patch(\n",
    "#     plt.Rectangle((3, 2), width=1, height=1, color='red')\n",
    "# )\n",
    "# red4 = ax.add_patch(\n",
    "#     plt.Rectangle((4, 4), width=1, height=1, color='red')\n",
    "# )\n",
    "\n",
    "# # entry spot\n",
    "# entry = ax.add_patch(\n",
    "#     plt.Rectangle((0, 0), width=1, height=1, color='white')\n",
    "# )\n",
    "# agent_icon = ax.add_patch(\n",
    "#     plt.Circle((agent_pos[0] + 0.5, agent_pos[1] + 0.5), radius=0.25, color='black')\n",
    "# )\n",
    "\n",
    "\n",
    "# desired_location = ax.add_patch(\n",
    "#     plt.Rectangle((6, 4), width=1, height=1, color='green')\n",
    "# )\n",
    "\n",
    "# # ax.set_xlim(0, grid_dims[1])\n",
    "# # ax.set_ylim(0, grid_dims[0])\n",
    "# # ax.set_aspect('equal')\n",
    "# # ax.set_xticks(np.arange(grid_dims[1]) + 0.5)\n",
    "# # ax.set_yticks(np.arange(grid_dims[0]) + 0.5)\n",
    "# # ax.set_xticklabels(np.arange(grid_dims[1]))\n",
    "# # ax.set_yticklabels(np.arange(grid_dims[0]))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reward\n",
    "# reward_conditions_positive = ['END GOAL']\n",
    "# reward_locations_positive = [(6,4)]\n",
    "# reward_conditions_negative = ['RED1', 'RED2', 'RED3', 'RED4']\n",
    "# reward_locations_negative = [(1, 2), (6, 1), (3, 2), (4, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_names = ['SAFE', 'RED']\n",
    "# choice_names = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "\n",
    "# num_states = [len(context_names), len(choice_names)]\n",
    "# num_factors = len(num_states)\n",
    "\n",
    "# context_action_names = ['Do-nothing']\n",
    "# choice_action_names = ['Move-up', 'Move-down', 'Move-left', 'Move-right']\n",
    "\n",
    "# num_controls = [len(context_action_names), len(choice_action_names)]\n",
    "\n",
    "# loc_obs_attributes = ['SAFE', 'DANGER', 'GOAL']\n",
    "# # agent's belief about map hidden state\n",
    "# map_obs = {\n",
    "#     (0,0) : False,\n",
    "#     (0, 1) : False,\n",
    "#     (1, 0) : False,\n",
    "#     (1, 1) : False,\n",
    "# }\n",
    "\n",
    "# num_obs = [len(loc_obs_attribute), len(loc_obs_map)]\n",
    "# num_modalities = len(num_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden states s have these hidden state factors:\n",
    "1. Location (as many levels as there are grid locations)\n",
    "\n",
    "The observations!!:\n",
    "1. Positions\n",
    "2. Safety (2 hidden state levels - safe or dangerous/red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = [len(grid_locations)] # location\n",
    "\n",
    "safety = ['EMPTY', 'RED'] # obs\n",
    "goal = ['EMPTY', 'GOAL']\n",
    "\n",
    "num_obs = [len(grid_locations), len(safety), len(goal)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 35], [2, 35], [2, 35]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_m_shapes = [ [o_dim] + num_states for o_dim in num_obs] # list of shapes of modality-specific A[m] arrays\n",
    "A = utils.obj_array_zeros(A_m_shapes) # initialize A array to an object array of all-zero subarrays\n",
    "A_m_shapes # 2 types of observations, one type of state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location observation modality: A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A[0] = np.eye(num_grid_points)\n",
    "\n",
    "# # Safety observations (probability 1 for the safe state, 0 for the dangerous one)\n",
    "# A[1] = np.zeros((2, num_grid_points))  # safety matrix initialized to 0\n",
    "# A[1][0, 0] = 1  # Safe state (SAFE) for the first grid point, probability 1\n",
    "# A[1][1, 0] = 0  # Danger (RED) for the first grid point, probability 0\n",
    "\n",
    "# A[2][0, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_transition(A, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Add noise to transition matrix while preserving normalization\n",
    "    \n",
    "    Args:\n",
    "        A: Original transition matrix\n",
    "        noise_level: Amount of noise to add (0-1)\n",
    "    \"\"\"\n",
    "    # Generate random noise\n",
    "    noise = np.random.uniform(-noise_level, noise_level, size=A.shape)\n",
    "\n",
    "    print(noise) \n",
    "    \n",
    "    # Add noise to matrix\n",
    "    noisy_A = A + noise\n",
    "    \n",
    "    # Ensure non-negative\n",
    "    noisy_A = np.maximum(noisy_A, 0.0)\n",
    "    \n",
    "    # Normalize columns to sum to 1\n",
    "    noisy_A = noisy_A / noisy_A.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    return noisy_A\n",
    "\n",
    "# Usage:\n",
    "# A = add_noise_to_transition(A, noise_level=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09869595  0.00932144 -0.02040958 ... -0.02294469 -0.0055596\n",
      "   0.00233751]\n",
      " [ 0.01754759 -0.04020472  0.01996878 ...  0.04265713 -0.0360002\n",
      "   0.09323831]\n",
      " [-0.02138943 -0.01384876  0.04886909 ... -0.0749099   0.07117647\n",
      "  -0.09846618]\n",
      " ...\n",
      " [-0.03955137 -0.04439076  0.0689671  ...  0.00203005  0.03968972\n",
      "  -0.04532436]\n",
      " [ 0.0414408   0.06289316 -0.03586379 ...  0.06756145 -0.01822964\n",
      "  -0.07476814]\n",
      " [ 0.02717714  0.02225782 -0.07068513 ... -0.05864924 -0.04686008\n",
      "   0.07922887]]\n",
      "[[ 0.04838627 -0.04474232  0.0516194  -0.09871437 -0.07402924 -0.03893842\n",
      "  -0.03864764  0.06688703 -0.06213534  0.02157994 -0.0895357   0.0107657\n",
      "  -0.03960523 -0.00481141  0.09970598  0.07720113 -0.02814317  0.02534754\n",
      "   0.03681721  0.08785565  0.04500084 -0.02334405 -0.07155965  0.08380517\n",
      "   0.04189196  0.06245591 -0.06794447  0.04661749  0.03352779  0.02338957\n",
      "   0.0375544  -0.04490802 -0.0854567   0.05660989 -0.02631424]\n",
      " [-0.04533377 -0.09685997 -0.04233403  0.02719616  0.09632937  0.06923253\n",
      "  -0.03415242  0.09389471  0.00965134 -0.08103781 -0.03232526 -0.00024486\n",
      "   0.00917386  0.06887934 -0.09869982 -0.03741885  0.036805    0.02234353\n",
      "  -0.01098065 -0.07202083  0.06412985 -0.09348722 -0.07292914 -0.03147292\n",
      "   0.0007276  -0.0879718   0.0509406  -0.06773718 -0.04289104 -0.04935173\n",
      "  -0.03015425 -0.03683164 -0.02463423 -0.0542872   0.08770896]]\n",
      "[[ 4.40560590e-02  1.59305203e-02  7.41536905e-02  2.73879373e-03\n",
      "  -2.67738900e-02 -6.82864099e-02 -2.49091047e-02 -1.04042787e-02\n",
      "   9.36450468e-02 -9.83989293e-02 -7.72313666e-02  1.81834076e-03\n",
      "  -9.65303382e-02 -2.59768520e-02 -6.91488407e-02  5.68105074e-03\n",
      "  -2.57874489e-02 -7.43691130e-02  9.53341812e-02  5.41323263e-02\n",
      "  -1.99305979e-03  4.09934476e-02  5.24904707e-02  8.01593604e-02\n",
      "  -2.47995678e-02 -6.16178950e-02  7.93580898e-02  4.58941975e-02\n",
      "  -9.31057508e-02  6.84693022e-03  8.67534039e-02 -6.26387094e-02\n",
      "   4.90977119e-02 -5.52385069e-02 -4.82889506e-02]\n",
      " [-8.78895051e-02 -5.61963181e-02  7.68465844e-02  8.98987546e-02\n",
      "  -5.37817960e-02  2.63101199e-02 -6.57722134e-02  5.68249665e-02\n",
      "   3.89209656e-02 -6.54986242e-02  9.39313200e-02 -5.44104795e-02\n",
      "   2.34576075e-02 -4.02167948e-02  8.02489320e-02 -9.55977686e-02\n",
      "   1.04036286e-05 -5.63051723e-02 -4.39195210e-02  1.74816490e-02\n",
      "   1.07324706e-02  7.06682962e-02 -3.82754824e-02  7.50211750e-02\n",
      "  -2.02549876e-02 -7.90220141e-02  9.26177235e-02  5.36291563e-03\n",
      "   6.20173085e-02 -2.78621589e-04  3.37120274e-02 -2.74543686e-02\n",
      "  -7.07397450e-02  3.78776874e-02 -1.31335717e-02]]\n",
      "Modality 0 column sums before check: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Modality 1 column sums before check: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Modality 2 column sums before check: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[array([[0.48254606, 0.00510709, 0.        , ..., 0.        , 0.        ,\n",
      "         0.00142299],\n",
      "        [0.00939475, 0.52585907, 0.01299501, ..., 0.02062003, 0.        ,\n",
      "         0.05675984],\n",
      "        [0.        , 0.        , 0.68256871, ..., 0.        , 0.04015566,\n",
      "         0.        ],\n",
      "        ...,\n",
      "        [0.        , 0.        , 0.04488147, ..., 0.48437122, 0.02239177,\n",
      "         0.        ],\n",
      "        [0.02218685, 0.03445833, 0.        , ..., 0.03265853, 0.55388578,\n",
      "         0.        ],\n",
      "        [0.01455027, 0.01219476, 0.        , ..., 0.        , 0.        ,\n",
      "         0.65699236]])\n",
      " array([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 9.70709002e-01,\n",
      "         9.05771929e-01, 9.32803143e-01, 1.00000000e+00, 9.19110797e-01,\n",
      "         9.89814066e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "         9.90538204e-01, 9.35267908e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "         9.63511060e-01, 9.78673550e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "         9.42180076e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "         9.99302141e-01, 1.00000000e+00, 9.48178232e-01, 1.00000000e+00,\n",
      "         1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "         1.00000000e+00, 1.00000000e+00, 9.17364427e-01],\n",
      "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.92909984e-02,\n",
      "         9.42280709e-02, 6.71968574e-02, 0.00000000e+00, 8.08892027e-02,\n",
      "         1.01859338e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "         9.46179590e-03, 6.47320922e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "         3.64889403e-02, 2.13264495e-02, 0.00000000e+00, 0.00000000e+00,\n",
      "         5.78199240e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "         6.97858891e-04, 0.00000000e+00, 5.18217681e-02, 0.00000000e+00,\n",
      "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "         0.00000000e+00, 0.00000000e+00, 8.26355727e-02]])\n",
      " array([[1.00000000e+00, 1.00000000e+00, 9.33234956e-01, 9.17723169e-01,\n",
      "         1.00000000e+00, 9.72537089e-01, 1.00000000e+00, 9.45695869e-01,\n",
      "         9.65634705e-01, 1.00000000e+00, 9.07611563e-01, 1.00000000e+00,\n",
      "         9.74693152e-01, 1.00000000e+00, 9.20632059e-01, 1.00000000e+00,\n",
      "         9.99989321e-01, 1.00000000e+00, 1.00000000e+00, 9.83686617e-01,\n",
      "         9.89360512e-01, 9.36430037e-01, 1.00000000e+00, 9.35056753e-01,\n",
      "         1.00000000e+00, 1.00000000e+00, 9.20973008e-01, 9.94898569e-01,\n",
      "         9.35992808e-01, 1.00000000e+00, 9.69912479e-01, 1.00000000e+00,\n",
      "         1.00000000e+00, 9.61453107e-01, 1.00000000e+00],\n",
      "        [0.00000000e+00, 0.00000000e+00, 6.67650443e-02, 8.22768307e-02,\n",
      "         0.00000000e+00, 2.74629110e-02, 0.00000000e+00, 5.43041314e-02,\n",
      "         3.43652954e-02, 0.00000000e+00, 9.23884374e-02, 0.00000000e+00,\n",
      "         2.53068480e-02, 0.00000000e+00, 7.93679406e-02, 0.00000000e+00,\n",
      "         1.06788991e-05, 0.00000000e+00, 0.00000000e+00, 1.63133828e-02,\n",
      "         1.06394877e-02, 6.35699633e-02, 0.00000000e+00, 6.49432472e-02,\n",
      "         0.00000000e+00, 0.00000000e+00, 7.90269923e-02, 5.10143100e-03,\n",
      "         6.40071924e-02, 0.00000000e+00, 3.00875212e-02, 0.00000000e+00,\n",
      "         0.00000000e+00, 3.85468930e-02, 0.00000000e+00]])              ]\n"
     ]
    }
   ],
   "source": [
    "A = utils.obj_array_zeros(A_m_shapes)\n",
    "A[0] = np.eye(num_grid_points)  # Location observations (one-hot encoded)\n",
    "\n",
    "# Safety observations\n",
    "A[1] = np.zeros((2, num_grid_points))\n",
    "A[1][0, 0] = 1  # Safe state probability\n",
    "A[1][1, 0] = 0  # Danger state probability\n",
    "\n",
    "# For remaining columns in A[1], we need to set probabilities\n",
    "# Let's say for now all other states are \"safe\"\n",
    "A[1][0, 1:] = 1  # Set all other states as safe\n",
    "A[1][1, 1:] = 0  # Set all other states as not dangerous\n",
    "\n",
    "# Do the same for A[2]\n",
    "A[2] = np.zeros((2, num_grid_points))\n",
    "A[2][0, 0] = 1\n",
    "A[2][1, 0] = 0\n",
    "A[2][0, 1:] = 1\n",
    "A[2][1, 1:] = 0\n",
    "\n",
    "# # Add noise to each modality separately\n",
    "for modality in range(len(A)):\n",
    "     A[modality] = add_noise_to_transition(A[modality], noise_level=0.1)\n",
    "\n",
    "# Verify normalization\n",
    "for modality in range(len(A)):\n",
    "    column_sums = np.sum(A[modality], axis=0)\n",
    "    print(f\"Modality {modality} column sums before check:\", column_sums)\n",
    "    \n",
    "    # Each column should sum to 1\n",
    "    assert np.allclose(column_sums, 1.0), f\"Modality {modality} is not normalized\"\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_likelihood((A[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = utils.obj_array(num_modalities)\n",
    "\n",
    "# p_safe = 0.5\n",
    "# p_danger = 1 - p_safe\n",
    "\n",
    "# A_loc_attribute = np.zeros((len(loc_obs_attributes), len(context_names), len(choice_names)))\n",
    "\n",
    "# for choice_id, choice_name in enumerate(choice_names):\n",
    "#     if choice_name == 'UP':\n",
    "#         A_loc_attribute[0,:,choice_id] =  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 35, 5]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_controls = [5]\n",
    "B_f_shapes = [ [ns, ns, num_controls[f]] for f, ns in enumerate(num_states)]\n",
    "B = utils.obj_array_zeros(B_f_shapes)\n",
    "B_f_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"STAY\"]\n",
    "\n",
    "for action_id, action_label in enumerate(actions):\n",
    "\n",
    "  for curr_state, grid_location in enumerate(grid_locations):\n",
    "\n",
    "    y, x = grid_location\n",
    "\n",
    "    if action_label == \"UP\":\n",
    "      next_y = y - 1 if y > 0 else y \n",
    "      next_x = x\n",
    "\n",
    "    elif action_label == \"DOWN\":\n",
    "      next_y = y + 1 if y < (grid_dims[0]-1) else y \n",
    "      next_x = x\n",
    "      \n",
    "    elif action_label == \"LEFT\":\n",
    "      next_x = x - 1 if x > 0 else x \n",
    "      next_y = y\n",
    "    elif action_label == \"RIGHT\":\n",
    "      next_x = x + 1 if x < (grid_dims[1]-1) else x \n",
    "      next_y = y\n",
    "    elif action_label == \"STAY\":\n",
    "      next_x = x\n",
    "      next_y = y\n",
    "\n",
    "    new_location = (next_y, next_x)\n",
    "    next_state = grid_locations.index(new_location)\n",
    "    B[0][next_state, curr_state, action_id] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C Vectors (prior preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "C = utils.obj_array_zeros(num_obs)  # Initialize C array with shape matching num_obs\n",
    "print(C.shape)\n",
    "\n",
    "# Set preferences for state observations (location)\n",
    "C[0] = np.zeros(len(grid_locations))\n",
    "\n",
    "print(C[0])\n",
    "\n",
    "# Set preferences for safety observations\n",
    "C[1] = np.zeros(len(safety))\n",
    "C[1][1] = -1  # Negative preference for red spots\n",
    "C[1][0] = 1 # Positive preference for safe spots\n",
    "\n",
    "# Set preferences for goal observations\n",
    "C[2] = np.zeros(len(goal))\n",
    "C[2][1] = 1  # Positive preference for reaching the goal\n",
    "C[2][0] = 0 # No preference for empty spots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_likelihood((C[0]), title_str = 'Probability of safety)')\n",
    "# plot_likelihood((C[1]), title_str = 'Probability of safety)')\n",
    "# plot_likelihood((C[2]), title_str = 'Probability of safety)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = utils.obj_array_zeros(num_obs)\n",
    "\n",
    "# C[1][1] = -5 # negative preference for red spots (punishment)\n",
    "# C[2][1] = 20 # preference for end goal (reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D Vectors: Prior over (initial) hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = utils.obj_array_uniform(num_states)\n",
    "D[0] = utils.onehot(grid_locations.index((0,0)), len(grid_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vision(current_location, grid_dims, distance):\n",
    "    \"\"\"\n",
    "    Update the agent's field of vision based on the current location and distance\n",
    "    Returns a list of all grid positions within the vision range\n",
    "    \n",
    "    Args:\n",
    "        current_location (tuple): Current (y,x) position of the agent\n",
    "        grid_dims (list): Dimensions of the grid [height, width]\n",
    "        distance (int): Vision range/distance\n",
    "        \n",
    "    Returns:\n",
    "        list: List of (y,x) tuples representing visible grid positions\n",
    "    \"\"\"\n",
    "    y, x = current_location\n",
    "    y_min = max(0, y - distance)\n",
    "    y_max = min(grid_dims[0], y + distance + 1)\n",
    "    x_min = max(0, x - distance)\n",
    "    x_max = min(grid_dims[1], x + distance + 1)\n",
    "    \n",
    "    visible_locations = []\n",
    "    for y_pos in range(y_min, y_max):\n",
    "        for x_pos in range(x_min, x_max):\n",
    "            visible_locations.append((y_pos, x_pos))\n",
    "            \n",
    "    return visible_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 0, 0\n",
    "\n",
    "class GridWorldEnv():\n",
    "\n",
    "    def __init__(self, starting_loc = (0, 0), red1_loc = (1, 2), red2_loc = (3,2), red3_loc = (4,4), red4_loc = (6, 1), goal = (6 ,4)):\n",
    "        self.init_loc = starting_loc\n",
    "        self.current_location = self.init_loc\n",
    "        Y, X = self.current_location\n",
    "\n",
    "        self.red1_loc = red1_loc\n",
    "        self.red2_loc = red2_loc\n",
    "        self.red3_loc = red3_loc\n",
    "        self.red4_loc = red4_loc\n",
    "        self.redspots = [self.red1_loc, self.red2_loc, self.red3_loc, self.red4_loc]\n",
    "\n",
    "        self.goal = goal\n",
    "\n",
    "        self.red_obs = ['Null']\n",
    "        self.goal_obs = 'Null'\n",
    "        self.empty_obs = ['Null']\n",
    "\n",
    "        self.agent_reward = 0\n",
    "\n",
    "        print(f\"Starting location is {self.init_loc} | Red spot locations are {self.red1_loc, self.red2_loc, self.red3_loc, self.red4_loc} | Goal is {self.goal}\")\n",
    "    \n",
    "    def step(self, action_label):\n",
    "\n",
    "        Y, X = self.current_location\n",
    "\n",
    "\n",
    "        if action_label == \"UP\": \n",
    "          if Y < grid_dims[0] - 1: Y_new = Y + 1\n",
    "          else: Y_new = Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"DOWN\": \n",
    "        \n",
    "          if Y > 0: Y_new = Y - 1\n",
    "          else: Y_new = Y\n",
    "          X_new = X      \n",
    "\n",
    "        elif action_label == \"LEFT\": \n",
    "          \n",
    "          if X > 0: X_new = X - 1\n",
    "          else: X_new = X\n",
    "          Y_new = Y\n",
    "\n",
    "        elif action_label == \"RIGHT\": \n",
    "          \n",
    "          if X < grid_dims[1] - 1: X_new = X + 1\n",
    "          else: X_new = X\n",
    "          Y_new = Y\n",
    "\n",
    "        elif action_label == \"STAY\":\n",
    "          Y_new, X_new = Y, X\n",
    "        \n",
    "        X, Y = X_new, Y_new\n",
    "        self.current_location = (Y_new, X_new) # store the new grid location\n",
    "        self.vision = update_vision(self.current_location, grid_dims, 7)\n",
    "\n",
    "        self.loc_obs = self.current_location # agent directly observes its position in grid\n",
    "\n",
    "        for spot in self.vision:\n",
    "            if spot in self.redspots:\n",
    "                if 'Null' in self.red_obs:\n",
    "                    self.red_obs = [spot]\n",
    "                else:\n",
    "                    self.red_obs.append(spot)\n",
    "            elif spot == self.goal:\n",
    "                self.goal_obs = spot\n",
    "            else:\n",
    "                if 'Null' in self.empty_obs:\n",
    "                    self.empty_obs = [spot]\n",
    "                else:\n",
    "                    self.empty_obs.append(spot)\n",
    "\n",
    "\n",
    "        if self.current_location in self.redspots:\n",
    "            self.agent_reward -= 5\n",
    "            if 'Null' in self.red_obs:\n",
    "                self.red_obs = [self.current_location]\n",
    "            else:\n",
    "                self.red_obs.append(self.current_location)\n",
    "        elif self.current_location == self.goal:\n",
    "            self.agent_reward += 20\n",
    "            self.goal_obs = self.current_location\n",
    "        else:\n",
    "            if 'Null' in self.empty_obs:\n",
    "                self.empty_obs = [self.current_location]\n",
    "            else:\n",
    "                self.empty_obs.append(self.current_location)\n",
    "        \n",
    "        return self.agent_reward, self.loc_obs, self.goal_obs, self.empty_obs, self.red_obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_location = self.init_loc\n",
    "        print(f'Re-initialized location to {self.init_loc}')\n",
    "        self.loc_obs = self.current_location\n",
    "        self.goal_obs, self.empty_obs, self.red_obs, self.agent_reward = 'Null', ['Null'], ['Null'], 0\n",
    "\n",
    "        return self.loc_obs, self.goal_obs, self.empty_obs, self.red_obs, self.agent_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting location is (0, 0) | Red spot locations are ((1, 2), (3, 2), (4, 4), (6, 1)) | Goal is (6, 4)\n",
      "Re-initialized location to (0, 0)\n"
     ]
    }
   ],
   "source": [
    "my_agent = Agent(A = A, B = B, C = C, D = D, policy_len = 4)\n",
    "\n",
    "my_env = GridWorldEnv(starting_loc = (0, 0), red1_loc = (1, 2), red2_loc = (3,2), red3_loc = (4,4), red4_loc = (6, 1), goal = (6 ,4))\n",
    "\n",
    "loc_obs, goal_obs, empty_obs, red_obs, agent_reward = my_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0), 'Null', ['Null'], ['Null'], 0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_obs, goal_obs, empty_obs, red_obs, agent_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action at time 0: [1.]\n",
      "Grid location at time 0: (0, 0)\n",
      "Reward at time 0: 0\n",
      "Action at time 1: [0.]\n",
      "Grid location at time 1: (1, 0)\n",
      "Reward at time 1: 0\n",
      "Action at time 2: [2.]\n",
      "Grid location at time 2: (1, 0)\n",
      "Reward at time 2: 0\n",
      "Action at time 3: [4.]\n",
      "Grid location at time 3: (1, 0)\n",
      "Reward at time 3: 0\n",
      "Action at time 4: [2.]\n",
      "Grid location at time 4: (1, 0)\n",
      "Reward at time 4: 0\n",
      "Action at time 5: [4.]\n",
      "Grid location at time 5: (1, 0)\n",
      "Reward at time 5: 0\n",
      "Action at time 6: [2.]\n",
      "Grid location at time 6: (1, 0)\n",
      "Reward at time 6: 0\n",
      "Action at time 7: [4.]\n",
      "Grid location at time 7: (1, 0)\n",
      "Reward at time 7: 0\n",
      "Action at time 8: [2.]\n",
      "Grid location at time 8: (1, 0)\n",
      "Reward at time 8: 0\n",
      "Action at time 9: [4.]\n",
      "Grid location at time 9: (1, 0)\n",
      "Reward at time 9: 0\n",
      "Action at time 10: [2.]\n",
      "Grid location at time 10: (1, 0)\n",
      "Reward at time 10: 0\n",
      "Action at time 11: [4.]\n",
      "Grid location at time 11: (1, 0)\n",
      "Reward at time 11: 0\n"
     ]
    }
   ],
   "source": [
    "history_of_locs = [loc_obs]\n",
    "\n",
    "T = 12\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    # Feed Observations ft. infer_states function\n",
    "    for spot in grid_locations:\n",
    "        obs = [grid_locations.index(spot)]\n",
    "\n",
    "        # spot, safety, goal\n",
    "        if spot in red_obs:\n",
    "            obs.append(1)\n",
    "        else:\n",
    "            obs.append(0)\n",
    "        \n",
    "        if spot == goal_obs:\n",
    "            obs.append(1)\n",
    "        else:\n",
    "            obs.append(0)\n",
    "\n",
    "        qs = my_agent.infer_states(obs)\n",
    "    \n",
    "    my_agent.infer_policies()\n",
    "    chosen_action_id = my_agent.sample_action()\n",
    "\n",
    "    print(f'Action at time {t}: {chosen_action_id}')\n",
    "\n",
    "    movement_id = int(chosen_action_id[0])\n",
    "\n",
    "    choice_action = actions[movement_id]\n",
    "    \n",
    "    agent_reward, loc_obs, goal_obs, empty_obs, red_obs = my_env.step(choice_action)\n",
    "    \n",
    "    history_of_locs.append(loc_obs)\n",
    "\n",
    "    print(f\"Grid location at time {t}: {loc_obs}\")\n",
    "\n",
    "    print(f'Reward at time {t}: {agent_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
