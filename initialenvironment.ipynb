{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment: Gridworld\n",
    "\n",
    "Task: Get to some point X (given). Avoid red spots (some points are red and the agent doesn’t wanna go on those).\n",
    "\n",
    "### Info:\n",
    "GRID: 7 by 5 \\\n",
    "Number of red spots: 4 \\\n",
    "Positions of red spots: red1, red2, red3, red4 = (randomly define locations for each one) \\\n",
    "Red_spots = [(1, 2), (6, 1), (3, 2), (4, 4)]\n",
    "\n",
    "### S\n",
    "Location of Agent \\\n",
    "    Agent_pos = (x, y)\n",
    "\n",
    "Locations of Red Spots: \\\n",
    "Agent Map = Belixef of Possible Locations on Grid \\\n",
    "    Possible_locations = dict((1,1) : False) \\\n",
    "        1st component = location \\\n",
    "        2nd component encodes whether it’s a red spot (true) or safe (false)\n",
    "\n",
    "### T\n",
    "Location of Agent \\\n",
    "    Environmental Constraints \\\n",
    "        If agent_pos[0] == 0: P(a = LEFT) = 0  \\\n",
    "        If agent_pos[1] == 0: P(a = DOWN) = 0  \\\n",
    "        If agent_pos[0] ==  6: P(a = RIGHT) = 0  \\\n",
    "        If agent_pos[1] == 4: P(a = UP) = 0 \\\n",
    "If a == RIGHT: agent_pos[0] += 1 \\\n",
    "If a == LEFT: agent_pos[0] -= 1 \\\n",
    "If a == UP: agent_pos[1] += 1 \\\n",
    "If a == DOWN: agent_pos[1] -= 1\n",
    "\n",
    "### R\n",
    "Reward_points = 0 \\\n",
    "Redspot: If agent_pos in redspots: reward_points -= 5 \\\n",
    "Endgoal \\\n",
    "    If agent_pos == (4, 6): reward_points += 20\n",
    "\n",
    "\n",
    "### set of observations (dimensionality of 2)\n",
    "Observation \\\n",
    "    Observed_spot \\\n",
    "        ((x, y), True/False) \\\n",
    "    Possible_locations.append(observed_spot)\n",
    "\n",
    "O is set of conditional observation probabilities (prior preference) \\\n",
    "    C = C matrix \\\n",
    "    C[(4,6)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pymdp\n",
    "from pymdp import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(grid_locations, num_x = 3, num_y = 3 ):\n",
    "    \"\"\"\n",
    "    Plots the spatial coordinates of GridWorld as a heatmap, with each (X, Y) coordinate \n",
    "    labeled with its linear index (its `state id`)\n",
    "    \"\"\"\n",
    "\n",
    "    grid_heatmap = np.zeros((num_x, num_y))\n",
    "    for linear_idx, location in enumerate(grid_locations):\n",
    "      y, x = location\n",
    "      grid_heatmap[y, x] = linear_idx\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.heatmap(grid_heatmap, annot=True, cbar = False, fmt='.0f', cmap='crest')\n",
    "\n",
    "def plot_likelihood(matrix, title_str = \"Likelihood distribution (A)\"):\n",
    "    \"\"\"\n",
    "    Plots a 2-D likelihood matrix as a heatmap\n",
    "    \"\"\"\n",
    "\n",
    "    if not np.isclose(matrix.sum(axis=0), 1.0).all():\n",
    "      raise ValueError(\"Distribution not column-normalized! Please normalize (ensure matrix.sum(axis=0) == 1.0 for all columns)\")\n",
    "    \n",
    "    fig = plt.figure(figsize = (6,6))\n",
    "    ax = sns.heatmap(matrix, cmap = 'gray', cbar = False, vmin = 0.0, vmax = 1.0)\n",
    "    plt.title(title_str)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_beliefs(belief_dist, title_str=\"\"):\n",
    "    \"\"\"\n",
    "    Plot a categorical distribution or belief distribution, stored in the 1-D numpy vector `belief_dist`\n",
    "    \"\"\"\n",
    "\n",
    "    if not np.isclose(belief_dist.sum(), 1.0):\n",
    "      raise ValueError(\"Distribution not normalized! Please normalize\")\n",
    "\n",
    "    plt.grid(zorder=0)\n",
    "    plt.bar(range(belief_dist.shape[0]), belief_dist, color='r', zorder=3)\n",
    "    plt.xticks(range(belief_dist.shape[0]))\n",
    "    plt.title(title_str)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_dimensions\n",
    "grid_dims = [7,5]\n",
    "num_grid_points = np.prod(grid_dims) # total number of grid locations (rows X columns)\n",
    "\n",
    "# setup matrix\n",
    "grid = np.arange(num_grid_points).reshape(grid_dims) # arange -> creates list; reshape -> makes it in the shape specified by grid_dims\n",
    "\n",
    "# define red spots\n",
    "grid[(1, 2)] = 1\n",
    "grid[(3, 2)] = 1\n",
    "grid[(4, 4)] = 1\n",
    "grid[(6, 1)] = 1\n",
    "\n",
    "# list of grid positiions\n",
    "grid_locations = []\n",
    "it = np.nditer(grid, flags=[\"multi_index\"]) # set up the iterator to go throgh the matrix\n",
    "while not it.finished:\n",
    "    grid_locations.append(it.multi_index)\n",
    "    it.iternext()\n",
    "\n",
    "grid, grid_locations\n",
    "\n",
    "redspots = [(1,2), (3,2), (4,4), (6,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the agent hidden state\n",
    "agent_pos = (0,0)\n",
    "\n",
    "goal_location = (6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual gridworld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up figure & grid\n",
    "fig: The entire figure (canvas) where the grid and visual elements will be plotted; ax: The specific axis (plot area) for drawing the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to create the visual grid. \\\n",
    "np.meshgrid defines/creates it. \\\n",
    "The other functions are purely visuals. \\\n",
    "FIGURE OUT WHY WE HAVE TO REDEFINE IT LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8, 6))  # Properly sized figure\n",
    "\n",
    "# # Create grid\n",
    "# X, Y = np.meshgrid(np.arange(grid_dims[1] + 1), np.arange(grid_dims[0] + 1))  # 5x7 grid\n",
    "# h = ax.pcolormesh(X, Y, np.zeros(grid_dims), edgecolors='k', linewidth=3, cmap='coolwarm')  # Base grid\n",
    "\n",
    "# # Add goal (green square)\n",
    "# ax.add_patch(\n",
    "#     plt.Rectangle((4, 6), width=1, height=1, color='green')  # Adjusted coordinates for grid alignment\n",
    "# )\n",
    "\n",
    "# # Add red obstacles\n",
    "# red_obstacles = [(2, 1), (1, 6), (2, 3), (4, 4)]  # List of (x, y) coordinates for red obstacles\n",
    "# for red in red_obstacles:\n",
    "#     ax.add_patch(\n",
    "#         plt.Rectangle((red[0], red[1]), width=1, height=1, color='red')\n",
    "#     )\n",
    "\n",
    "# # Add entry point (white square)\n",
    "# ax.add_patch(\n",
    "#     plt.Rectangle((0, 0), width=1, height=1, color='white')\n",
    "# )\n",
    "\n",
    "# # Add agent (black circle)\n",
    "# ax.add_patch(\n",
    "#     plt.Circle((agent_pos[0] + 0.5, agent_pos[1] + 0.5), radius=0.25, color='black')\n",
    "# )\n",
    "\n",
    "# # Set grid limits and labels\n",
    "# ax.set_xlim(0, grid_dims[1])\n",
    "# ax.set_ylim(0, grid_dims[0])\n",
    "# ax.set_aspect('equal')\n",
    "# ax.set_xticks(np.arange(grid_dims[1]) + 0.5)\n",
    "# ax.set_yticks(np.arange(grid_dims[0]) + 0.5)\n",
    "# ax.set_xticklabels(np.arange(grid_dims[1]))\n",
    "# ax.set_yticklabels(np.arange(grid_dims[0]))\n",
    "# plt.gca().invert_yaxis()  # Invert y-axis to match typical grid orientation\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 6)) # idk why we need to redefine this. FIGURE IT OUT LATER\n",
    "\n",
    "# # create grid\n",
    "# X, Y = np.meshgrid(np.arange(grid_dims[1]+1), np.arange(grid_dims[0]+1))\n",
    "# print(X, Y)\n",
    "# # grid visuals\n",
    "# h = ax.pcolormesh(X, Y, np.ones([5, 7]), edgecolors='k', vmin = 0, vmax = 30, linewidth=3, cmap = 'coolwarm')\n",
    "\n",
    "# # goal\n",
    "# desired_location = ax.add_patch(\n",
    "#     plt.Rectangle((4, 6), width=1, height=1, color='green')\n",
    "# )\n",
    "\n",
    "# # red spots\n",
    "# red1 = ax.add_patch(\n",
    "#     plt.Rectangle((1, 2), width=1, height=1, color='red')\n",
    "# )\n",
    "# red2 = ax.add_patch(\n",
    "#     plt.Rectangle((6, 1), width=1, height=1, color='red')\n",
    "# )\n",
    "# red3 = ax.add_patch(\n",
    "#     plt.Rectangle((3, 2), width=1, height=1, color='red')\n",
    "# )\n",
    "# red4 = ax.add_patch(\n",
    "#     plt.Rectangle((4, 4), width=1, height=1, color='red')\n",
    "# )\n",
    "\n",
    "# # entry spot\n",
    "# entry = ax.add_patch(\n",
    "#     plt.Rectangle((0, 0), width=1, height=1, color='white')\n",
    "# )\n",
    "# agent_icon = ax.add_patch(\n",
    "#     plt.Circle((agent_pos[0] + 0.5, agent_pos[1] + 0.5), radius=0.25, color='black')\n",
    "# )\n",
    "\n",
    "\n",
    "# desired_location = ax.add_patch(\n",
    "#     plt.Rectangle((6, 4), width=1, height=1, color='green')\n",
    "# )\n",
    "\n",
    "# # ax.set_xlim(0, grid_dims[1])\n",
    "# # ax.set_ylim(0, grid_dims[0])\n",
    "# # ax.set_aspect('equal')\n",
    "# # ax.set_xticks(np.arange(grid_dims[1]) + 0.5)\n",
    "# # ax.set_yticks(np.arange(grid_dims[0]) + 0.5)\n",
    "# # ax.set_xticklabels(np.arange(grid_dims[1]))\n",
    "# # ax.set_yticklabels(np.arange(grid_dims[0]))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reward\n",
    "# reward_conditions_positive = ['END GOAL']\n",
    "# reward_locations_positive = [(6,4)]\n",
    "# reward_conditions_negative = ['RED1', 'RED2', 'RED3', 'RED4']\n",
    "# reward_locations_negative = [(1, 2), (6, 1), (3, 2), (4, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_names = ['SAFE', 'RED']\n",
    "# choice_names = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "\n",
    "# num_states = [len(context_names), len(choice_names)]\n",
    "# num_factors = len(num_states)\n",
    "\n",
    "# context_action_names = ['Do-nothing']\n",
    "# choice_action_names = ['Move-up', 'Move-down', 'Move-left', 'Move-right']\n",
    "\n",
    "# num_controls = [len(context_action_names), len(choice_action_names)]\n",
    "\n",
    "# loc_obs_attributes = ['SAFE', 'DANGER', 'GOAL']\n",
    "# # agent's belief about map hidden state\n",
    "# map_obs = {\n",
    "#     (0,0) : False,\n",
    "#     (0, 1) : False,\n",
    "#     (1, 0) : False,\n",
    "#     (1, 1) : False,\n",
    "# }\n",
    "\n",
    "# num_obs = [len(loc_obs_attribute), len(loc_obs_map)]\n",
    "# num_modalities = len(num_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden states s have these hidden state factors:\n",
    "1. Location (as many levels as there are grid locations)\n",
    "\n",
    "The observations!!:\n",
    "1. Positions\n",
    "2. Safety (2 hidden state levels - safe or dangerous/red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = [len(grid_locations)] # location\n",
    "\n",
    "safety = ['EMPTY', 'RED'] # obs\n",
    "goal = ['EMPTY', 'GOAL']\n",
    "\n",
    "num_obs = [len(grid_locations), len(safety), len(goal)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 35], [2, 35], [2, 35]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_m_shapes = [ [o_dim] + num_states for o_dim in num_obs] # list of shapes of modality-specific A[m] arrays\n",
    "A = utils.obj_array_zeros(A_m_shapes) # initialize A array to an object array of all-zero subarrays\n",
    "A_m_shapes # 2 types of observations, one type of state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location observation modality: A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A[0] = np.eye(num_grid_points)\n",
    "\n",
    "# # Safety observations (probability 1 for the safe state, 0 for the dangerous one)\n",
    "# A[1] = np.zeros((2, num_grid_points))  # safety matrix initialized to 0\n",
    "# A[1][0, 0] = 1  # Safe state (SAFE) for the first grid point, probability 1\n",
    "# A[1][1, 0] = 0  # Danger (RED) for the first grid point, probability 0\n",
    "\n",
    "# A[2][0, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality 0 column sums before check: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Modality 1 column sums before check: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Modality 2 column sums before check: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "A = utils.obj_array_zeros(A_m_shapes)\n",
    "A[0] = np.eye(num_grid_points)  # Location observations (one-hot encoded)\n",
    "\n",
    "# Safety observations\n",
    "A[1] = np.zeros((2, num_grid_points))\n",
    "A[1][0, 0] = 1  # Safe state probability\n",
    "A[1][1, 0] = 0  # Danger state probability\n",
    "\n",
    "# For remaining columns in A[1], we need to set probabilities\n",
    "# Let's say for now all other states are \"safe\"\n",
    "A[1][0, 1:] = 1  # Set all other states as safe\n",
    "A[1][1, 1:] = 0  # Set all other states as not dangerous\n",
    "\n",
    "# Do the same for A[2]\n",
    "A[2] = np.zeros((2, num_grid_points))\n",
    "A[2][0, 0] = 1\n",
    "A[2][1, 0] = 0\n",
    "A[2][0, 1:] = 1\n",
    "A[2][1, 1:] = 0\n",
    "\n",
    "# Verify normalization\n",
    "for modality in range(len(A)):\n",
    "    column_sums = np.sum(A[modality], axis=0)\n",
    "    print(f\"Modality {modality} column sums before check:\", column_sums)\n",
    "    \n",
    "    # Each column should sum to 1\n",
    "    assert np.allclose(column_sums, 1.0), f\"Modality {modality} is not normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_likelihood((A[2]), title_str = 'Probability of safety)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = utils.obj_array(num_modalities)\n",
    "\n",
    "# p_safe = 0.5\n",
    "# p_danger = 1 - p_safe\n",
    "\n",
    "# A_loc_attribute = np.zeros((len(loc_obs_attributes), len(context_names), len(choice_names)))\n",
    "\n",
    "# for choice_id, choice_name in enumerate(choice_names):\n",
    "#     if choice_name == 'UP':\n",
    "#         A_loc_attribute[0,:,choice_id] =  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 35, 5]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_controls = [5]\n",
    "B_f_shapes = [ [ns, ns, num_controls[f]] for f, ns in enumerate(num_states)]\n",
    "B = utils.obj_array_zeros(B_f_shapes)\n",
    "B_f_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"STAY\"]\n",
    "\n",
    "for action_id, action_label in enumerate(actions):\n",
    "\n",
    "  for curr_state, grid_location in enumerate(grid_locations):\n",
    "\n",
    "    y, x = grid_location\n",
    "\n",
    "    if action_label == \"UP\":\n",
    "      next_y = y - 1 if y > 0 else y \n",
    "      next_x = x\n",
    "\n",
    "    elif action_label == \"DOWN\":\n",
    "      next_y = y + 1 if y < (grid_dims[0]-1) else y \n",
    "      next_x = x\n",
    "    elif action_label == \"LEFT\":\n",
    "      next_x = x - 1 if x > 0 else x \n",
    "      next_y = y\n",
    "    elif action_label == \"RIGHT\":\n",
    "      next_x = x + 1 if x < (grid_dims[1]-1) else x \n",
    "      next_y = y\n",
    "    elif action_label == \"STAY\":\n",
    "      next_x = x\n",
    "      next_y = y\n",
    "\n",
    "    new_location = (next_y, next_x)\n",
    "    next_state = grid_locations.index(new_location)\n",
    "    B[0][next_state, curr_state, action_id] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C Vectors (prior preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C = utils.obj_array_zeros(num_obs)  # Initialize C array with shape matching num_obs\n",
    "\n",
    "# Set preferences for state observations (location)\n",
    "C[0] = np.zeros(len(grid_locations))\n",
    "\n",
    "# Set preferences for safety observations\n",
    "C[1] = np.zeros(len(safety))\n",
    "C[1][1] = -5.0  # Negative preference for red spots\n",
    "\n",
    "# Set preferences for goal observations\n",
    "C[2] = np.zeros(len(goal))\n",
    "C[2][1] = 20.0  # Positive preference for reaching the goal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = utils.obj_array_zeros(num_obs)\n",
    "\n",
    "# C[1][1] = -5 # negative preference for red spots (punishment)\n",
    "# C[2][1] = 20 # preference for end goal (reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D Vectors: Prior over (initial) hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = utils.obj_array_uniform(num_states)\n",
    "D[0] = utils.onehot(grid_locations.index((0,0)), len(grid_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vision(current_location, grid_dims, distance):\n",
    "    \"\"\"\n",
    "    Update the agent's field of vision based on the current location and distance\n",
    "    Returns a list of all grid positions within the vision range\n",
    "    \n",
    "    Args:\n",
    "        current_location (tuple): Current (y,x) position of the agent\n",
    "        grid_dims (list): Dimensions of the grid [height, width]\n",
    "        distance (int): Vision range/distance\n",
    "        \n",
    "    Returns:\n",
    "        list: List of (y,x) tuples representing visible grid positions\n",
    "    \"\"\"\n",
    "    y, x = current_location\n",
    "    y_min = max(0, y - distance)\n",
    "    y_max = min(grid_dims[0], y + distance + 1)\n",
    "    x_min = max(0, x - distance)\n",
    "    x_max = min(grid_dims[1], x + distance + 1)\n",
    "    \n",
    "    visible_locations = []\n",
    "    for y_pos in range(y_min, y_max):\n",
    "        for x_pos in range(x_min, x_max):\n",
    "            visible_locations.append((y_pos, x_pos))\n",
    "            \n",
    "    return visible_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 0, 0\n",
    "\n",
    "class GridWorldEnv():\n",
    "\n",
    "    def __init__(self, starting_loc = (0, 0), red1_loc = (1, 2), red2_loc = (3,2), red3_loc = (4,4), red4_loc = (6, 1), goal = (6 ,4)):\n",
    "        self.init_loc = starting_loc\n",
    "        self.current_location = self.init_loc\n",
    "        Y, X = self.current_location\n",
    "\n",
    "        self.red1_loc = red1_loc\n",
    "        self.red2_loc = red2_loc\n",
    "        self.red3_loc = red3_loc\n",
    "        self.red4_loc = red4_loc\n",
    "        self.redspots = [self.red1_loc, self.red2_loc, self.red3_loc, self.red4_loc]\n",
    "\n",
    "        self.goal = goal\n",
    "\n",
    "        self.red_obs = ['Null']\n",
    "        self.goal_obs = 'Null'\n",
    "        self.empty_obs = ['Null']\n",
    "\n",
    "        self.agent_reward = 0\n",
    "\n",
    "        print(f\"Starting location is {self.init_loc} | Red spot locations are {self.red1_loc, self.red2_loc, self.red3_loc, self.red4_loc} | Goal is {self.goal}\")\n",
    "    \n",
    "    def step(self, action_label):\n",
    "\n",
    "        Y, X = self.current_location\n",
    "\n",
    "        if action_label == \"DOWN\": \n",
    "          if Y < grid_dims[0] - 1: Y_new = Y + 1\n",
    "          else: Y_new = Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"UP\": \n",
    "        \n",
    "          if Y > 0: Y_new = Y - 1\n",
    "          else: Y_new = Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"LEFT\": \n",
    "          \n",
    "          if X > 0: X_new = X - 1\n",
    "          else: X_new = X\n",
    "          Y_new = Y\n",
    "\n",
    "        elif action_label == \"RIGHT\": \n",
    "          \n",
    "          if X < grid_dims[1] - 1: X_new = X + 1\n",
    "          else: X_new = X\n",
    "          Y_new = Y\n",
    "\n",
    "        elif action_label == \"STAY\":\n",
    "          Y_new, X_new = Y, X\n",
    "        \n",
    "        X, Y = X_new, Y_new\n",
    "        current_location = (Y_new, X_new) # store the new grid location\n",
    "        self.vision = update_vision(current_location, grid_dims, 7)\n",
    "\n",
    "        loc_obs = self.current_location # agent directly observes its position in grid\n",
    "\n",
    "\n",
    "        for spot in self.vision:\n",
    "            if spot in self.redspots:\n",
    "                if 'Null' in self.red_obs:\n",
    "                    self.red_obs = [spot]\n",
    "                else:\n",
    "                    self.red_obs.append(spot)\n",
    "            elif spot == self.goal:\n",
    "                self.goal_obs = spot\n",
    "            else:\n",
    "                if 'Null' in self.empty_obs:\n",
    "                    self.empty_obs = [spot]\n",
    "                else:\n",
    "                    self.empty_obs.append(spot)\n",
    "\n",
    "\n",
    "        if self.current_location in self.redspots:\n",
    "            self.agent_reward -= 5\n",
    "            if 'Null' in self.red_obs:\n",
    "                self.red_obs = [self.current_location]\n",
    "            else:\n",
    "                self.red_obs.append(self.current_location)\n",
    "        elif self.current_location == self.goal:\n",
    "            self.agent_reward += 20\n",
    "            self.goal_obs = current_location\n",
    "        else:\n",
    "            if 'Null' in self.empty_obs:\n",
    "                self.empty_obs = [self.current_location]\n",
    "            else:\n",
    "                self.empty_obs.append(self.current_location)\n",
    "        \n",
    "        return self.agent_reward, self.loc_obs, self.goal_obs, self.empty_obs, self.red_obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_location = self.init_loc\n",
    "        print(f'Re-initialized location to {self.init_loc}')\n",
    "        self.loc_obs = self.current_location\n",
    "        self.goal_obs, self.empty_obs, self.red_obs, self.agent_reward = 'Null', ['Null'], ['Null'], 0\n",
    "\n",
    "        return self.loc_obs, self.goal_obs, self.empty_obs, self.red_obs, self.agent_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting location is (0, 0) | Red spot locations are ((1, 2), (3, 2), (4, 4), (6, 1)) | Goal is (6, 4)\n",
      "Re-initialized location to (0, 0)\n"
     ]
    }
   ],
   "source": [
    "my_agent = Agent(A = A, B = B, C = C, D = D, policy_len = 4)\n",
    "\n",
    "my_env = GridWorldEnv(starting_loc = (0, 0), red1_loc = (1, 2), red2_loc = (3,2), red3_loc = (4,4), red4_loc = (6, 1), goal = (6 ,4))\n",
    "\n",
    "loc_obs, goal_obs, empty_obs, red_obs, agent_reward = my_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0), 'Null', ['Null'], ['Null'], 0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_obs, goal_obs, empty_obs, red_obs, agent_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action at time 0: UP\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 0: (0, 0)\n",
      "Reward at time 0: 0\n",
      "Action at time 1: DOWN\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 1: (0, 0)\n",
      "Reward at time 1: 0\n",
      "Action at time 2: UP\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 2: (0, 0)\n",
      "Reward at time 2: 0\n",
      "Action at time 3: DOWN\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 3: (0, 0)\n",
      "Reward at time 3: 0\n",
      "Action at time 4: UP\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 4: (0, 0)\n",
      "Reward at time 4: 0\n",
      "Action at time 5: DOWN\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 5: (0, 0)\n",
      "Reward at time 5: 0\n",
      "Action at time 6: UP\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 6: (0, 0)\n",
      "Reward at time 6: 0\n",
      "Action at time 7: DOWN\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 7: (0, 0)\n",
      "Reward at time 7: 0\n",
      "Action at time 8: UP\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 8: (0, 0)\n",
      "Reward at time 8: 0\n",
      "Action at time 9: DOWN\n",
      "0 (0, 0) (6, 4) [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0), (0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (5, 0), (5, 1), (5, 2), (5, 3), (5, 4), (6, 0), (6, 2), (6, 3), (0, 0)] [(1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1), (1, 2), (3, 2), (4, 4), (6, 1)]\n",
      "Grid location at time 9: (0, 0)\n",
      "Reward at time 9: 0\n"
     ]
    }
   ],
   "source": [
    "history_of_locs = [loc_obs]\n",
    "\n",
    "T = 10\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    # Feed Observations ft. infer_states function\n",
    "    for spot in grid_locations:\n",
    "        obs = [grid_locations.index(spot)]\n",
    "\n",
    "        # spot, safety, goal\n",
    "        if spot in red_obs:\n",
    "            obs.append(1)\n",
    "        else:\n",
    "            obs.append(0)\n",
    "        \n",
    "        if spot == goal_obs:\n",
    "            obs.append(1)\n",
    "        else:\n",
    "            obs.append(0)\n",
    "\n",
    "        qs = my_agent.infer_states(obs)\n",
    "    \n",
    "    my_agent.infer_policies()\n",
    "    chosen_action_id = my_agent.sample_action()\n",
    "\n",
    "    movement_id = int(chosen_action_id[0])\n",
    "\n",
    "    choice_action = actions[movement_id]\n",
    "\n",
    "    print(f'Action at time {t}: {choice_action}')\n",
    "\n",
    "    \n",
    "    agent_reward, loc_obs, goal_obs, empty_obs, red_obs = my_env.step(choice_action)\n",
    "    \n",
    "    print(agent_reward, loc_obs, goal_obs, empty_obs, red_obs)\n",
    "\n",
    "\n",
    "    history_of_locs.append(loc_obs)\n",
    "\n",
    "    print(f'Grid location at time {t}: {loc_obs}')\n",
    "\n",
    "    print(f'Reward at time {t}: {agent_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
