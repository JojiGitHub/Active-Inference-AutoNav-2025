{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment: Gridworld\n",
    "\n",
    "Task: Get to some point X (given). Avoid red spots (some points are red and the agent doesn’t wanna go on those).\n",
    "\n",
    "### Info:\n",
    "GRID: 7 by 5 \\\n",
    "Number of red spots: 4 \\\n",
    "Positions of red spots: red1, red2, red3, red4 = (randomly define locations for each one) \\\n",
    "Red_spots = [(1, 2), (6, 1), (3, 2), (4, 4)]\n",
    "\n",
    "### S\n",
    "Location of Agent \\\n",
    "    Agent_pos = (x, y)\n",
    "\n",
    "Locations of Red Spots: \\\n",
    "Agent Map = Belixef of Possible Locations on Grid \\\n",
    "    Possible_locations = dict((1,1) : False) \\\n",
    "        1st component = location \\\n",
    "        2nd component encodes whether it’s a red spot (true) or safe (false)\n",
    "\n",
    "### T\n",
    "Location of Agent \\\n",
    "    Environmental Constraints \\\n",
    "        If agent_pos[0] == 0: P(a = LEFT) = 0  \\\n",
    "        If agent_pos[1] == 0: P(a = DOWN) = 0  \\\n",
    "        If agent_pos[0] ==  6: P(a = RIGHT) = 0  \\\n",
    "        If agent_pos[1] == 4: P(a = UP) = 0 \\\n",
    "If a == RIGHT: agent_pos[0] += 1 \\\n",
    "If a == LEFT: agent_pos[0] -= 1 \\\n",
    "If a == UP: agent_pos[1] += 1 \\\n",
    "If a == DOWN: agent_pos[1] -= 1\n",
    "\n",
    "### R\n",
    "Reward_points = 0 \\\n",
    "Redspot: If agent_pos in redspots: reward_points -= 5 \\\n",
    "Endgoal \\\n",
    "    If agent_pos == (4, 6): reward_points += 20\n",
    "\n",
    "\n",
    "### set of observations (dimensionality of 2)\n",
    "Observation \\\n",
    "    Observed_spot \\\n",
    "        ((x, y), True/False) \\\n",
    "    Possible_locations.append(observed_spot)\n",
    "\n",
    "O is set of conditional observation probabilities (prior preference) \\\n",
    "    C = C matrix \\\n",
    "    C[(4,6)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pymdp\n",
    "from pymdp import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(grid_locations, num_x = 3, num_y = 3 ):\n",
    "    \"\"\"\n",
    "    Plots the spatial coordinates of GridWorld as a heatmap, with each (X, Y) coordinate \n",
    "    labeled with its linear index (its `state id`)\n",
    "    \"\"\"\n",
    "\n",
    "    grid_heatmap = np.zeros((num_x, num_y))\n",
    "    for linear_idx, location in enumerate(grid_locations):\n",
    "      y, x = location\n",
    "      grid_heatmap[y, x] = linear_idx\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.heatmap(grid_heatmap, annot=True, cbar = False, fmt='.0f', cmap='crest')\n",
    "\n",
    "def plot_likelihood(matrix, title_str = \"Likelihood distribution (A)\"):\n",
    "    \"\"\"\n",
    "    Plots a 2-D likelihood matrix as a heatmap\n",
    "    \"\"\"\n",
    "\n",
    "    if not np.isclose(matrix.sum(axis=0), 1.0).all():\n",
    "      raise ValueError(\"Distribution not column-normalized! Please normalize (ensure matrix.sum(axis=0) == 1.0 for all columns)\")\n",
    "    \n",
    "    fig = plt.figure(figsize = (6,6))\n",
    "    ax = sns.heatmap(matrix, cmap = 'gray', cbar = False, vmin = 0.0, vmax = 1.0)\n",
    "    plt.title(title_str)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_beliefs(belief_dist, title_str=\"\"):\n",
    "    \"\"\"\n",
    "    Plot a categorical distribution or belief distribution, stored in the 1-D numpy vector `belief_dist`\n",
    "    \"\"\"\n",
    "\n",
    "    if not np.isclose(belief_dist.sum(), 1.0):\n",
    "      raise ValueError(\"Distribution not normalized! Please normalize\")\n",
    "\n",
    "    plt.grid(zorder=0)\n",
    "    plt.bar(range(belief_dist.shape[0]), belief_dist, color='r', zorder=3)\n",
    "    plt.xticks(range(belief_dist.shape[0]))\n",
    "    plt.title(title_str)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_dimensions\n",
    "grid_dims = [7,5]\n",
    "num_grid_points = np.prod(grid_dims) # total number of grid locations (rows X columns)\n",
    "\n",
    "# setup matrix\n",
    "grid = np.arange(num_grid_points).reshape(grid_dims) # arange -> creates list; reshape -> makes it in the shape specified by grid_dims\n",
    "\n",
    "# define red spots\n",
    "grid[(1, 2)] = 1\n",
    "grid[(3, 2)] = 1\n",
    "grid[(4, 4)] = 1\n",
    "grid[(6, 1)] = 1\n",
    "\n",
    "# list of grid positiions\n",
    "grid_locations = []\n",
    "it = np.nditer(grid, flags=[\"multi_index\"]) # set up the iterator to go throgh the matrix\n",
    "while not it.finished:\n",
    "    grid_locations.append(it.multi_index)\n",
    "    it.iternext()\n",
    "\n",
    "grid, grid_locations\n",
    "\n",
    "redspots = [(1,2), (3,2), (4,4), (6,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the agent hidden state\n",
    "agent_pos = (0,0)\n",
    "\n",
    "goal_location = (6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual gridworld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up figure & grid\n",
    "fig: The entire figure (canvas) where the grid and visual elements will be plotted; ax: The specific axis (plot area) for drawing the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to create the visual grid. \\\n",
    "np.meshgrid defines/creates it. \\\n",
    "The other functions are purely visuals. \\\n",
    "FIGURE OUT WHY WE HAVE TO REDEFINE IT LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8, 6))  # Properly sized figure\n",
    "\n",
    "# # Create grid\n",
    "# X, Y = np.meshgrid(np.arange(grid_dims[1] + 1), np.arange(grid_dims[0] + 1))  # 5x7 grid\n",
    "# h = ax.pcolormesh(X, Y, np.zeros(grid_dims), edgecolors='k', linewidth=3, cmap='coolwarm')  # Base grid\n",
    "\n",
    "# # Add goal (green square)\n",
    "# ax.add_patch(\n",
    "#     plt.Rectangle((4, 6), width=1, height=1, color='green')  # Adjusted coordinates for grid alignment\n",
    "# )\n",
    "\n",
    "# # Add red obstacles\n",
    "# red_obstacles = [(2, 1), (1, 6), (2, 3), (4, 4)]  # List of (x, y) coordinates for red obstacles\n",
    "# for red in red_obstacles:\n",
    "#     ax.add_patch(\n",
    "#         plt.Rectangle((red[0], red[1]), width=1, height=1, color='red')\n",
    "#     )\n",
    "\n",
    "# # Add entry point (white square)\n",
    "# ax.add_patch(\n",
    "#     plt.Rectangle((0, 0), width=1, height=1, color='white')\n",
    "# )\n",
    "\n",
    "# # Add agent (black circle)\n",
    "# ax.add_patch(\n",
    "#     plt.Circle((agent_pos[0] + 0.5, agent_pos[1] + 0.5), radius=0.25, color='black')\n",
    "# )\n",
    "\n",
    "# # Set grid limits and labels\n",
    "# ax.set_xlim(0, grid_dims[1])\n",
    "# ax.set_ylim(0, grid_dims[0])\n",
    "# ax.set_aspect('equal')\n",
    "# ax.set_xticks(np.arange(grid_dims[1]) + 0.5)\n",
    "# ax.set_yticks(np.arange(grid_dims[0]) + 0.5)\n",
    "# ax.set_xticklabels(np.arange(grid_dims[1]))\n",
    "# ax.set_yticklabels(np.arange(grid_dims[0]))\n",
    "# plt.gca().invert_yaxis()  # Invert y-axis to match typical grid orientation\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 6)) # idk why we need to redefine this. FIGURE IT OUT LATER\n",
    "\n",
    "# # create grid\n",
    "# X, Y = np.meshgrid(np.arange(grid_dims[1]+1), np.arange(grid_dims[0]+1))\n",
    "# print(X, Y)\n",
    "# # grid visuals\n",
    "# h = ax.pcolormesh(X, Y, np.ones([5, 7]), edgecolors='k', vmin = 0, vmax = 30, linewidth=3, cmap = 'coolwarm')\n",
    "\n",
    "# # goal\n",
    "# desired_location = ax.add_patch(\n",
    "#     plt.Rectangle((4, 6), width=1, height=1, color='green')\n",
    "# )\n",
    "\n",
    "# # red spots\n",
    "# red1 = ax.add_patch(\n",
    "#     plt.Rectangle((1, 2), width=1, height=1, color='red')\n",
    "# )\n",
    "# red2 = ax.add_patch(\n",
    "#     plt.Rectangle((6, 1), width=1, height=1, color='red')\n",
    "# )\n",
    "# red3 = ax.add_patch(\n",
    "#     plt.Rectangle((3, 2), width=1, height=1, color='red')\n",
    "# )\n",
    "# red4 = ax.add_patch(\n",
    "#     plt.Rectangle((4, 4), width=1, height=1, color='red')\n",
    "# )\n",
    "\n",
    "# # entry spot\n",
    "# entry = ax.add_patch(\n",
    "#     plt.Rectangle((0, 0), width=1, height=1, color='white')\n",
    "# )\n",
    "# agent_icon = ax.add_patch(\n",
    "#     plt.Circle((agent_pos[0] + 0.5, agent_pos[1] + 0.5), radius=0.25, color='black')\n",
    "# )\n",
    "\n",
    "\n",
    "# desired_location = ax.add_patch(\n",
    "#     plt.Rectangle((6, 4), width=1, height=1, color='green')\n",
    "# )\n",
    "\n",
    "# # ax.set_xlim(0, grid_dims[1])\n",
    "# # ax.set_ylim(0, grid_dims[0])\n",
    "# # ax.set_aspect('equal')\n",
    "# # ax.set_xticks(np.arange(grid_dims[1]) + 0.5)\n",
    "# # ax.set_yticks(np.arange(grid_dims[0]) + 0.5)\n",
    "# # ax.set_xticklabels(np.arange(grid_dims[1]))\n",
    "# # ax.set_yticklabels(np.arange(grid_dims[0]))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reward\n",
    "# reward_conditions_positive = ['END GOAL']\n",
    "# reward_locations_positive = [(6,4)]\n",
    "# reward_conditions_negative = ['RED1', 'RED2', 'RED3', 'RED4']\n",
    "# reward_locations_negative = [(1, 2), (6, 1), (3, 2), (4, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_names = ['SAFE', 'RED']\n",
    "# choice_names = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "\n",
    "# num_states = [len(context_names), len(choice_names)]\n",
    "# num_factors = len(num_states)\n",
    "\n",
    "# context_action_names = ['Do-nothing']\n",
    "# choice_action_names = ['Move-up', 'Move-down', 'Move-left', 'Move-right']\n",
    "\n",
    "# num_controls = [len(context_action_names), len(choice_action_names)]\n",
    "\n",
    "# loc_obs_attributes = ['SAFE', 'DANGER', 'GOAL']\n",
    "# # agent's belief about map hidden state\n",
    "# map_obs = {\n",
    "#     (0,0) : False,\n",
    "#     (0, 1) : False,\n",
    "#     (1, 0) : False,\n",
    "#     (1, 1) : False,\n",
    "# }\n",
    "\n",
    "# num_obs = [len(loc_obs_attribute), len(loc_obs_map)]\n",
    "# num_modalities = len(num_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden states s have these hidden state factors:\n",
    "1. Location (as many levels as there are grid locations)\n",
    "\n",
    "The observations!!:\n",
    "1. Positions\n",
    "2. Safety (2 hidden state levels - safe or dangerous/red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = [len(grid_locations)] # location\n",
    "\n",
    "safety = ['EMPTY', 'RED'] # obs\n",
    "goal = ['EMPTY', 'GOAL']\n",
    "\n",
    "num_obs = [len(grid_locations), len(safety), len(goal)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 35], [2, 35], [2, 35]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_m_shapes = [ [o_dim] + num_states for o_dim in num_obs] # list of shapes of modality-specific A[m] arrays\n",
    "A = utils.obj_array_zeros(A_m_shapes) # initialize A array to an object array of all-zero subarrays\n",
    "A_m_shapes # 2 types of observations, one type of state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location observation modality: A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A[0] = np.eye(num_grid_points)\n",
    "\n",
    "# # Safety observations (probability 1 for the safe state, 0 for the dangerous one)\n",
    "# A[1] = np.zeros((2, num_grid_points))  # safety matrix initialized to 0\n",
    "# A[1][0, 0] = 1  # Safe state (SAFE) for the first grid point, probability 1\n",
    "# A[1][1, 0] = 0  # Danger (RED) for the first grid point, probability 0\n",
    "\n",
    "# A[2][0, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_transition(A, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Add noise to transition matrix while preserving normalization\n",
    "    \n",
    "    Args:\n",
    "        A: Original transition matrix\n",
    "        noise_level: Amount of noise to add (0-1)\n",
    "    \"\"\"\n",
    "    # Generate random noise\n",
    "    noise = np.random.uniform(-noise_level, noise_level, size=A.shape)\n",
    "\n",
    "    print(noise) \n",
    "    \n",
    "    # Add noise to matrix\n",
    "    noisy_A = A + noise\n",
    "    \n",
    "    # Ensure non-negative\n",
    "    noisy_A = np.maximum(noisy_A, 0.0)\n",
    "    \n",
    "    # Normalize columns to sum to 1\n",
    "    noisy_A = noisy_A / noisy_A.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    return noisy_A\n",
    "\n",
    "# Usage:\n",
    "# A = add_noise_to_transition(A, noise_level=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06258829 -0.01181472  0.08306078 ... -0.01512775 -0.03752622\n",
      "  -0.00342062]\n",
      " [-0.09914439 -0.03924097 -0.09778204 ... -0.02325339 -0.02848461\n",
      "   0.03997605]\n",
      " [ 0.09162305  0.01516829 -0.08350082 ...  0.01640085 -0.09493356\n",
      "   0.08239232]\n",
      " ...\n",
      " [ 0.06220714 -0.02224643 -0.0191882  ...  0.03542392  0.03752526\n",
      "  -0.03071102]\n",
      " [ 0.03329871 -0.09343562 -0.0263457  ...  0.04130403 -0.01703541\n",
      "   0.09328128]\n",
      " [-0.04665148  0.01908238  0.01824238 ... -0.02970929 -0.00848467\n",
      "  -0.04047075]]\n",
      "[[-0.0308847   0.02098693  0.06117079  0.01242759 -0.05642428 -0.0935874\n",
      "  -0.03918961  0.05463376 -0.00157286 -0.01190736 -0.05430209 -0.08505713\n",
      "   0.09582235  0.06594381 -0.00676465  0.03674393 -0.07813444 -0.00130902\n",
      "   0.09107851  0.02507639 -0.01997922  0.08952935 -0.05331997  0.09932301\n",
      "   0.00298539  0.04063329 -0.08347785 -0.01605971 -0.01737392  0.00616034\n",
      "  -0.09191633 -0.08234774 -0.09296769 -0.05803777 -0.02690983]\n",
      " [-0.08210134 -0.06265666  0.09469503  0.0390017  -0.09116137 -0.02991221\n",
      "  -0.05617507 -0.07316656 -0.05639427  0.04622176 -0.08646582  0.02518683\n",
      "  -0.09333333  0.04967016 -0.09695185  0.00322149  0.06899757 -0.08541407\n",
      "   0.03813753 -0.01772762  0.05287339  0.05507894 -0.04827526 -0.00970533\n",
      "  -0.05312906 -0.01386789 -0.0443458   0.05896223 -0.06237293  0.09473772\n",
      "   0.02532876 -0.06857689 -0.06716192 -0.09834072  0.08358632]]\n",
      "[[-0.01041172  0.04478     0.03576618 -0.0342704  -0.04440641  0.05859606\n",
      "   0.09085744  0.00400381  0.08661751 -0.07665172 -0.06013646  0.01234838\n",
      "   0.05497256 -0.09137454  0.05047829 -0.06832724 -0.08264621 -0.02875297\n",
      "  -0.0881383   0.01135352 -0.09321335 -0.05779664 -0.06523477  0.0003769\n",
      "  -0.00900026 -0.005218   -0.05366056  0.03516453  0.0667207  -0.07268144\n",
      "  -0.0275986  -0.02979646  0.07470663 -0.09520498 -0.07460067]\n",
      " [-0.00523112  0.05406373 -0.08010393 -0.08433221 -0.07847329 -0.09757861\n",
      "  -0.01592891  0.01820741 -0.0567194   0.00903843  0.05875545 -0.07777997\n",
      "   0.02034516 -0.01269161 -0.05073956  0.04611623  0.00671446 -0.05415422\n",
      "  -0.07083915  0.08108445 -0.03653133  0.02689888 -0.06352197 -0.00014149\n",
      "  -0.04882581 -0.0199263  -0.06355629  0.00190264 -0.01174039  0.02425582\n",
      "   0.04919572 -0.09702585 -0.0193      0.06078515  0.0965644 ]]\n",
      "Modality 0 column sums before check: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Modality 1 column sums before check: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Modality 2 column sums before check: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[array([[0.61720242, 0.        , 0.04241937, ..., 0.        , 0.        ,\n",
      "         0.        ],\n",
      "        [0.        , 0.47110684, 0.        , ..., 0.        , 0.        ,\n",
      "         0.02046038],\n",
      "        [0.05321908, 0.00743775, 0.46805867, ..., 0.01160244, 0.        ,\n",
      "         0.0421697 ],\n",
      "        ...,\n",
      "        [0.0361329 , 0.        , 0.        , ..., 0.73248886, 0.02408983,\n",
      "         0.        ],\n",
      "        [0.01934149, 0.        , 0.        , ..., 0.02921967, 0.6310269 ,\n",
      "         0.04774283],\n",
      "        [0.        , 0.00935702, 0.00931643, ..., 0.        , 0.        ,\n",
      "         0.49110227]])\n",
      " array([[1.        , 1.        , 0.91807437, 0.96290602, 1.        ,\n",
      "         1.        , 1.        , 1.        , 1.        , 0.9553117 ,\n",
      "         1.        , 0.97320919, 1.        , 0.95547728, 1.        ,\n",
      "         0.99690231, 0.93036619, 1.        , 0.96622654, 1.        ,\n",
      "         0.94881045, 0.95187966, 1.        , 1.        , 1.        ,\n",
      "         1.        , 1.        , 0.94346333, 1.        , 0.91394505,\n",
      "         0.97286434, 1.        , 1.        , 1.        , 0.92089696],\n",
      "        [0.        , 0.        , 0.08192563, 0.03709398, 0.        ,\n",
      "         0.        , 0.        , 0.        , 0.        , 0.0446883 ,\n",
      "         0.        , 0.02679081, 0.        , 0.04452272, 0.        ,\n",
      "         0.00309769, 0.06963381, 0.        , 0.03377346, 0.        ,\n",
      "         0.05118955, 0.04812034, 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.05653667, 0.        , 0.08605495,\n",
      "         0.02713566, 0.        , 0.        , 0.        , 0.07910304]])\n",
      " array([[1.        , 0.95079944, 1.        , 1.        , 1.        ,\n",
      "         1.        , 1.        , 0.98218821, 1.        , 0.99030614,\n",
      "         0.9411633 , 1.        , 0.98107986, 1.        , 1.        ,\n",
      "         0.95283621, 0.99273381, 1.        , 1.        , 0.92577661,\n",
      "         1.        , 0.97224351, 1.        , 1.        , 1.        ,\n",
      "         1.        , 1.        , 0.99816537, 1.        , 0.9745098 ,\n",
      "         0.95184431, 1.        , 1.        , 0.93704805, 0.90551093],\n",
      "        [0.        , 0.04920056, 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.01781179, 0.        , 0.00969386,\n",
      "         0.0588367 , 0.        , 0.01892014, 0.        , 0.        ,\n",
      "         0.04716379, 0.00726619, 0.        , 0.        , 0.07422339,\n",
      "         0.        , 0.02775649, 0.        , 0.        , 0.        ,\n",
      "         0.        , 0.        , 0.00183463, 0.        , 0.0254902 ,\n",
      "         0.04815569, 0.        , 0.        , 0.06295195, 0.09448907]])]\n"
     ]
    }
   ],
   "source": [
    "A = utils.obj_array_zeros(A_m_shapes)\n",
    "A[0] = np.eye(num_grid_points)  # Location observations (one-hot encoded)\n",
    "\n",
    "# Safety observations\n",
    "A[1] = np.zeros((2, num_grid_points))\n",
    "A[1][0, 0] = 1  # Safe state probability\n",
    "A[1][1, 0] = 0  # Danger state probability\n",
    "\n",
    "# For remaining columns in A[1], we need to set probabilities\n",
    "# Let's say for now all other states are \"safe\"\n",
    "A[1][0, 1:] = 1  # Set all other states as safe\n",
    "A[1][1, 1:] = 0  # Set all other states as not dangerous\n",
    "\n",
    "# Do the same for A[2]\n",
    "A[2] = np.zeros((2, num_grid_points))\n",
    "A[2][0, 0] = 1\n",
    "A[2][1, 0] = 0\n",
    "A[2][0, 1:] = 1\n",
    "A[2][1, 1:] = 0\n",
    "\n",
    "# # Add noise to each modality separately\n",
    "for modality in range(len(A)):\n",
    "     A[modality] = add_noise_to_transition(A[modality], noise_level=0.1)\n",
    "\n",
    "# Verify normalization\n",
    "for modality in range(len(A)):\n",
    "    column_sums = np.sum(A[modality], axis=0)\n",
    "    print(f\"Modality {modality} column sums before check:\", column_sums)\n",
    "    \n",
    "    # Each column should sum to 1\n",
    "    assert np.allclose(column_sums, 1.0), f\"Modality {modality} is not normalized\"\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_likelihood((A[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = utils.obj_array(num_modalities)\n",
    "\n",
    "# p_safe = 0.5\n",
    "# p_danger = 1 - p_safe\n",
    "\n",
    "# A_loc_attribute = np.zeros((len(loc_obs_attributes), len(context_names), len(choice_names)))\n",
    "\n",
    "# for choice_id, choice_name in enumerate(choice_names):\n",
    "#     if choice_name == 'UP':\n",
    "#         A_loc_attribute[0,:,choice_id] =  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 35, 5]]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_controls = [5]\n",
    "B_f_shapes = [ [ns, ns, num_controls[f]] for f, ns in enumerate(num_states)]\n",
    "B = utils.obj_array_zeros(B_f_shapes)\n",
    "B_f_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"STAY\"]\n",
    "\n",
    "for action_id, action_label in enumerate(actions):\n",
    "\n",
    "  for curr_state, grid_location in enumerate(grid_locations):\n",
    "\n",
    "    y, x = grid_location\n",
    "\n",
    "    if action_label == \"UP\":\n",
    "      next_y = y - 1 if y > 0 else y \n",
    "      next_x = x\n",
    "\n",
    "    elif action_label == \"DOWN\":\n",
    "      next_y = y + 1 if y < (grid_dims[0]-1) else y \n",
    "      next_x = x\n",
    "      \n",
    "    elif action_label == \"LEFT\":\n",
    "      next_x = x - 1 if x > 0 else x \n",
    "      next_y = y\n",
    "    elif action_label == \"RIGHT\":\n",
    "      next_x = x + 1 if x < (grid_dims[1]-1) else x \n",
    "      next_y = y\n",
    "    elif action_label == \"STAY\":\n",
    "      next_x = x\n",
    "      next_y = y\n",
    "\n",
    "    new_location = (next_y, next_x)\n",
    "    next_state = grid_locations.index(new_location)\n",
    "    B[0][next_state, curr_state, action_id] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C Vectors (prior preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "C = utils.obj_array_zeros(num_obs)  # Initialize C array with shape matching num_obs\n",
    "print(C.shape)\n",
    "\n",
    "# Set preferences for state observations (location)\n",
    "C[0] = np.zeros(len(grid_locations))\n",
    "\n",
    "print(C[0])\n",
    "\n",
    "# Set preferences for safety observations\n",
    "C[1] = np.zeros(len(safety))\n",
    "C[1][1] = -20  # Negative preference for red spots\n",
    "\n",
    "# Set preferences for goal observations\n",
    "C[2] = np.zeros(len(goal))\n",
    "C[2][1] = 20  # Positive preference for reaching the goal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_likelihood((C[0]), title_str = 'Probability of safety)')\n",
    "# plot_likelihood((C[1]), title_str = 'Probability of safety)')\n",
    "# plot_likelihood((C[2]), title_str = 'Probability of safety)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = utils.obj_array_zeros(num_obs)\n",
    "\n",
    "# C[1][1] = -5 # negative preference for red spots (punishment)\n",
    "# C[2][1] = 20 # preference for end goal (reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D Vectors: Prior over (initial) hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = utils.obj_array_uniform(num_states)\n",
    "D[0] = utils.onehot(grid_locations.index((0,0)), len(grid_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vision(current_location, grid_dims, distance):\n",
    "    \"\"\"\n",
    "    Update the agent's field of vision based on the current location and distance\n",
    "    Returns a list of all grid positions within the vision range\n",
    "    \n",
    "    Args:\n",
    "        current_location (tuple): Current (y,x) position of the agent\n",
    "        grid_dims (list): Dimensions of the grid [height, width]\n",
    "        distance (int): Vision range/distance\n",
    "        \n",
    "    Returns:\n",
    "        list: List of (y,x) tuples representing visible grid positions\n",
    "    \"\"\"\n",
    "    y, x = current_location\n",
    "    y_min = max(0, y - distance)\n",
    "    y_max = min(grid_dims[0], y + distance + 1)\n",
    "    x_min = max(0, x - distance)\n",
    "    x_max = min(grid_dims[1], x + distance + 1)\n",
    "    \n",
    "    visible_locations = []\n",
    "    for y_pos in range(y_min, y_max):\n",
    "        for x_pos in range(x_min, x_max):\n",
    "            visible_locations.append((y_pos, x_pos))\n",
    "            \n",
    "    return visible_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 0, 0\n",
    "\n",
    "class GridWorldEnv():\n",
    "\n",
    "    def __init__(self, starting_loc = (0, 0), red1_loc = (1, 2), red2_loc = (3,2), red3_loc = (4,4), red4_loc = (6, 1), goal = (6 ,4)):\n",
    "        self.init_loc = starting_loc\n",
    "        self.current_location = self.init_loc\n",
    "        Y, X = self.current_location\n",
    "\n",
    "        self.red1_loc = red1_loc\n",
    "        self.red2_loc = red2_loc\n",
    "        self.red3_loc = red3_loc\n",
    "        self.red4_loc = red4_loc\n",
    "        self.redspots = [self.red1_loc, self.red2_loc, self.red3_loc, self.red4_loc]\n",
    "\n",
    "        self.goal = goal\n",
    "\n",
    "        self.red_obs = ['Null']\n",
    "        self.goal_obs = 'Null'\n",
    "        self.empty_obs = ['Null']\n",
    "\n",
    "        self.agent_reward = 0\n",
    "\n",
    "        print(f\"Starting location is {self.init_loc} | Red spot locations are {self.red1_loc, self.red2_loc, self.red3_loc, self.red4_loc} | Goal is {self.goal}\")\n",
    "    \n",
    "    def step(self, action_label):\n",
    "\n",
    "        Y, X = self.current_location\n",
    "\n",
    "\n",
    "        if action_label == \"UP\": \n",
    "          if Y < grid_dims[0] - 1: Y_new = Y + 1\n",
    "          else: Y_new = Y\n",
    "          X_new = X\n",
    "\n",
    "        elif action_label == \"DOWN\": \n",
    "        \n",
    "          if Y > 0: Y_new = Y - 1\n",
    "          else: Y_new = Y\n",
    "          X_new = X      \n",
    "\n",
    "        elif action_label == \"LEFT\": \n",
    "          \n",
    "          if X > 0: X_new = X - 1\n",
    "          else: X_new = X\n",
    "          Y_new = Y\n",
    "\n",
    "        elif action_label == \"RIGHT\": \n",
    "          \n",
    "          if X < grid_dims[1] - 1: X_new = X + 1\n",
    "          else: X_new = X\n",
    "          Y_new = Y\n",
    "\n",
    "        elif action_label == \"STAY\":\n",
    "          Y_new, X_new = Y, X\n",
    "        \n",
    "        X, Y = X_new, Y_new\n",
    "        self.current_location = (Y_new, X_new) # store the new grid location\n",
    "        self.vision = update_vision(self.current_location, grid_dims, 7)\n",
    "\n",
    "        self.loc_obs = self.current_location # agent directly observes its position in grid\n",
    "\n",
    "        for spot in self.vision:\n",
    "            if spot in self.redspots:\n",
    "                if 'Null' in self.red_obs:\n",
    "                    self.red_obs = [spot]\n",
    "                else:\n",
    "                    self.red_obs.append(spot)\n",
    "            elif spot == self.goal:\n",
    "                self.goal_obs = spot\n",
    "            else:\n",
    "                if 'Null' in self.empty_obs:\n",
    "                    self.empty_obs = [spot]\n",
    "                else:\n",
    "                    self.empty_obs.append(spot)\n",
    "\n",
    "\n",
    "        if self.current_location in self.redspots:\n",
    "            self.agent_reward -= 5\n",
    "            if 'Null' in self.red_obs:\n",
    "                self.red_obs = [self.current_location]\n",
    "            else:\n",
    "                self.red_obs.append(self.current_location)\n",
    "        elif self.current_location == self.goal:\n",
    "            self.agent_reward += 20\n",
    "            self.goal_obs = self.current_location\n",
    "        else:\n",
    "            if 'Null' in self.empty_obs:\n",
    "                self.empty_obs = [self.current_location]\n",
    "            else:\n",
    "                self.empty_obs.append(self.current_location)\n",
    "        \n",
    "        return self.agent_reward, self.loc_obs, self.goal_obs, self.empty_obs, self.red_obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_location = self.init_loc\n",
    "        print(f'Re-initialized location to {self.init_loc}')\n",
    "        self.loc_obs = self.current_location\n",
    "        self.goal_obs, self.empty_obs, self.red_obs, self.agent_reward = 'Null', ['Null'], ['Null'], 0\n",
    "\n",
    "        return self.loc_obs, self.goal_obs, self.empty_obs, self.red_obs, self.agent_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting location is (0, 0) | Red spot locations are ((1, 2), (3, 2), (4, 4), (6, 1)) | Goal is (6, 4)\n",
      "Re-initialized location to (0, 0)\n"
     ]
    }
   ],
   "source": [
    "my_agent = Agent(A = A, B = B, C = C, D = D, policy_len = 4)\n",
    "\n",
    "my_env = GridWorldEnv(starting_loc = (0, 0), red1_loc = (1, 2), red2_loc = (3,2), red3_loc = (4,4), red4_loc = (6, 1), goal = (6 ,4))\n",
    "\n",
    "loc_obs, goal_obs, empty_obs, red_obs, agent_reward = my_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0), 'Null', ['Null'], ['Null'], 0)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_obs, goal_obs, empty_obs, red_obs, agent_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid location at time 0: (0, 0)\n",
      "Reward at time 0: 0\n",
      "Grid location at time 1: (0, 1)\n",
      "Reward at time 1: 0\n",
      "Grid location at time 2: (0, 0)\n",
      "Reward at time 2: 0\n",
      "Grid location at time 3: (0, 0)\n",
      "Reward at time 3: 0\n",
      "Grid location at time 4: (0, 0)\n",
      "Reward at time 4: 0\n",
      "Grid location at time 5: (0, 0)\n",
      "Reward at time 5: 0\n",
      "Grid location at time 6: (0, 0)\n",
      "Reward at time 6: 0\n",
      "Grid location at time 7: (0, 0)\n",
      "Reward at time 7: 0\n",
      "Grid location at time 8: (0, 0)\n",
      "Reward at time 8: 0\n",
      "Grid location at time 9: (0, 0)\n",
      "Reward at time 9: 0\n",
      "Grid location at time 10: (0, 0)\n",
      "Reward at time 10: 0\n",
      "Grid location at time 11: (0, 0)\n",
      "Reward at time 11: 0\n"
     ]
    }
   ],
   "source": [
    "history_of_locs = [loc_obs]\n",
    "\n",
    "T = 12\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    # Feed Observations ft. infer_states function\n",
    "    for spot in grid_locations:\n",
    "        obs = [grid_locations.index(spot)]\n",
    "\n",
    "        # spot, safety, goal\n",
    "        if spot in red_obs:\n",
    "            obs.append(1)\n",
    "        else:\n",
    "            obs.append(0)\n",
    "        \n",
    "        if spot == goal_obs:\n",
    "            obs.append(1)\n",
    "        else:\n",
    "            obs.append(0)\n",
    "\n",
    "        qs = my_agent.infer_states(obs)\n",
    "    \n",
    "    my_agent.infer_policies()\n",
    "    chosen_action_id = my_agent.sample_action()\n",
    "\n",
    "    print(f'Action at time {t}: {choice_action}')\n",
    "\n",
    "    movement_id = int(chosen_action_id[0])\n",
    "\n",
    "    choice_action = actions[movement_id]\n",
    "    \n",
    "    agent_reward, loc_obs, goal_obs, empty_obs, red_obs = my_env.step(choice_action)\n",
    "    \n",
    "    history_of_locs.append(loc_obs)\n",
    "\n",
    "    print(f\"Grid location at time {t}: {loc_obs}\")\n",
    "\n",
    "    print(f'Reward at time {t}: {agent_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
