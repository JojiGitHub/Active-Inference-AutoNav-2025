{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redspots Environment\n",
    "\n",
    "## Environment Description\n",
    "\n",
    "A simple gridworld with white (safe) spots, green (rewarding) spots, and red (undesirable/dangerous) spots.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Have an agent map the environment and infer the best way to avoid red spots and get to the green spot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pymdp\n",
    "from pymdp import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(grid_locations, num_x = 3, num_y = 3 ):\n",
    "    \"\"\"\n",
    "    Plots the spatial coordinates of GridWorld as a heatmap, with each (X, Y) coordinate \n",
    "    labeled with its linear index (its `state id`)\n",
    "    \"\"\"\n",
    "\n",
    "    grid_heatmap = np.zeros((num_x, num_y))\n",
    "    for linear_idx, location in enumerate(grid_locations):\n",
    "      y, x = location\n",
    "      grid_heatmap[y, x] = linear_idx\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.heatmap(grid_heatmap, annot=True, cbar = False, fmt='.0f', cmap='crest')\n",
    "\n",
    "def plot_likelihood(matrix, title_str = \"Likelihood distribution (A)\"):\n",
    "    \"\"\"\n",
    "    Plots a 2-D likelihood matrix as a heatmap\n",
    "    \"\"\"\n",
    "\n",
    "    if not np.isclose(matrix.sum(axis=0), 1.0).all():\n",
    "      raise ValueError(\"Distribution not column-normalized! Please normalize (ensure matrix.sum(axis=0) == 1.0 for all columns)\")\n",
    "    \n",
    "    fig = plt.figure(figsize = (6,6))\n",
    "    ax = sns.heatmap(matrix, cmap = 'gray', cbar = False, vmin = 0.0, vmax = 1.0)\n",
    "    plt.title(title_str)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_beliefs(belief_dist, title_str=\"\"):\n",
    "    \"\"\"\n",
    "    Plot a categorical distribution or belief distribution, stored in the 1-D numpy vector `belief_dist`\n",
    "    \"\"\"\n",
    "\n",
    "    if not np.isclose(belief_dist.sum(), 1.0):\n",
    "      raise ValueError(\"Distribution not normalized! Please normalize\")\n",
    "\n",
    "    plt.grid(zorder=0)\n",
    "    plt.bar(range(belief_dist.shape[0]), belief_dist, color='r', zorder=3)\n",
    "    plt.xticks(range(belief_dist.shape[0]))\n",
    "    plt.title(title_str)\n",
    "    plt.show()\n",
    "\n",
    "def add_noise(matrix, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Add noise to transition matrix while preserving normalization\n",
    "    \n",
    "    Args:\n",
    "        A: Original transition matrix\n",
    "        noise_level: Amount of noise to add (0-1)\n",
    "    \"\"\"\n",
    "    # Generate random noise\n",
    "    noise = np.random.uniform(-noise_level, noise_level, size=matrix.shape)\n",
    "\n",
    "    print(noise) \n",
    "    \n",
    "    # Add noise to matrix\n",
    "    noisy_matrix = matrix + noise\n",
    "    \n",
    "    # Ensure non-negative\n",
    "    noisy_matrix = np.maximum(noisy_matrix, 0.0)\n",
    "    \n",
    "    # Normalize columns to sum to 1\n",
    "    noisy_matrix = noisy_matrix / noisy_matrix.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    return noisy_matrix\n",
    "\n",
    "def move_to_grid(x, y, z):\n",
    "    '''Moves coppelia coordinates (x,y,z) to a 200x200 grid, z coordinate remains constant, outputs coordinate in terms of grid'''\n",
    "    \n",
    "    # Translate x,y coordinate 2.5 up and 2.5 right\n",
    "    x = x + 2.5\n",
    "    y = y + 2.5\n",
    "    \n",
    "    # Ensure coordinates (x,y) are within (0,0) and (5,5)\n",
    "    if x > 5 or x < 0:\n",
    "        return \"Invalid x coordinate!\"\n",
    "    elif y > 5 or y < 0:\n",
    "        return \"Invalid y coordinate!\"\n",
    "    \n",
    "    # Convert x, y to grid indices by dividing by 0.05 (since each grid cell is 0.05 wide)\n",
    "    x_grid = round(x / 0.05)\n",
    "    y_grid = round(y / 0.05)\n",
    "    \n",
    "    # Ensure that the coordinates are within valid grid range (0 to 200)\n",
    "    if x_grid > 200 or x_grid < 0:\n",
    "        return \"Invalid x grid point!\"\n",
    "    if y_grid > 200 or y_grid < 0:\n",
    "        return \"Invalid y grid point!\"\n",
    "    \n",
    "    # Return the grid indices\n",
    "    return (x_grid, y_grid)\n",
    "\n",
    "    \n",
    "def grid_to_coordinates(x_grid, y_grid, z):\n",
    "    '''Converts a valid 200x200 grid point back into coppelia (x,y,z) coordinates in the range (x,y) = (0,0)-(5,5), z remains constant'''\n",
    "    \n",
    "    # Ensure the grid points are within valid range (0 to 200)\n",
    "    if x_grid > 200 or x_grid < 0:\n",
    "        return \"Invalid x grid point!\"\n",
    "    if y_grid > 200 or y_grid < 0:\n",
    "        return \"Invalid y grid point!\"\n",
    "    \n",
    "    # Reverse the grid index conversion by multiplying by 0.05\n",
    "    x = x_grid * 0.05\n",
    "    y = y_grid * 0.05\n",
    "    \n",
    "    # Return the original (x, y, z) coordinates\n",
    "    return (x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_dimensions\n",
    "grid_dims = [40, 40]\n",
    "\n",
    "# list of grid positiions\n",
    "grid_locations = []\n",
    "for i in range(grid_dims[0]):\n",
    "    for j in range(grid_dims[1]):\n",
    "        grid_locations.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "redspots = [(34, 20), (28, 32), (8, 28), (12, 12), (28, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start point\n",
    "agent_pos = (0,0)\n",
    "\n",
    "# end goal\n",
    "goal_location = (6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States & Observations\n",
    "\n",
    "s1 = current location \\\n",
    "s2 = attribute of current location\n",
    "\n",
    "o1 = observed current location \\\n",
    "o2 = color of current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1 is already defined = grid_locations\n",
    "\n",
    "# s2\n",
    "current_attribute = ['SAFE', 'DANGER', 'REWARDING']\n",
    "\n",
    "# list of # of possibillities for states\n",
    "num_states = [len(grid_locations), len(current_attribute)] # location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o1 is already defined = grid_locatioons\n",
    "\n",
    "# o2\n",
    "current_color = ['WHITE', 'RED', 'GREEN']\n",
    "\n",
    "# list of # of possibilities for observations\n",
    "num_obs = [len(grid_locations), len(current_color)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent's Observation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "vision_matrix = np.zeros((num_states[0], num_states[1]))\n",
    "\n",
    "# Rule-based assignment\n",
    "for loc in range(num_states[0]):\n",
    "    # Example: Assume all locations have [SAFE: 0.7, DANGER: 0.2, REWARDING: 0.1]\n",
    "    vision_matrix[loc] = np.array([0.33, 0.33, 0.33])\n",
    "    vision_matrix[loc] /= vision_matrix[loc].sum()\n",
    "\n",
    "    # Normalize each location's attribute distribution (ensure sum = 1)\n",
    "\n",
    "vision_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vision_matrix(vision_matrix, obs):\n",
    "    \"\"\"\n",
    "    Update the observation matrix based on an observation\n",
    "    \"\"\"\n",
    "\n",
    "    one_hot_obs = [0,0,0]\n",
    "    one_hot_obs[obs[1]] = 1\n",
    "    vision_matrix[obs[0]] = one_hot_obs\n",
    "\n",
    "    return vision_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_vision_matrix(vision_matrix, grid_dims=grid_dims):\n",
    "    \"\"\"\n",
    "    Visualizes the observation matrix as three separate heatmaps, one for each attribute\n",
    "    (SAFE, DANGER, REWARDING)\n",
    "    \n",
    "    Args:\n",
    "        vision_matrix: numpy array of shape (num_locations, num_attributes)\n",
    "        grid_dims: list of [height, width] of the grid\n",
    "    \"\"\"\n",
    "    # Create figure with three subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Labels for each subplot\n",
    "    titles = ['SAFE', 'DANGER', 'REWARDING']\n",
    "    \n",
    "    for idx, title in enumerate(titles):\n",
    "        # Reshape the matrix to match grid dimensions\n",
    "        heatmap_data = vision_matrix[:, idx].reshape(grid_dims[0], grid_dims[1])\n",
    "        \n",
    "        # Plot heatmap\n",
    "        sns.heatmap(heatmap_data, \n",
    "                   ax=axes[idx], \n",
    "                   cmap='YlOrRd',\n",
    "                   vmin=0, \n",
    "                   vmax=1,\n",
    "                   annot=True,\n",
    "                   fmt='.2f')\n",
    "        \n",
    "        axes[idx].set_title(f'{title} Probability')\n",
    "        axes[idx].set_xlabel('Y coordinate')\n",
    "        axes[idx].set_ylabel('X coordinate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "visualize_vision_matrix(vision_matrix, grid_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Define A Matrix\n",
    "A_shapes = []\n",
    "for i in num_obs:\n",
    "    A_shapes.append([i] + num_states)\n",
    "\n",
    "A = utils.obj_array_zeros(A_shapes)\n",
    "A.shape, A_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Observation Modality A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "A[0] = np.zeros(A_shapes[0])  # Initialize with zeros\n",
    "\n",
    "# Fill in the observation mapping for each safety level\n",
    "for safety_level in range(num_states[1]):\n",
    "    A[0][:,:,safety_level] = np.eye(num_states[0])  # Copy the identity matrix for each safety level\n",
    "\n",
    "# Verify the shape and normalization\n",
    "print(\"New A[0] shape:\", A[0].shape)\n",
    "print(\"Column sums:\", A[0].sum(axis=0).sum(axis=1))  # Should be all 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Extract a 2D slice by fixing the safety level dimension to 0\n",
    "import numpy as np\n",
    "plot_likelihood(A[0][:, :, 0], \"Location observation likelihood matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color observation modality: A[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map safety levels to indices\n",
    "safety_level_to_index = {state: i for i, state in enumerate(current_attribute)}  # {'SAFE': 0, 'DANGER': 1, 'REWARDING': 2}\n",
    "\n",
    "# Probabilities for each color given the safety level (in correct heatmap order: RED, GREEN, WHITE)\n",
    "probabilities = {\n",
    "    \"SAFE\": [1, 0, 0],        # ['WHITE', 'RED', 'GREEN']\n",
    "    \"DANGER\": [0, 1, 0.],      # ['WHITE', 'RED', 'GREEN']\n",
    "    \"REWARDING\": [0, 0, 1]    # ['WHITE', 'RED', 'GREEN']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate A[1]\n",
    "for safety_level, probs in probabilities.items():\n",
    "    safety_idx = safety_level_to_index[safety_level]\n",
    "    for loc in range(len(grid_locations)):  # Iterate over grid locations\n",
    "        for color_idx, prob in enumerate(probs):  # Iterate over colors (RED, GREEN, WHITE)\n",
    "            A[1][color_idx, loc, safety_idx] = prob  # Assign probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create a figure with 3 subplots (one for each safety state)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Extract and plot each safety state slice\n",
    "for safety_idx in range(3):\n",
    "    # Get a slice for the current safety state (fixing all other dimensions to 0)\n",
    "    slice_matrix = A[1][:, :, safety_idx]\n",
    "    \n",
    "    # Plot the slice\n",
    "    sns.heatmap(slice_matrix, ax=axes[safety_idx], cmap='gray', cbar=False, vmin=0.0, vmax=1.0)\n",
    "    axes[safety_idx].set_title(f'Safety State {safety_idx}')\n",
    "    axes[safety_idx].set_xlabel('Location States')\n",
    "    if safety_idx == 0:\n",
    "        axes[safety_idx].set_ylabel('Color Observations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Add noise to each modality separately\n",
    "for modality in range(len(A)):\n",
    "    A[modality] = add_noise(A[modality], noise_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Each Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "num_controls = [5, 1]\n",
    "B_f_shapes = [ [ns, ns, num_controls[f]] for f, ns in enumerate(num_states)]\n",
    "B = utils.obj_array_zeros(B_f_shapes)\n",
    "B_f_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B[0] - Control Factor - Location Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "grid_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"STAY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action_id, action_label in enumerate(actions):\n",
    "  \n",
    "    for curr_state, (x, y) in enumerate(grid_locations):\n",
    "        \n",
    "        # Calculate next position based on action\n",
    "        if action_label == \"UP\":\n",
    "            next_y = max(0, y - 1)        # Move up (decrease y)\n",
    "            next_x = x\n",
    "        elif action_label == \"DOWN\":\n",
    "            next_y = min(grid_dims[1]-1, y + 1)  # Move down (increase y)\n",
    "            next_x = x\n",
    "        elif action_label == \"LEFT\":\n",
    "            next_x = max(0, x - 1)        # Move left (decrease x)\n",
    "            next_y = y\n",
    "        elif action_label == \"RIGHT\":\n",
    "            next_x = min(grid_dims[0]-1, x + 1)  # Move right (increase x)\n",
    "            next_y = y\n",
    "        else:  # STAY\n",
    "            next_x = x\n",
    "            next_y = y\n",
    "        \n",
    "        # Get the state index for the next position\n",
    "        next_state = grid_locations.index((next_x, next_y))\n",
    "        \n",
    "        # Set transition probability to 1.0\n",
    "        B[0][next_state, curr_state, action_id] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B[1] - Non-Control Factor - Identity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize safety level transition matrix (no changes for safety levels)\n",
    "B[1][:,:,0] = np.eye(3)  # Identity matrix for safety level transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize B matrix columns for each action\n",
    "for action_id in range(len(actions)):\n",
    "    # Get slice for current action\n",
    "    B_action = B[0][..., action_id]\n",
    "    \n",
    "    # Replace zero columns with ones in appropriate positions\n",
    "    zero_cols = (B_action.sum(axis=0) == 0)\n",
    "    for col in range(B_action.shape[1]):\n",
    "        if zero_cols[col]:\n",
    "            # Stay in the same state if no transition is defined\n",
    "            B_action[col, col] = 1.0\n",
    "    \n",
    "    # Normalize columns\n",
    "    column_sums = B_action.sum(axis=0)\n",
    "    B[0][..., action_id] = B_action / column_sums[None, :]\n",
    "\n",
    "# Verify normalization\n",
    "for action_id in range(len(actions)):\n",
    "    assert np.allclose(B[0][..., action_id].sum(axis=0), 1.0), f\"Action {actions[action_id]} not normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(B[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C Vectors (prior preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "C = utils.obj_array_zeros(num_obs)  # Initialize C array with shape matching num_obs\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C[0] - Preference for location observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "goal_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Set preferences for state observations (location)\n",
    "C[0] = np.ones(len(grid_locations))\n",
    "C[0][grid_locations.index(goal_location)] += 1\n",
    "\n",
    "print(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for i, loc in enumerate(grid_locations):\n",
    "    x = ((goal_location[0] - loc[0])**2 + (goal_location[1] - loc[1])**2) ** 0.5\n",
    "    print(loc, i, x)\n",
    "    C[0][i] -= x * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.maths import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[0] = softmax(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plot_beliefs(C[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C[1] - Preference for color observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white, red, green <- order it's encoded in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Set preferences for color observations\n",
    "C[1] = np.zeros((num_obs[1],))\n",
    "C[1][0] = -0.1\n",
    "C[1][1] = -1\n",
    "C[1][2] = 1.1\n",
    "\n",
    "print(C[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D Vectors: Prior beliefs about hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Shape\n",
    "num_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = utils.obj_array_uniform(num_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D[0] - Belief About Current Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Define prior belief about agent's location (same as before)\n",
    "D[0] = np.zeros(num_states[0])  # Shape (35,)\n",
    "D[0][grid_locations.index(agent_pos)] = 1.0  # One-hot encoding for location\n",
    "\n",
    "print(\"D[0] shape (Location prior):\", D[0].shape)  # (35,)\n",
    "D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize uniform distribution over locations\n",
    "# D[0] = np.ones(num_states[0]) / num_states[0]  # Create normalized uniform distribution over all locations\n",
    "\n",
    "# D[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D[1] - Belief About Attribute of Current Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "D[1] = np.ones(num_states[1]) / num_states[1]  # Create normalized uniform distribution over all locations\n",
    "D[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plot_beliefs(D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plot_beliefs(D[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vision(current_location, grid_dims, distance):\n",
    "    \"\"\"\n",
    "    Update the agent's field of vision based on the current location and distance\n",
    "    Returns a list of all grid positions within the vision range\n",
    "    \n",
    "    Args:\n",
    "        current_location (tuple): Current (x,y) position of the agent\n",
    "        grid_dims (list): Dimensions of the grid [width, height]\n",
    "        distance (int): Vision range/distance\n",
    "        \n",
    "    Returns:\n",
    "        list: List of (x,y) tuples representing visible grid positions\n",
    "    \"\"\"\n",
    "    x, y = current_location\n",
    "    x_min = max(0, x - distance)\n",
    "    x_max = min(grid_dims[0], x + distance + 1)\n",
    "    y_min = max(0, y - distance)\n",
    "    y_max = min(grid_dims[1], y + distance + 1)\n",
    "    \n",
    "    visible_locations = []\n",
    "    for y_pos in range(y_min, y_max):\n",
    "        for x_pos in range(x_min, x_max):\n",
    "            visible_locations.append((x_pos, y_pos))\n",
    "            \n",
    "    return visible_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GridWorldEnv():\n",
    "#     def __init__(self, starting_loc=(0, 0), redspots=[(1, 2), (3, 2), (4, 4), (6, 1)], goal=(6,4)):\n",
    "#         # Initialize coordinates\n",
    "#         self.x, self.y = starting_loc\n",
    "#         self.init_loc = starting_loc\n",
    "#         self.current_location = (self.x, self.y)\n",
    "\n",
    "#         self.goal = goal\n",
    "\n",
    "#         self.redspots = redspots\n",
    "\n",
    "#         self.red_obs = ['Null']\n",
    "#         self.green_obs = 'Null'\n",
    "#         self.white_obs = ['Null']\n",
    "\n",
    "#         self.agent_reward = 0\n",
    "        \n",
    "#         print(f\"Starting location is {self.current_location} | Red spot locations are {self.redspots} | Goal is {self.goal}\")\n",
    "    \n",
    "#     def step(self, action_label):\n",
    "#         if action_label == \"UP\": \n",
    "#             self.y = max(0, self.y - 1)  # Move up (decrease y)\n",
    "            \n",
    "#         elif action_label == \"DOWN\": \n",
    "#             self.y = min(grid_dims[1] - 1, self.y + 1)  # Move down (increase y)\n",
    "\n",
    "#         elif action_label == \"LEFT\": \n",
    "#             self.x = max(0, self.x - 1)  # Move left (decrease x)\n",
    "\n",
    "#         elif action_label == \"RIGHT\": \n",
    "#             self.x = min(grid_dims[0] - 1, self.x + 1)  # Move right (increase x)\n",
    "\n",
    "#         # Update current_location tuple after movement\n",
    "#         self.current_location = (self.x, self.y)\n",
    "#         print(f\"self.current_location: {self.current_location}\")\n",
    "        \n",
    "#         # Update vision with current coordinates\n",
    "#         self.vision = update_vision(self.current_location, grid_dims, 6)\n",
    "\n",
    "#         self.loc_obs = self.current_location\n",
    "\n",
    "#         # Reset observations at each step\n",
    "#         self.red_obs = ['Null']\n",
    "#         self.white_obs = ['Null']\n",
    "#         self.green_obs = 'Null'\n",
    "\n",
    "#         # Update observations based on vision\n",
    "#         for spot in self.vision:\n",
    "#             if spot in self.redspots:\n",
    "#                 if 'Null' in self.red_obs:\n",
    "#                     self.red_obs = [spot]\n",
    "#                 else:\n",
    "#                     self.red_obs.append(spot)\n",
    "#             elif spot == self.goal:\n",
    "#                 self.green_obs = spot\n",
    "#             else:\n",
    "#                 if 'Null' in self.white_obs:\n",
    "#                     self.white_obs = [spot]\n",
    "#                 else:\n",
    "#                     self.white_obs.append(spot)\n",
    "\n",
    "#         # Update rewards and observations based on current location\n",
    "#         if self.current_location in self.redspots:\n",
    "#             self.agent_reward -= 5\n",
    "#             if 'Null' in self.red_obs:\n",
    "#                 self.red_obs = [self.current_location]\n",
    "#             else:\n",
    "#                 self.red_obs.append(self.current_location)\n",
    "#         elif self.current_location == self.goal:\n",
    "#             self.agent_reward += 20\n",
    "#             self.green_obs = self.current_location\n",
    "#         else:\n",
    "#             if 'Null' in self.white_obs:\n",
    "#                 self.white_obs = [self.current_location]\n",
    "#             else:\n",
    "#                 self.white_obs.append(self.current_location)\n",
    "        \n",
    "#         return self.loc_obs, self.green_obs, self.white_obs, self.red_obs, self.agent_reward\n",
    "    \n",
    "#     def reset(self):\n",
    "#         self.x, self.y = self.init_loc\n",
    "#         self.current_location = (self.x, self.y)\n",
    "#         print(f'Re-initialized location to {self.current_location}')\n",
    "#         self.loc_obs = self.current_location\n",
    "#         self.green_obs, self.white_obs, self.red_obs, self.agent_reward = 'Null', ['Null'], ['Null'], 0\n",
    "\n",
    "#         return self.loc_obs, self.green_obs, self.white_obs, self.red_obs, self.agent_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_get_expected_states(qs, B, policy, vision_matrix=vision_matrix):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Compute the expected states under a policy, also known as the posterior predictive density over states\n",
    "\n",
    "    Parameters\n",
    "\n",
    "    ----------\n",
    "\n",
    "    qs: ``numpy.ndarray`` of dtype object\n",
    "\n",
    "        Marginal posterior beliefs over hidden states at a given timepoint.\n",
    "\n",
    "    B: ``numpy.ndarray`` of dtype object\n",
    "\n",
    "        Dynamics likelihood mapping or 'transition model', mapping from hidden states at ``t`` to hidden states at ``t+1``, given some control state ``u``.\n",
    "\n",
    "        Each element ``B[f]`` of this object array stores a 3-D tensor for hidden state factor ``f``, whose entries ``B[f][s, v, u]`` store the probability\n",
    "\n",
    "        of hidden state level ``s`` at the current time, given hidden state level ``v`` and action ``u`` at the previous time.\n",
    "\n",
    "    policy: 2D ``numpy.ndarray``\n",
    "\n",
    "        Array that stores actions entailed by a policy over time. Shape is ``(num_timesteps, num_factors)`` where ``num_timesteps`` is the temporal\n",
    "\n",
    "        depth of the policy and ``num_factors`` is the number of control factors.\n",
    "\n",
    "    Returns\n",
    "\n",
    "    -------\n",
    "\n",
    "    qs_pi: ``list`` of ``numpy.ndarray`` of dtype object\n",
    "\n",
    "        Predictive posterior beliefs over hidden states expected under the policy, where ``qs_pi[t]`` stores the beliefs about\n",
    "\n",
    "        hidden states expected under the policy at time ``t``\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n_steps = policy.shape[0]\n",
    "\n",
    "    n_factors = policy.shape[1]\n",
    "\n",
    "    # initialise posterior predictive density as a list of beliefs over time, including current posterior beliefs about hidden states as the first element\n",
    "\n",
    "    qs_pi = [qs] + [utils.obj_array(n_factors) for t in range(n_steps)]\n",
    "\n",
    "    \n",
    "\n",
    "    # get expected states over time\n",
    "\n",
    "    for t in range(n_steps):\n",
    "\n",
    "        for control_factor, action in enumerate(policy[t,:]):\n",
    "\n",
    "            qs_pi[t+1][control_factor] = B[control_factor][:,:,int(action)].dot(qs_pi[t][control_factor])\n",
    "\n",
    "            qs_pi[t+1][1] = vision_matrix[qs_pi[t+1][0].argmax()]\n",
    "\n",
    "            # # Debug visualization:\n",
    "            # print(f\"\\n--- Debugging at timestep {t+1} and policy {policy[t,:]}\")\n",
    "            # print(\"Location beliefs:\")\n",
    "            # plot_beliefs(qs_pi[t+1][0], title_str=f\"Location Beliefs - Step {t+1}\")\n",
    "            # print(\"Color beliefs:\")\n",
    "            # plot_beliefs(qs_pi[t+1][1], title_str=f\"Color Beliefs - Step {t+1}\")\n",
    "            \n",
    "\n",
    "    return qs_pi[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp import control\n",
    "\n",
    "# Inject our custom function\n",
    "control.get_expected_states = custom_get_expected_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "agent_pos, redspots, goal_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base agent\n",
    "my_agent = Agent(A=A, B=B, C=C, D=D, policy_len=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "grid_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_color_observation(position, red_obs, green_obs, white_obs):\n",
    "\n",
    "    if red_obs != ['Null']:\n",
    "        if position in red_obs: return 1  # RED\n",
    "    if green_obs == position: return 2 # GREEN\n",
    "    elif white_obs != ['Null']:\n",
    "        if position in white_obs: return 0 # WHITE\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_observation(position, red_obs, green_obs, white_obs):\n",
    "    return [grid_locations.index(position), create_color_observation(position, red_obs, green_obs, white_obs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coppelia Environment + Gridworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coppeliasim_zmqremoteapi_client import RemoteAPIClient\n",
    "import numpy as np\n",
    "import time\n",
    "from math import comb\n",
    "\n",
    "client = RemoteAPIClient()\n",
    "sim = client.getObject('sim')\n",
    "\n",
    "def move_to_grid(x, y):\n",
    "    '''Moves coppelia coordinates (x,y) to a 40x40 grid, z coordinate remains constant, outputs coordinate in terms of grid'''\n",
    "    \n",
    "    # Translate x,y coordinate 2.5 up and 2.5 right\n",
    "    x = x + 2.5\n",
    "    y = y + 2.5\n",
    "    \n",
    "    # Ensure coordinates (x,y) are within (0,0) and (5,5)\n",
    "    if x > 5 or x < 0:\n",
    "        return \"Invalid x coordinate!\"\n",
    "    elif y > 5 or y < 0:\n",
    "        return \"Invalid y coordinate!\"\n",
    "    \n",
    "    # Convert x, y to grid indices by dividing by 0.05 (since each grid cell is 0.05 wide)\n",
    "    x_grid = round(x / 0.125)\n",
    "    y_grid = round(y / 0.125)\n",
    "    \n",
    "    # Ensure that the coordinates are within valid grid range (0 to 200)\n",
    "    if x_grid > 40 or x_grid < 0:\n",
    "        return \"Invalid x grid point!\"\n",
    "    if y_grid > 40 or y_grid < 0:\n",
    "        return \"Invalid y grid point!\"\n",
    "    \n",
    "    # Return the grid indices\n",
    "    return (x_grid, y_grid)\n",
    "\n",
    "    \n",
    "def grid_to_coordinates(x_grid, y_grid):\n",
    "    '''Converts a valid 200x200 grid point back into coppelia (x,y,z) coordinates in the range (x,y) = (0,0)-(5,5), z remains constant'''\n",
    "    \n",
    "    # Ensure the grid points are within valid range (0 to 200)\n",
    "    if x_grid > 40 or x_grid < 0:\n",
    "        return \"Invalid x grid point!\"\n",
    "    if y_grid > 40 or y_grid < 0:\n",
    "        return \"Invalid y grid point!\"\n",
    "    \n",
    "    # Reverse the grid index conversion by multiplying by 0.05\n",
    "    x = x_grid * 0.125\n",
    "    y = y_grid * 0.125\n",
    "    \n",
    "    # Return the original (x, y, z) coordinates\n",
    "    return (x, y, 0.05)   \n",
    "\n",
    "def get_object_position(object_name):\n",
    "    # Step 2: Get the object handle by name\n",
    "    objectHandle = sim.getObject(f'/{object_name}')\n",
    "    \n",
    "    if objectHandle == -1:\n",
    "        raise Exception(f\"Object '{object_name}' not found.\")\n",
    "    \n",
    "    # Step 3: Get the position of the obstacle relative to the world (-1 means world reference)\n",
    "    objectPosition = sim.getObjectPosition(objectHandle, -1)\n",
    "    \n",
    "    # Round each element in the position to the nearest thousandth\n",
    "    roundedPosition = [round(coord, 3) for coord in objectPosition]\n",
    "    \n",
    "    print(f\"Position of {object_name}: {roundedPosition}\")\n",
    "    return roundedPosition\n",
    "\n",
    "def create_bounding_locations(position, dimensions):\n",
    "    (x, y) = position\n",
    "    (a, b, c) = dimensions\n",
    "\n",
    "    # Bounding locations\n",
    "    top_right = (x + a/2, y + b/2)\n",
    "    bottom_left = (x - a/2, y - b/2)\n",
    "    top_left = (x - a/2, y + b/2)\n",
    "    bottom_right = (x + a/2, y - b/2)\n",
    "\n",
    "    # Midpoints\n",
    "    mid_top = ((top_right[0] + top_left[0]) / 2, (top_right[1] + top_left[1]) / 2)\n",
    "    mid_bottom = ((bottom_right[0] + bottom_left[0]) / 2, (bottom_right[1] + bottom_left[1]) / 2)\n",
    "    mid_left = ((top_left[0] + bottom_left[0]) / 2, (top_left[1] + bottom_left[1]) / 2)\n",
    "    mid_right = ((top_right[0] + bottom_right[0]) / 2, (top_right[1] + bottom_right[1]) / 2)\n",
    "    \n",
    "\n",
    "    return top_right, bottom_left, top_left, bottom_right, mid_top, mid_bottom, mid_left, mid_right\n",
    "\n",
    "\n",
    "def get_obstacle_locations():\n",
    "    sceneObjects = [sim.getObjectAlias(obj) for obj in sim.getObjectsInTree(sim.handle_scene)]\n",
    "    for i in sceneObjects:\n",
    "        if \"Obstacle\" in i:\n",
    "            obstacleHandle = sim.getObject(sim.getObjectAlias(i))\n",
    "            obstaclePosition = get_object_position(sim.getObjectAlias(i))\n",
    "            obstacleDimensions = sim.getObjectSize(obstacleHandle)\n",
    "            obstacleBoundingLocations = create_bounding_locations(obstaclePosition, obstacleDimensions)\n",
    "            return obstacleBoundingLocations\n",
    "    \n",
    "def check_bounds(loc):\n",
    "    '''Checks if a location is within the bounds of the grid'''\n",
    "    \n",
    "    x, y, z = loc\n",
    "    if x > 5 or x < 0:\n",
    "        return None\n",
    "    elif y > 5 or y < 0:\n",
    "        return None\n",
    "    else:\n",
    "        return loc\n",
    "\n",
    "\n",
    "\n",
    "bubbleRobHandle = sim.getObject('/bubbleRob')\n",
    "ctrlPts = [[0.0,0.0,0.05,0.0,0.0,0.0,1.0]]\n",
    "ctrlPts_flattened = [coord for point in ctrlPts for coord in point]\n",
    "\n",
    "\n",
    "\n",
    "def monitor_position():\n",
    "    pos1 = sim.getObjectPosition(bubbleRobHandle, -1)\n",
    "    time.sleep(0.1)\n",
    "    pos2 = sim.getObjectPosition(bubbleRobHandle, -1)\n",
    "    print(f\"Position change: {np.array(pos2) - np.array(pos1)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "class CoppeliaEnv():\n",
    "    def get_initial_object_properties(self):\n",
    "        initial_pos = sim.getObjectPosition(self.bubbleRobHandle, -1)\n",
    "        initial_orient = sim.getObjectQuaternion(self.bubbleRobHandle, -1)\n",
    "        return initial_pos[2], initial_orient\n",
    "\n",
    "    def __init__(self, redspots, starting_loc=move_to_grid(get_object_position('bubbleRob')[0], get_object_position('bubbleRob')[1]), goal=move_to_grid(get_object_position('Goal_Loc')[0],get_object_position('Goal_Loc')[1])):\n",
    "        # Get robot handle first and ensure it's valid\n",
    "        try:\n",
    "            self.bubbleRobHandle = sim.getObject('/bubbleRob')  # Get handle directly here\n",
    "            if self.bubbleRobHandle == -1:\n",
    "                raise Exception(\"Could not get handle to bubbleRob\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting robot handle: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Initialize coordinates \n",
    "        self.x, self.y = starting_loc\n",
    "        self.init_loc = starting_loc\n",
    "        self.current_location = (self.x, self.y)\n",
    "        self.goal = goal\n",
    "        self.redspots = redspots\n",
    "\n",
    "        # Initialize observations\n",
    "        self.red_obs = ['Null']\n",
    "        self.green_obs = 'Null'\n",
    "        self.white_obs = ['Null']\n",
    "        \n",
    "        # Initialize properties\n",
    "        self.initial_z, self.initial_orientation = self.get_initial_object_properties()\n",
    "\n",
    "        # Initialize path-related variables\n",
    "        self.ctrlPts = ctrlPts\n",
    "        self.ctrlPts_flattened = ctrlPts_flattened\n",
    "        self.t = 0\n",
    "        self.posAlongPath = 0\n",
    "        self.velocity = 0.08\n",
    "        self.totalLength = self.calculate_total_length()\n",
    "        \n",
    "        self.previousSimulationTime = 0\n",
    "        self.agent_reward = 0\n",
    "\n",
    "\n",
    "    def bezier_recursive(self, t):\n",
    "        n = (len(self.ctrlPts) // 7) - 1\n",
    "        point = np.zeros(3)\n",
    "        total_weight = 0\n",
    "        \n",
    "        for i in range(n + 1):\n",
    "            binomial_coeff = comb(n, i)\n",
    "            weight = binomial_coeff * ((1 - t) ** (n - i)) * (t ** i)\n",
    "            point_coords = np.array(self.ctrlPts[i * 7:i * 7 + 3])\n",
    "            point += weight * point_coords\n",
    "            total_weight += weight\n",
    "        \n",
    "        if total_weight > 0:\n",
    "            point = point / total_weight\n",
    "        \n",
    "        point[2] = self.initial_z  # Now this will work as initial_z is set before this is called\n",
    "        return point\n",
    "\n",
    "    def calculate_total_length(self, subdivisions=1000):\n",
    "        total_length = 0.0\n",
    "        prev_point = self.bezier_recursive(0)\n",
    "        \n",
    "        for i in range(1, subdivisions + 1):\n",
    "            t = i / subdivisions\n",
    "            curr_point = self.bezier_recursive(t)\n",
    "            total_length += np.linalg.norm(curr_point - prev_point)\n",
    "            prev_point = curr_point\n",
    "        \n",
    "        # return total_length\n",
    "        return 0.125\n",
    "\n",
    "    def get_point_and_tangent(self, t):\n",
    "        point = self.bezier_recursive(t)\n",
    "        \n",
    "        delta = 0.001\n",
    "        t_next = min(1.0, t + delta)\n",
    "        next_point = self.bezier_recursive(t_next)\n",
    "        \n",
    "        tangent = next_point - point\n",
    "        if np.linalg.norm(tangent) > 0:\n",
    "            tangent = tangent / np.linalg.norm(tangent)\n",
    "        \n",
    "        return point, tangent\n",
    "\n",
    "    def update_orientation(self, current_pos, tangent):\n",
    "        forward = np.array([1, 0, 0])  # Assuming robot's forward direction is along x-axis\n",
    "        rotation_axis = np.cross(forward, tangent)\n",
    "        \n",
    "        if np.linalg.norm(rotation_axis) > 0:\n",
    "            rotation_axis = rotation_axis / np.linalg.norm(rotation_axis)\n",
    "            angle = np.arccos(np.dot(forward, tangent))\n",
    "            \n",
    "            s = np.sin(angle/2)\n",
    "            quat = [np.cos(angle/2), rotation_axis[0]*s, rotation_axis[1]*s, rotation_axis[2]*s]\n",
    "            \n",
    "            ssim.setObjectQuaternion(self.bubbleRobHandle, -1, quat)\n",
    "\n",
    "    def follow_path(self):\n",
    "        # Verify handle is valid before starting\n",
    "        if self.bubbleRobHandle == -1:\n",
    "            print(\"Invalid robot handle\")\n",
    "            return\n",
    "            \n",
    "        self.previousSimulationTime = sim.getSimulationTime()\n",
    "        start_pos = sim.getObjectPosition(self.bubbleRobHandle, -1)\n",
    "        print(f\"Starting position: {start_pos}\")  # Debug print\n",
    "        \n",
    "        while self.posAlongPath < self.totalLength:\n",
    "            t = sim.getSimulationTime()\n",
    "            deltaT = t - self.previousSimulationTime\n",
    "            \n",
    "            if deltaT <= 0.0:\n",
    "                self.previousSimulationTime = t\n",
    "                continue\n",
    "            \n",
    "            self.posAlongPath += self.velocity * deltaT\n",
    "            \n",
    "            if self.posAlongPath >= self.totalLength - 0.001:\n",
    "                self.posAlongPath = self.totalLength\n",
    "                print(\"Reached the end of the path!\")\n",
    "                break\n",
    "            \n",
    "            t_norm = np.clip(self.posAlongPath / self.totalLength, 0, 1)\n",
    "            current_pos, tangent = self.get_point_and_tangent(t_norm)\n",
    "            \n",
    "            # Ensure Z coordinate and convert to list\n",
    "            current_pos[2] = self.initial_z\n",
    "            pos_list = current_pos.tolist()\n",
    "            \n",
    "            # Set position with error checking\n",
    "            try:\n",
    "                ret = sim.setObjectPosition(self.bubbleRobHandle, -1, pos_list)\n",
    "                if ret == -1:\n",
    "                    print(f\"Failed to set position: {pos_list}\")\n",
    "                current_actual_pos = sim.getObjectPosition(self.bubbleRobHandle, -1)\n",
    "                if current_actual_pos != pos_list:\n",
    "                    print(f\"Position mismatch - Requested: {pos_list}, Actual: {current_actual_pos}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting position: {e}\")\n",
    "                break\n",
    "                \n",
    "            # Update orientation\n",
    "            self.update_orientation(current_pos, tangent)\n",
    "            \n",
    "            self.previousSimulationTime = t\n",
    "            sim.step()\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "        # Print final position for debugging\n",
    "        end_pos = sim.getObjectPosition(self.bubbleRobHandle, -1)\n",
    "        print(f\"Ending position: {end_pos}\")\n",
    "\n",
    "    \n",
    "    def step(self, action_label):\n",
    "        sim.startSimulation()\n",
    "        if action_label == \"UP\": \n",
    "            self.y = max(0, self.y - 1)  # Move up (decrease y)\n",
    "            self.ctrlPts.append([grid_to_coordinates(self.x,self.y)[0], grid_to_coordinates(self.x,self.y)[1], 0.05,0.0,0.0,0.0,1.0])\n",
    "            self.ctrlPts_flattened = [coord for point in ctrlPts for coord in point]\n",
    "            self.totalLength = self.calculate_total_length()\n",
    "            print(self.totalLength)\n",
    "            print(self.ctrlPts)\n",
    "            print(self.ctrlPts_flattened)\n",
    "            pathHandle = sim.createPath(\n",
    "                self.ctrlPts_flattened,\n",
    "                0,  # Options: open path\n",
    "                100,  # Subdivision for smoothness\n",
    "                1,  # No smoothness\n",
    "                0,  # Orientation mode\n",
    "                [0.0, 0.0, 1.0]\n",
    "            )\n",
    "            self.follow_path()\n",
    "            monitor_position()\n",
    "            time.sleep(0.05)\n",
    "            self.ctrlPts.clear()\n",
    "            \n",
    "        elif action_label == \"DOWN\": \n",
    "            self.y = min(grid_dims[1] - 1, self.y + 1)  # Move down (increase y)\n",
    "            self.ctrlPts.append([grid_to_coordinates(self.x,self.y)[0], grid_to_coordinates(self.x,self.y)[1], 0.05,0.0,0.0,0.0,1.0])\n",
    "            self.ctrlPts_flattened = [coord for point in ctrlPts for coord in point]\n",
    "            self.totalLength = self.calculate_total_length()\n",
    "            print(self.totalLength)\n",
    "            print(self.ctrlPts)\n",
    "            print(self.ctrlPts_flattened)\n",
    "            pathHandle = sim.createPath(\n",
    "                self.ctrlPts_flattened,\n",
    "                0,  # Options: open path\n",
    "                100,  # Subdivision for smoothness\n",
    "                1,  # No smoothness\n",
    "                0,  # Orientation mode\n",
    "                [0.0, 0.0, 1.0]\n",
    "            )\n",
    "            self.follow_path()\n",
    "            monitor_position()\n",
    "            time.sleep(0.05)\n",
    "            self.ctrlPts.clear()\n",
    "            \n",
    "        elif action_label == \"LEFT\": \n",
    "            self.x = max(0, self.x - 1)  # Move left (decrease x)\n",
    "            self.ctrlPts.append([grid_to_coordinates(self.x,self.y)[0], grid_to_coordinates(self.x,self.y)[1], 0.05,0.0,0.0,0.0,1.0])\n",
    "            self.ctrlPts_flattened = [coord for point in ctrlPts for coord in point]\n",
    "            self.totalLength = self.calculate_total_length()\n",
    "            print(self.totalLength)\n",
    "            print(self.ctrlPts)\n",
    "            print(self.ctrlPts_flattened)\n",
    "            pathHandle = sim.createPath(\n",
    "                self.ctrlPts_flattened,\n",
    "                0,  # Options: open path\n",
    "                100,  # Subdivision for smoothness\n",
    "                1,  # No smoothness\n",
    "                0,  # Orientation mode\n",
    "                [0.0, 0.0, 1.0]\n",
    "            )\n",
    "            self.follow_path()\n",
    "            monitor_position()\n",
    "            time.sleep(0.05)\n",
    "            self.ctrlPts.clear()\n",
    "            self.ctrlPts.append([grid_to_coordinates(self.x,self.y)[0], grid_to_coordinates(self.x,self.y)[1], 0.05,0.0,0.0,0.0,1.0])\n",
    "        elif action_label == \"RIGHT\": \n",
    "            self.x = min(grid_dims[0] - 1, self.x + 1)  # Move right (increase x)\n",
    "            self.ctrlPts.append([grid_to_coordinates(self.x,self.y)[0], grid_to_coordinates(self.x,self.y)[1], 0.05,0.0,0.0,0.0,1.0])\n",
    "            self.ctrlPts_flattened = [coord for point in ctrlPts for coord in point]\n",
    "            self.totalLength = self.calculate_total_length()\n",
    "            print(self.totalLength)\n",
    "            print(self.ctrlPts)\n",
    "            print(self.ctrlPts_flattened)\n",
    "            pathHandle = sim.createPath(\n",
    "                self.ctrlPts_flattened,\n",
    "                0,  # Options: open path\n",
    "                100,  # Subdivision for smoothness\n",
    "                1,  # No smoothness\n",
    "                0,  # Orientation mode\n",
    "                [0.0, 0.0, 1.0]\n",
    "            )\n",
    "            self.follow_path()\n",
    "            monitor_position()\n",
    "            time.sleep(0.05)\n",
    "            self.ctrlPts.clear()\n",
    "            self.ctrlPts.append([grid_to_coordinates(self.x,self.y)[0], grid_to_coordinates(self.x,self.y)[1], 0.05,0.0,0.0,0.0,1.0])\n",
    "        # Update current_location tuple after movement\n",
    "        self.current_location = (self.x, self.y)\n",
    "        print(f\"self.current_location: {self.current_location}\")\n",
    "        \n",
    "        # Update vision with current coordinates\n",
    "        self.vision = update_vision(self.current_location, grid_dims, 6)\n",
    "\n",
    "        self.loc_obs = self.current_location\n",
    "\n",
    "        # Reset observations at each step\n",
    "        self.red_obs = ['Null']\n",
    "        self.white_obs = ['Null']\n",
    "        self.green_obs = 'Null'\n",
    "\n",
    "        # Update observations based on vision\n",
    "        for spot in self.vision:\n",
    "            if spot in self.redspots:\n",
    "                if 'Null' in self.red_obs:\n",
    "                    self.red_obs = [spot]\n",
    "                else:\n",
    "                    self.red_obs.append(spot)\n",
    "            elif spot == self.goal:\n",
    "                self.green_obs = spot\n",
    "                \n",
    "            else:\n",
    "                if 'Null' in self.white_obs:\n",
    "                    self.white_obs = [spot]\n",
    "                else:\n",
    "                    self.white_obs.append(spot)\n",
    "\n",
    "        # Update rewards and observations based on current location\n",
    "        if self.current_location in self.redspots:\n",
    "            self.agent_reward -= 5\n",
    "            if 'Null' in self.red_obs:\n",
    "                self.red_obs = [self.current_location]\n",
    "            else:\n",
    "                self.red_obs.append(self.current_location)\n",
    "        elif self.current_location == self.goal:\n",
    "            self.agent_reward += 20\n",
    "            self.green_obs = self.current_location\n",
    "        else:\n",
    "            if 'Null' in self.white_obs:\n",
    "                self.white_obs = [self.current_location]\n",
    "            else:\n",
    "                self.white_obs.append(self.current_location)\n",
    "        \n",
    "        return self.loc_obs, self.green_obs, self.white_obs, self.red_obs, self.agent_reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x, self.y = self.init_loc\n",
    "        self.current_location = (self.x, self.y)\n",
    "        print(f'Re-initialized location to {self.current_location}')\n",
    "        self.loc_obs = self.current_location\n",
    "        self.green_obs, self.white_obs, self.red_obs, self.agent_reward = 'Null', ['Null'], ['Null'], 0\n",
    "\n",
    "        return self.loc_obs, self.green_obs, self.white_obs, self.red_obs, self.agent_reward\n",
    "    \n",
    "my_env = CoppeliaEnv(starting_loc = agent_pos, redspots=redspots, goal = goal_location)\n",
    "loc_obs, green_obs, white_obs, red_obs, agent_reward = my_env.reset()\n",
    "loc_obs, green_obs, white_obs, red_obs, agent_reward\n",
    "loc_obs, green_obs, white_obs, red_obs, agent_reward = my_env.step('STAY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = create_observation(loc_obs, red_obs, green_obs, white_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "history_of_locs = [loc_obs]\n",
    "\n",
    "T = 15\n",
    "\n",
    "\n",
    "for t in range(T):\n",
    "    obs = create_observation(loc_obs, red_obs, green_obs, white_obs)\n",
    "    print(f\"Observation: {obs}\")\n",
    "    vision_matrix = update_vision_matrix(vision_matrix, obs)\n",
    "\n",
    "    # Update beliefs\n",
    "    qs = my_agent.infer_states(obs)\n",
    "\n",
    "    # plot_beliefs(qs[0])\n",
    "    # plot_beliefs(qs[1])\n",
    "    \n",
    "    # Update obs matrix\n",
    "    surrounding_locs = update_vision(loc_obs, grid_dims, 2)\n",
    "    for loc in surrounding_locs:\n",
    "        obs = create_observation(loc, red_obs, green_obs, white_obs)\n",
    "        vision_matrix = update_vision_matrix(vision_matrix, obs)\n",
    "        \n",
    "    visualize_vision_matrix(vision_matrix, grid_dims)\n",
    "    \n",
    "    # Policy selection\n",
    "    my_agent.infer_policies()\n",
    "    chosen_action_id = my_agent.sample_action()\n",
    "    \n",
    "    movement_id = int(chosen_action_id[0])\n",
    "    choice_action = actions[movement_id]\n",
    "    print(f'Action at time {t}: {choice_action}')\n",
    "    \n",
    "    # Environment step\n",
    "    loc_obs, green_obs, white_obs, red_obs, agent_reward = my_env.step(choice_action)\n",
    "    \n",
    "    print(agent_reward, loc_obs, green_obs, white_obs, red_obs)\n",
    "    history_of_locs.append(loc_obs)\n",
    "    print(f'Grid location at time {t}: {loc_obs}')\n",
    "    print(f'Reward at time {t}: {agent_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
