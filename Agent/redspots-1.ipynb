{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redspots Environment\n",
    "\n",
    "## Environment Description\n",
    "\n",
    "A simple gridworld with white (safe) spots, green (rewarding) spots, and red (undesirable/dangerous) spots.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Have an agent map the environment and infer the best way to avoid red spots and get to the green spot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pymdp\n",
    "from pymdp import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxilaryfunctions import plot_grid, add_noise, plot_likelihood, plot_beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_dimensions\n",
    "grid_dims = [200, 200]\n",
    "\n",
    "# list of grid positiions\n",
    "grid_locations = []\n",
    "for i in range(grid_dims[0]):\n",
    "    for j in range(grid_dims[1]):\n",
    "        grid_locations.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "redspots = [(73, 23), (67, 23), (73, 17), (67, 17), (88, 53), (82, 53), (82, 47), (88, 47), (73, 78), (67, 78), (73, 71), (67, 71), (23, 73), (17, 73), (23, 67), (17, 67), (23, 73), (17, 73), (23, 67), (17, 67)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start point\n",
    "agent_pos = (0,0)\n",
    "\n",
    "# end goal\n",
    "goal_location = (6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States & Observations\n",
    "\n",
    "s1 = current location \\\n",
    "s2 = attribute of current location\n",
    "\n",
    "o1 = observed current location \\\n",
    "o2 = color of current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1 is already defined = grid_locations\n",
    "\n",
    "# s2\n",
    "current_attribute = ['SAFE', 'DANGER', 'REWARDING']\n",
    "\n",
    "# s3\n",
    "right_attribute = ['SAFE', 'DANGER', 'REWARDING', 'N/A']\n",
    "\n",
    "# s4\n",
    "left_attribute = ['SAFE', 'DANGER', 'REWARDING', 'N/A']\n",
    "\n",
    "# s5\n",
    "up_attribute = ['SAFE', 'DANGER', 'REWARDING', 'N/A']\n",
    "\n",
    "# s6\n",
    "down_attribute = ['SAFE', 'DANGER', 'REWARDING', 'N/A']\n",
    "\n",
    "# list of # of possibillities for states\n",
    "num_states = [len(grid_locations), len(current_attribute), len(right_attribute), len(left_attribute), len(up_attribute), len(down_attribute)] # location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o1 is already defined = grid_locatioons\n",
    "\n",
    "# o2\n",
    "current_color = ['WHITE', 'RED', 'GREEN']\n",
    "\n",
    "# o3\n",
    "right_color = ['WHITE', 'RED', 'GREEN', 'N/A']\n",
    "\n",
    "# o4\n",
    "left_color = ['WHITE', 'RED', 'GREEN', 'N/A']\n",
    "\n",
    "# o5\n",
    "up_color = ['WHITE', 'RED', 'GREEN', 'N/A']\n",
    "\n",
    "# o6\n",
    "down_color = ['WHITE', 'RED', 'GREEN', 'N/A']\n",
    "\n",
    "\n",
    "# list of # of possibilities for observations\n",
    "num_obs = [len(grid_locations), len(current_color), len(right_color), len(left_color), len(up_color), len(down_color)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       ...,\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_matrix = np.zeros((num_states[0], num_states[1]))\n",
    "\n",
    "# Rule-based assignment\n",
    "for loc in range(num_states[0]):\n",
    "    # Example: Assume all locations have [SAFE: 0.7, DANGER: 0.2, REWARDING: 0.1]\n",
    "    rule_matrix[loc] = np.array([0.33, 0.33, 0.33])\n",
    "    rule_matrix[loc] /= rule_matrix[loc].sum()\n",
    "\n",
    "    # Normalize each location's attribute distribution (ensure sum = 1)\n",
    "\n",
    "rule_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red, green, white, one-hot encoded\n",
    "# rule_matrix -> white, red, green -> safe, dangerous, rewarding\n",
    "\n",
    "def update_rule_matrix(rule_matrix, beliefs):\n",
    "\n",
    "    # Take current location\n",
    "    s1 = np.argmax(beliefs[0])\n",
    "\n",
    "    # Take safety belief\n",
    "    s2 = np.argmax(beliefs[1])\n",
    "\n",
    "    # one hot encoding\n",
    "    if s2 == 0: rule_matrix[s1] = [1, 0, 0]\n",
    "    elif s2 == 1: rule_matrix[s1] = [0, 1, 0]\n",
    "    else: rule_matrix[s1] = [0, 0, 1]\n",
    "\n",
    "    return rule_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define A Matrix\n",
    "A_shapes = []\n",
    "for i in num_obs:\n",
    "    A_shapes.append([i] + num_states)\n",
    "\n",
    "A = utils.obj_array_zeros(A_shapes)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Observation Modality A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrix for location observations\n",
    "A[0] = np.zeros(A_shapes[0])  # Initialize with zeros\n",
    "\n",
    "# Create identity mapping for locations, regardless of safety levels\n",
    "base_mapping = np.eye(num_states[0])  # 40x40 identity matrix for locations\n",
    "\n",
    "# Fill in the observation mapping for each combination of hidden state factors\n",
    "for s1 in range(num_states[1]):  # current attribute\n",
    "    for s2 in range(num_states[2]):  # right attribute\n",
    "        for s3 in range(num_states[3]):  # left attribute\n",
    "            for s4 in range(num_states[4]):  # up attribute\n",
    "                for s5 in range(num_states[5]):  # down attribute\n",
    "                    A[0][:,:,s1,s2,s3,s4,s5] = base_mapping\n",
    "\n",
    "# Verify the shape and normalization\n",
    "print(\"A[0] shape:\", A[0].shape)\n",
    "print(\"Column sums:\", np.allclose(A[0].sum(axis=0), 1.0))  # Should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a 2D slice by fixing all other dimensions to 0\n",
    "plot_likelihood(A[0][:,:,0,0,0,0,0], \"Location observation likelihood matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color observation modality: A[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map safety levels to indices\n",
    "safety_level_to_index = {state: i for i, state in enumerate(current_attribute)}  # {'SAFE': 0, 'DANGER': 1, 'REWARDING': 2}\n",
    "\n",
    "# Probabilities for each color given the safety level (in correct heatmap order: RED, GREEN, WHITE)\n",
    "probabilities = {\n",
    "    \"SAFE\": [1, 0, 0],        # ['WHITE', 'RED', 'GREEN']\n",
    "    \"DANGER\": [0, 1, 0.],      # ['WHITE', 'RED', 'GREEN']\n",
    "    \"REWARDING\": [0, 0, 1]    # ['WHITE', 'RED', 'GREEN']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Populate A[1] with the mapping from safety states to color observations\n",
    "\n",
    "for location in range(num_states[0]):  # For each location\n",
    "\n",
    "    for s1 in range(num_states[1]):  # current attribute\n",
    "\n",
    "        for s2 in range(num_states[2]):  # right attribute\n",
    "\n",
    "            for s3 in range(num_states[3]):  # left attribute\n",
    "\n",
    "                for s4 in range(num_states[4]):  # up attribute\n",
    "\n",
    "                    for s5 in range(num_states[5]):  # down attribute\n",
    "\n",
    "                        # Get the probabilities based on the current attribute (s1)\n",
    "\n",
    "                        if s1 == 0:  # SAFE\n",
    "\n",
    "                            A[1][:, location, s1, s2, s3, s4, s5] = [1, 0, 0]  # WHITE\n",
    "\n",
    "                        elif s1 == 1:  # DANGER\n",
    "\n",
    "                            A[1][:, location, s1, s2, s3, s4, s5] = [0, 1, 0]  # RED\n",
    "\n",
    "                        else:  # REWARDING\n",
    "\n",
    "                            A[1][:, location, s1, s2, s3, s4, s5] = [0, 0, 1]  # GREEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 3 subplots (one for each safety state)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Extract and plot each safety state slice\n",
    "for safety_idx in range(3):\n",
    "    # Get a slice for the current safety state (fixing all other dimensions to 0)\n",
    "    slice_matrix = A[1][:, :, safety_idx, 0, 0, 0, 0]\n",
    "    \n",
    "    # Plot the slice\n",
    "    sns.heatmap(slice_matrix, ax=axes[safety_idx], cmap='gray', cbar=False, vmin=0.0, vmax=1.0)\n",
    "    axes[safety_idx].set_title(f'Safety State {safety_idx}')\n",
    "    axes[safety_idx].set_xlabel('Location States')\n",
    "    if safety_idx == 0:\n",
    "        axes[safety_idx].set_ylabel('Color Observations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacent Locations Attributes Observation Modalities - A[2] through A[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 6):\n",
    "\n",
    "    for location in range(num_states[0]):  # For each location\n",
    "\n",
    "        for s1 in range(num_states[1]):  # current attribute\n",
    "\n",
    "            for s2 in range(num_states[2]):  # right attribute\n",
    "\n",
    "                for s3 in range(num_states[3]):  # left attribute\n",
    "\n",
    "                    for s4 in range(num_states[4]):  # up attribute\n",
    "\n",
    "                        for s5 in range(num_states[5]):  # down attribute\n",
    "\n",
    "                            # Get the probabilities based on the current attribute (s1)\n",
    "\n",
    "                            if s1 == 0:  # SAFE\n",
    "\n",
    "                                A[i][:, location, s1, s2, s3, s4, s5] = [1, 0, 0, 0]  # WHITE, RED, GREEN, N/A\n",
    "\n",
    "                            elif s1 == 1:  # DANGER\n",
    "\n",
    "                                A[i][:, location, s1, s2, s3, s4, s5] = [0, 1, 0, 0]  # WHITE, RED, GREEN, N/A\n",
    "\n",
    "                            elif s1 == 2:  # REWARDING\n",
    "\n",
    "                                A[i][:, location, s1, s2, s3, s4, s5] = [0, 0, 1, 0]  # WHITE, RED, GREEN, N/A\n",
    "\n",
    "                            else:  # N/A\n",
    "\n",
    "                                A[i][:, location, s1, s2, s3, s4, s5] = [0, 0, 0, 1]  # WHITE, RED, GREEN, N/A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 6):\n",
    "    # Create a figure with 3 subplots (one for each safety state)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Extract and plot each safety state slice\n",
    "    for safety_idx in range(3):\n",
    "        # Get a slice for the current safety state (fixing all other dimensions to 0)\n",
    "        slice_matrix = A[i][:, :, safety_idx, 0, 0, 0, 0]\n",
    "        \n",
    "        # Plot the slice\n",
    "        sns.heatmap(slice_matrix, ax=axes[safety_idx], cmap='gray', cbar=False, vmin=0.0, vmax=1.0)\n",
    "        axes[safety_idx].set_title(f'Safety State {safety_idx}')\n",
    "        axes[safety_idx].set_xlabel('Location States')\n",
    "        if safety_idx == 0:\n",
    "            axes[safety_idx].set_ylabel('Color Observations')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to each modality separately\n",
    "for modality in range(len(A)):\n",
    "    A[modality] = add_noise(A[modality], noise_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Each Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_controls = [5, 1, 1, 1, 1, 1]\n",
    "B_f_shapes = [ [ns, ns, num_controls[f]] for f, ns in enumerate(num_states)]\n",
    "B = utils.obj_array_zeros(B_f_shapes)\n",
    "B_f_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B[0] - Control Factor - Location Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"STAY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action_id, action_label in enumerate(actions):\n",
    "  \n",
    "    for curr_state, (x, y) in enumerate(grid_locations):\n",
    "        \n",
    "        # Calculate next position based on action\n",
    "        if action_label == \"UP\":\n",
    "            next_y = max(0, y - 1)        # Move up (decrease y)\n",
    "            next_x = x\n",
    "        elif action_label == \"DOWN\":\n",
    "            next_y = min(grid_dims[1]-1, y + 1)  # Move down (increase y)\n",
    "            next_x = x\n",
    "        elif action_label == \"LEFT\":\n",
    "            next_x = max(0, x - 1)        # Move left (decrease x)\n",
    "            next_y = y\n",
    "        elif action_label == \"RIGHT\":\n",
    "            next_x = min(grid_dims[0]-1, x + 1)  # Move right (increase x)\n",
    "            next_y = y\n",
    "        else:  # STAY\n",
    "            next_x = x\n",
    "            next_y = y\n",
    "        \n",
    "        # Get the state index for the next position\n",
    "        next_state = grid_locations.index((next_x, next_y))\n",
    "        \n",
    "        # Set transition probability to 1.0\n",
    "        B[0][next_state, curr_state, action_id] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B[1] - Non-Control Factor - Identity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize safety level transition matrix (no changes for safety levels)\n",
    "B[1][:,:,0] = np.eye(3)  # Identity matrix for safety level transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B[2] and beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "    B[i] = B[1][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize B matrix columns for each action\n",
    "for action_id in range(len(actions)):\n",
    "    # Get slice for current action\n",
    "    B_action = B[0][..., action_id]\n",
    "    \n",
    "    # Replace zero columns with ones in appropriate positions\n",
    "    zero_cols = (B_action.sum(axis=0) == 0)\n",
    "    for col in range(B_action.shape[1]):\n",
    "        if zero_cols[col]:\n",
    "            # Stay in the same state if no transition is defined\n",
    "            B_action[col, col] = 1.0\n",
    "    \n",
    "    # Normalize columns\n",
    "    column_sums = B_action.sum(axis=0)\n",
    "    B[0][..., action_id] = B_action / column_sums[None, :]\n",
    "\n",
    "# Verify normalization\n",
    "for action_id in range(len(actions)):\n",
    "    assert np.allclose(B[0][..., action_id].sum(axis=0), 1.0), f\"Action {actions[action_id]} not normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C Vectors (prior preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = utils.obj_array_zeros(num_obs)  # Initialize C array with shape matching num_obs\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C[0] - Preference for location observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set preferences for state observations (location)\n",
    "C[0] = np.ones(len(grid_locations))\n",
    "C[0][grid_locations.index(goal_location)] += 1\n",
    "\n",
    "print(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, loc in enumerate(grid_locations):\n",
    "    x = ((goal_location[0] - loc[0])**2 + (goal_location[1] - loc[1])**2) ** 0.5\n",
    "    print(loc, i, x)\n",
    "    C[0][i] -= x * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.maths import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[0] = softmax(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beliefs(C[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C[1] - Preference for color observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white, red, green <- order it's encoded in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set preferences for color observations\n",
    "C[1] = np.zeros((num_obs[1],))\n",
    "C[1][0] = -0.1\n",
    "C[1][1] = -1\n",
    "C[1][2] = 1.1\n",
    "\n",
    "print(C[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C[2] and beyond - preference for adjacent color observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set preferences for color observations\n",
    "for i in range(2,6):\n",
    "    C[i] = np.zeros((num_obs[i],))\n",
    "    C[i][0] = -0.01\n",
    "    C[i][1] = -0.1\n",
    "    C[i][2] = .11\n",
    "\n",
    "    print(C[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D Vectors: Prior beliefs about hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "num_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = utils.obj_array_uniform(num_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D[0] - Belief About Current Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prior belief about agent's location (same as before)\n",
    "D[0] = np.zeros(num_states[0])  # Shape (35,)\n",
    "D[0][grid_locations.index(agent_pos)] = 1.0  # One-hot encoding for location\n",
    "\n",
    "print(\"D[0] shape (Location prior):\", D[0].shape)  # (35,)\n",
    "D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize uniform distribution over locations\n",
    "# D[0] = np.ones(num_states[0]) / num_states[0]  # Create normalized uniform distribution over all locations\n",
    "\n",
    "# D[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D[1] - Belief About Attribute of Current Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[1] = np.ones(num_states[1]) / num_states[1]  # Create normalized uniform distribution over all locations\n",
    "D[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beliefs(D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beliefs(D[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D[2] and beyond - Belief About Attributes of Adjacent Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,6):\n",
    "    D[i] = D[1][:]\n",
    "    plot_beliefs(D[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vision(current_location, grid_dims, distance):\n",
    "    \"\"\"\n",
    "    Update the agent's field of vision based on the current location and distance\n",
    "    Returns a list of all grid positions within the vision range\n",
    "    \n",
    "    Args:\n",
    "        current_location (tuple): Current (x,y) position of the agent\n",
    "        grid_dims (list): Dimensions of the grid [width, height]\n",
    "        distance (int): Vision range/distance\n",
    "        \n",
    "    Returns:\n",
    "        list: List of (x,y) tuples representing visible grid positions\n",
    "    \"\"\"\n",
    "    x, y = current_location\n",
    "    x_min = max(0, x - distance)\n",
    "    x_max = min(grid_dims[0], x + distance + 1)\n",
    "    y_min = max(0, y - distance)\n",
    "    y_max = min(grid_dims[1], y + distance + 1)\n",
    "    \n",
    "    visible_locations = []\n",
    "    for y_pos in range(y_min, y_max):\n",
    "        for x_pos in range(x_min, x_max):\n",
    "            visible_locations.append((x_pos, y_pos))\n",
    "            \n",
    "    return visible_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv():\n",
    "    def __init__(self, starting_loc=(0, 0), redspots=[(1, 2), (3, 2), (4, 4), (6, 1)], goal=(6,4)):\n",
    "        # Initialize coordinates\n",
    "        self.x, self.y = starting_loc\n",
    "        self.init_loc = starting_loc\n",
    "        self.current_location = (self.x, self.y)\n",
    "\n",
    "        self.goal = goal\n",
    "\n",
    "        self.redspots = redspots\n",
    "\n",
    "        self.red_obs = ['Null']\n",
    "        self.green_obs = 'Null'\n",
    "        self.white_obs = ['Null']\n",
    "\n",
    "        self.agent_reward = 0\n",
    "        \n",
    "        print(f\"Starting location is {self.current_location} | Red spot locations are {self.redspots} | Goal is {self.goal}\")\n",
    "    \n",
    "    def step(self, action_label):\n",
    "        if action_label == \"UP\": \n",
    "            self.y = max(0, self.y - 1)  # Move up (decrease y)\n",
    "            \n",
    "        elif action_label == \"DOWN\": \n",
    "            self.y = min(grid_dims[1] - 1, self.y + 1)  # Move down (increase y)\n",
    "\n",
    "        elif action_label == \"LEFT\": \n",
    "            self.x = max(0, self.x - 1)  # Move left (decrease x)\n",
    "\n",
    "        elif action_label == \"RIGHT\": \n",
    "            self.x = min(grid_dims[0] - 1, self.x + 1)  # Move right (increase x)\n",
    "\n",
    "        # Update current_location tuple after movement\n",
    "        self.current_location = (self.x, self.y)\n",
    "        print(f\"self.current_location: {self.current_location}\")\n",
    "        \n",
    "        # Update vision with current coordinates\n",
    "        self.vision = update_vision(self.current_location, grid_dims, 6)\n",
    "\n",
    "        self.loc_obs = self.current_location\n",
    "\n",
    "        # Reset observations at each step\n",
    "        self.red_obs = ['Null']\n",
    "        self.white_obs = ['Null']\n",
    "        self.green_obs = 'Null'\n",
    "\n",
    "        # Update observations based on vision\n",
    "        for spot in self.vision:\n",
    "            if spot in self.redspots:\n",
    "                if 'Null' in self.red_obs:\n",
    "                    self.red_obs = [spot]\n",
    "                else:\n",
    "                    self.red_obs.append(spot)\n",
    "            elif spot == self.goal:\n",
    "                self.green_obs = spot\n",
    "            else:\n",
    "                if 'Null' in self.white_obs:\n",
    "                    self.white_obs = [spot]\n",
    "                else:\n",
    "                    self.white_obs.append(spot)\n",
    "\n",
    "        # Update rewards and observations based on current location\n",
    "        if self.current_location in self.redspots:\n",
    "            self.agent_reward -= 5\n",
    "            if 'Null' in self.red_obs:\n",
    "                self.red_obs = [self.current_location]\n",
    "            else:\n",
    "                self.red_obs.append(self.current_location)\n",
    "        elif self.current_location == self.goal:\n",
    "            self.agent_reward += 20\n",
    "            self.green_obs = self.current_location\n",
    "        else:\n",
    "            if 'Null' in self.white_obs:\n",
    "                self.white_obs = [self.current_location]\n",
    "            else:\n",
    "                self.white_obs.append(self.current_location)\n",
    "        \n",
    "        return self.loc_obs, self.green_obs, self.white_obs, self.red_obs, self.agent_reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x, self.y = self.init_loc\n",
    "        self.current_location = (self.x, self.y)\n",
    "        print(f'Re-initialized location to {self.current_location}')\n",
    "        self.loc_obs = self.current_location\n",
    "        self.green_obs, self.white_obs, self.red_obs, self.agent_reward = 'Null', ['Null'], ['Null'], 0\n",
    "\n",
    "        return self.loc_obs, self.green_obs, self.white_obs, self.red_obs, self.agent_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_pos, redspots, goal_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent = Agent(A=A, B=B, C=C, D=D, policy_len=6)\n",
    "\n",
    "my_env = GridWorldEnv(starting_loc = agent_pos, redspots=redspots, goal = goal_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_obs, green_obs, white_obs, red_obs, agent_reward = my_env.reset()\n",
    "loc_obs, green_obs, white_obs, red_obs, agent_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_obs, green_obs, white_obs, red_obs, agent_reward = my_env.step('STAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_obs, green_obs, white_obs, red_obs, agent_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_color_observation(position, red_obs, green_obs, white_obs):\n",
    "\n",
    "    if red_obs != ['Null']:\n",
    "        if position in red_obs: return 1  # RED\n",
    "    if green_obs == position: return 2 # GREEN\n",
    "    elif white_obs != ['Null']:\n",
    "        if position in white_obs: return 0 # WHITE\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_observation(position, red_obs, green_obs, white_obs):\n",
    "    return [grid_locations.index(position), create_color_observation(position, red_obs, green_obs, white_obs), create_color_observation((position[0] + 1, position[1]), red_obs, green_obs, white_obs), create_color_observation((position[0] - 1, position[1]), red_obs, green_obs, white_obs), create_color_observation((position[0], position[1] - 1), red_obs, green_obs, white_obs), create_color_observation((position[0], position[1] + 1), red_obs, green_obs, white_obs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.qs[0], my_agent.qs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = create_observation(loc_obs, red_obs, green_obs, white_obs)\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_of_locs = [loc_obs]\n",
    "\n",
    "T = 15\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    obs = create_observation(loc_obs, red_obs, green_obs, white_obs)\n",
    "\n",
    "    # generate observations\n",
    "    print(f\"Observation: {obs}\")\n",
    "\n",
    "    # belief posterior\n",
    "    qs = my_agent.infer_states(obs) #directly updates using bayesian inference \n",
    "\n",
    "    # plot belief posterior\n",
    "    plot_beliefs(qs[0])\n",
    "    plot_beliefs(qs[1])\n",
    "\n",
    "    # use belief posterior to update rule matrix\n",
    "    rule_matrix = update_rule_matrix(rule_matrix, qs)\n",
    "    print(f\"Rule Matrix at loc {loc_obs}: {rule_matrix[obs[0]]}\")\n",
    "\n",
    "    # ruled based update on A\n",
    "    # A = rule_based_update_A(rule_matrix, A)\n",
    "\n",
    "    # plot updated A\n",
    "    # plot_A_1(A)\n",
    "\n",
    "\n",
    "    # policy selection\n",
    "    my_agent.infer_policies()\n",
    "    \n",
    "    chosen_action_id = my_agent.sample_action()\n",
    "\n",
    "    movement_id = int(chosen_action_id[0])\n",
    "\n",
    "    choice_action = actions[movement_id]\n",
    "\n",
    "    print(f'Action at time {t}: {choice_action}')\n",
    "\n",
    "    \n",
    "    loc_obs, green_obs, white_obs, red_obs, agent_reward = my_env.step(choice_action)\n",
    "    \n",
    "    print(agent_reward, loc_obs, green_obs, white_obs, red_obs)\n",
    "\n",
    "\n",
    "    history_of_locs.append(loc_obs)\n",
    "\n",
    "    print(f'Grid location at time {t}: {loc_obs}')\n",
    "\n",
    "    print(f'Reward at time {t}: {agent_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
