{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redspots Environment\n",
    "\n",
    "## Environment Description\n",
    "\n",
    "A simple gridworld with white (safe) spots, green (rewarding) spots, and red (undesirable/dangerous) spots.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Have an agent map the environment and infer the best way to avoid red spots and get to the green spot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pymdp\n",
    "from pymdp import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxilaryfunctions import plot_grid, add_noise, plot_likelihood, plot_beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_dimensions\n",
    "grid_dims = [8,5]\n",
    "\n",
    "# list of grid positiions\n",
    "grid_locations = []\n",
    "for i in range(grid_dims[0]):\n",
    "    for j in range(grid_dims[1]):\n",
    "        grid_locations.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "redspots = [(1,2), (3,2), (4,4), (6,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start point\n",
    "agent_pos = (0,0)\n",
    "\n",
    "# end goal\n",
    "goal_location = (6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States & Observations\n",
    "\n",
    "s1 = current location \\\n",
    "s2 = attribute of current location\n",
    "\n",
    "o1 = observed current location \\\n",
    "o2 = color of current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1 is already defined = grid_locations\n",
    "\n",
    "# s2\n",
    "current_attribute = ['SAFE', 'DANGER', 'REWARDING']\n",
    "\n",
    "# list of # of possibillities for states\n",
    "num_states = [len(grid_locations), len(current_attribute)] # location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o1 is already defined = grid_locatioons\n",
    "\n",
    "# o2\n",
    "current_color = ['WHITE', 'RED', 'GREEN']\n",
    "\n",
    "# list of # of possibilities for observations\n",
    "num_obs = [len(grid_locations), len(current_color)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.33333333]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_matrix = np.zeros((num_states[0], num_states[1]))\n",
    "\n",
    "# Rule-based assignment\n",
    "for loc in range(num_states[0]):\n",
    "    # Example: Assume all locations have [SAFE: 0.7, DANGER: 0.2, REWARDING: 0.1]\n",
    "    rule_matrix[loc] = np.array([0.33, 0.33, 0.33])\n",
    "    rule_matrix[loc] /= rule_matrix[loc].sum()\n",
    "\n",
    "    # Normalize each location's attribute distribution (ensure sum = 1)\n",
    "\n",
    "rule_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red, green, white, one-hot encoded\n",
    "# rule_matrix -> white, red, green -> safe, dangerous, rewarding\n",
    "\n",
    "def update_rule_matrix(rule_matrix, beliefs):\n",
    "\n",
    "    # Take current location\n",
    "    s1 = np.argmax(beliefs[0])\n",
    "\n",
    "    # Take safety belief\n",
    "    s2 = np.argmax(beliefs[1])\n",
    "\n",
    "    # one hot encoding\n",
    "    if s2 == 0: rule_matrix[s1] = [1, 0, 0]\n",
    "    elif s2 == 1: rule_matrix[s1] = [0, 1, 0]\n",
    "    else: rule_matrix[s1] = [0, 0, 1]\n",
    "\n",
    "    return rule_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2,), [[40, 40, 3], [3, 40, 3]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define A Matrix\n",
    "A_shapes = []\n",
    "for i in num_obs:\n",
    "    A_shapes.append([i] + num_states)\n",
    "\n",
    "A = utils.obj_array_zeros(A_shapes)\n",
    "A.shape, A_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Observation Modality A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New A[0] shape: (40, 40, 3)\n",
      "Column sums: [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "A[0] = np.zeros(A_shapes[0])  # Initialize with zeros\n",
    "\n",
    "# Fill in the observation mapping for each safety level\n",
    "for safety_level in range(num_states[1]):\n",
    "    A[0][:,:,safety_level] = np.eye(num_states[0])  # Copy the identity matrix for each safety level\n",
    "\n",
    "# Verify the shape and normalization\n",
    "print(\"New A[0] shape:\", A[0].shape)\n",
    "print(\"Column sums:\", A[0].sum(axis=0).sum(axis=1))  # Should be all 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract a 2D slice by fixing all other dimensions to 0\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plot_likelihood(A[\u001b[38;5;241m0\u001b[39m][:, :, :], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation observation likelihood matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ISEF/Active Inference/Active-Inference-2025/auxilaryfunctions.py:19\u001b[0m, in \u001b[0;36mplot_likelihood\u001b[0;34m(matrix, title_str)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_likelihood\u001b[39m(matrix, title_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLikelihood distribution (A)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Plots a 2-D likelihood matrix as a heatmap\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(matrix\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1.0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m     20\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistribution not column-normalized! Please normalize (ensure matrix.sum(axis=0) == 1.0 for all columns)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract a 2D slice by fixing all other dimensions to 0\n",
    "import numpy as np\n",
    "plot_likelihood(A[0][:, :, :], \"Location observation likelihood matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color observation modality: A[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map safety levels to indices\n",
    "safety_level_to_index = {state: i for i, state in enumerate(current_attribute)}  # {'SAFE': 0, 'DANGER': 1, 'REWARDING': 2}\n",
    "\n",
    "# Probabilities for each color given the safety level (in correct heatmap order: RED, GREEN, WHITE)\n",
    "probabilities = {\n",
    "    \"SAFE\": [1, 0, 0],        # ['WHITE', 'RED', 'GREEN']\n",
    "    \"DANGER\": [0, 1, 0.],      # ['WHITE', 'RED', 'GREEN']\n",
    "    \"REWARDING\": [0, 0, 1]    # ['WHITE', 'RED', 'GREEN']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate A[1]\n",
    "for safety_level, probs in probabilities.items():\n",
    "    safety_idx = safety_level_to_index[safety_level]\n",
    "    for loc in range(len(grid_locations)):  # Iterate over grid locations\n",
    "        for color_idx, prob in enumerate(probs):  # Iterate over colors (RED, GREEN, WHITE)\n",
    "            A[1][color_idx, loc, safety_idx] = prob  # Assign probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure with 3 subplots (one for each safety state)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Extract and plot each safety state slice\n",
    "for safety_idx in range(3):\n",
    "    # Get a slice for the current safety state (fixing all other dimensions to 0)\n",
    "    slice_matrix = A[1][:, :, safety_idx]\n",
    "    \n",
    "    # Plot the slice\n",
    "    sns.heatmap(slice_matrix, ax=axes[safety_idx], cmap='gray', cbar=False, vmin=0.0, vmax=1.0)\n",
    "    axes[safety_idx].set_title(f'Safety State {safety_idx}')\n",
    "    axes[safety_idx].set_xlabel('Location States')\n",
    "    if safety_idx == 0:\n",
    "        axes[safety_idx].set_ylabel('Color Observations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Add noise to each modality separately\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modality \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(A)):\n\u001b[0;32m----> 3\u001b[0m     A[modality] \u001b[38;5;241m=\u001b[39m add_noise(A[modality], noise_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ISEF/Active Inference/Active-Inference-2025/auxilaryfunctions.py:51\u001b[0m, in \u001b[0;36madd_noise\u001b[0;34m(matrix, noise_level)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03mAdd noise to transition matrix while preserving normalization\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    noise_level: Amount of noise to add (0-1)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Generate random noise\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39mnoise_level, noise_level, size\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(noise) \n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Add noise to matrix\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Add noise to each modality separately\n",
    "for modality in range(len(A)):\n",
    "    A[modality] = add_noise(A[modality], noise_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Each Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 40, 5], [3, 3, 1]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_controls = [5, 1]\n",
    "B_f_shapes = [ [ns, ns, num_controls[f]] for f, ns in enumerate(num_states)]\n",
    "B = utils.obj_array_zeros(B_f_shapes)\n",
    "B_f_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B[0] - Control Factor - Location Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 5]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"STAY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action_id, action_label in enumerate(actions):\n",
    "  \n",
    "    for curr_state, (x, y) in enumerate(grid_locations):\n",
    "        \n",
    "        # Calculate next position based on action\n",
    "        if action_label == \"UP\":\n",
    "            next_y = max(0, y - 1)        # Move up (decrease y)\n",
    "            next_x = x\n",
    "        elif action_label == \"DOWN\":\n",
    "            next_y = min(grid_dims[1]-1, y + 1)  # Move down (increase y)\n",
    "            next_x = x\n",
    "        elif action_label == \"LEFT\":\n",
    "            next_x = max(0, x - 1)        # Move left (decrease x)\n",
    "            next_y = y\n",
    "        elif action_label == \"RIGHT\":\n",
    "            next_x = min(grid_dims[0]-1, x + 1)  # Move right (increase x)\n",
    "            next_y = y\n",
    "        else:  # STAY\n",
    "            next_x = x\n",
    "            next_y = y\n",
    "        \n",
    "        # Get the state index for the next position\n",
    "        next_state = grid_locations.index((next_x, next_y))\n",
    "        \n",
    "        # Set transition probability to 1.0\n",
    "        B[0][next_state, curr_state, action_id] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B[1] - Non-Control Factor - Identity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize safety level transition matrix (no changes for safety levels)\n",
    "B[1][:,:,0] = np.eye(3)  # Identity matrix for safety level transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize B matrix columns for each action\n",
    "for action_id in range(len(actions)):\n",
    "    # Get slice for current action\n",
    "    B_action = B[0][..., action_id]\n",
    "    \n",
    "    # Replace zero columns with ones in appropriate positions\n",
    "    zero_cols = (B_action.sum(axis=0) == 0)\n",
    "    for col in range(B_action.shape[1]):\n",
    "        if zero_cols[col]:\n",
    "            # Stay in the same state if no transition is defined\n",
    "            B_action[col, col] = 1.0\n",
    "    \n",
    "    # Normalize columns\n",
    "    column_sums = B_action.sum(axis=0)\n",
    "    B[0][..., action_id] = B_action / column_sums[None, :]\n",
    "\n",
    "# Verify normalization\n",
    "for action_id in range(len(actions)):\n",
    "    assert np.allclose(B[0][..., action_id].sum(axis=0), 1.0), f\"Action {actions[action_id]} not normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]]]\n"
     ]
    }
   ],
   "source": [
    "print(B[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C Vectors (prior preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "C = utils.obj_array_zeros(num_obs)  # Initialize C array with shape matching num_obs\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C[0] - Preference for location observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Set preferences for state observations (location)\n",
    "C[0] = np.ones(len(grid_locations))\n",
    "C[0][grid_locations.index(goal_location)] += 1\n",
    "\n",
    "print(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 0 7.211102550927978\n",
      "(0, 1) 1 6.708203932499369\n",
      "(0, 2) 2 6.324555320336759\n",
      "(0, 3) 3 6.082762530298219\n",
      "(0, 4) 4 6.0\n",
      "(1, 0) 5 6.4031242374328485\n",
      "(1, 1) 6 5.830951894845301\n",
      "(1, 2) 7 5.385164807134504\n",
      "(1, 3) 8 5.0990195135927845\n",
      "(1, 4) 9 5.0\n",
      "(2, 0) 10 5.656854249492381\n",
      "(2, 1) 11 5.0\n",
      "(2, 2) 12 4.47213595499958\n",
      "(2, 3) 13 4.123105625617661\n",
      "(2, 4) 14 4.0\n",
      "(3, 0) 15 5.0\n",
      "(3, 1) 16 4.242640687119285\n",
      "(3, 2) 17 3.605551275463989\n",
      "(3, 3) 18 3.1622776601683795\n",
      "(3, 4) 19 3.0\n",
      "(4, 0) 20 4.47213595499958\n",
      "(4, 1) 21 3.605551275463989\n",
      "(4, 2) 22 2.8284271247461903\n",
      "(4, 3) 23 2.23606797749979\n",
      "(4, 4) 24 2.0\n",
      "(5, 0) 25 4.123105625617661\n",
      "(5, 1) 26 3.1622776601683795\n",
      "(5, 2) 27 2.23606797749979\n",
      "(5, 3) 28 1.4142135623730951\n",
      "(5, 4) 29 1.0\n",
      "(6, 0) 30 4.0\n",
      "(6, 1) 31 3.0\n",
      "(6, 2) 32 2.0\n",
      "(6, 3) 33 1.0\n",
      "(6, 4) 34 0.0\n",
      "(7, 0) 35 4.123105625617661\n",
      "(7, 1) 36 3.1622776601683795\n",
      "(7, 2) 37 2.23606797749979\n",
      "(7, 3) 38 1.4142135623730951\n",
      "(7, 4) 39 1.0\n"
     ]
    }
   ],
   "source": [
    "for i, loc in enumerate(grid_locations):\n",
    "    x = ((goal_location[0] - loc[0])**2 + (goal_location[1] - loc[1])**2) ** 0.5\n",
    "    print(loc, i, x)\n",
    "    C[0][i] -= x * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27888974 0.32917961 0.36754447 0.39172375 0.4        0.35968758\n",
      " 0.41690481 0.46148352 0.49009805 0.5        0.43431458 0.5\n",
      " 0.5527864  0.58768944 0.6        0.5        0.57573593 0.63944487\n",
      " 0.68377223 0.7        0.5527864  0.63944487 0.71715729 0.7763932\n",
      " 0.8        0.58768944 0.68377223 0.7763932  0.85857864 0.9\n",
      " 0.6        0.7        0.8        0.9        2.         0.58768944\n",
      " 0.68377223 0.7763932  0.85857864 0.9       ]\n"
     ]
    }
   ],
   "source": [
    "print(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.maths import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "C[0] = softmax(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_beliefs(C[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/ISEF/Active Inference/Active-Inference-2025/auxilaryfunctions.py:33\u001b[0m, in \u001b[0;36mplot_beliefs\u001b[0;34m(belief_dist, title_str)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_beliefs\u001b[39m(belief_dist, title_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    Plot a categorical distribution or belief distribution, stored in the 1-D numpy vector `belief_dist`\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(belief_dist\u001b[38;5;241m.\u001b[39msum(), \u001b[38;5;241m1.0\u001b[39m):\n\u001b[1;32m     36\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistribution not normalized! Please normalize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "plot_beliefs(C[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C[1] - Preference for color observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# white, red, green <- order it's encoded in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1 -1.   1.1]\n"
     ]
    }
   ],
   "source": [
    "# Set preferences for color observations\n",
    "C[1] = np.zeros((num_obs[1],))\n",
    "C[1][0] = -0.1\n",
    "C[1][1] = -1\n",
    "C[1][2] = 1.1\n",
    "\n",
    "print(C[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D Vectors: Prior beliefs about hidden states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 3]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "num_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = utils.obj_array_uniform(num_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D[0] - Belief About Current Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D[0] shape (Location prior): (40,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define prior belief about agent's location (same as before)\n",
    "D[0] = np.zeros(num_states[0])  # Shape (35,)\n",
    "D[0][grid_locations.index(agent_pos)] = 1.0  # One-hot encoding for location\n",
    "\n",
    "print(\"D[0] shape (Location prior):\", D[0].shape)  # (35,)\n",
    "D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize uniform distribution over locations\n",
    "# D[0] = np.ones(num_states[0]) / num_states[0]  # Create normalized uniform distribution over all locations\n",
    "\n",
    "# D[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D[1] - Belief About Attribute of Current Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[1] = np.ones(num_states[1]) / num_states[1]  # Create normalized uniform distribution over all locations\n",
    "D[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_beliefs(D[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/ISEF/Active Inference/Active-Inference-2025/auxilaryfunctions.py:33\u001b[0m, in \u001b[0;36mplot_beliefs\u001b[0;34m(belief_dist, title_str)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_beliefs\u001b[39m(belief_dist, title_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    Plot a categorical distribution or belief distribution, stored in the 1-D numpy vector `belief_dist`\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(belief_dist\u001b[38;5;241m.\u001b[39msum(), \u001b[38;5;241m1.0\u001b[39m):\n\u001b[1;32m     36\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistribution not normalized! Please normalize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "plot_beliefs(D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_beliefs(D[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/ISEF/Active Inference/Active-Inference-2025/auxilaryfunctions.py:33\u001b[0m, in \u001b[0;36mplot_beliefs\u001b[0;34m(belief_dist, title_str)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_beliefs\u001b[39m(belief_dist, title_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    Plot a categorical distribution or belief distribution, stored in the 1-D numpy vector `belief_dist`\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(belief_dist\u001b[38;5;241m.\u001b[39msum(), \u001b[38;5;241m1.0\u001b[39m):\n\u001b[1;32m     36\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistribution not normalized! Please normalize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "plot_beliefs(D[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vision(current_location, grid_dims, distance):\n",
    "    \"\"\"\n",
    "    Update the agent's field of vision based on the current location and distance\n",
    "    Returns a list of all grid positions within the vision range\n",
    "    \n",
    "    Args:\n",
    "        current_location (tuple): Current (x,y) position of the agent\n",
    "        grid_dims (list): Dimensions of the grid [width, height]\n",
    "        distance (int): Vision range/distance\n",
    "        \n",
    "    Returns:\n",
    "        list: List of (x,y) tuples representing visible grid positions\n",
    "    \"\"\"\n",
    "    x, y = current_location\n",
    "    x_min = max(0, x - distance)\n",
    "    x_max = min(grid_dims[0], x + distance + 1)\n",
    "    y_min = max(0, y - distance)\n",
    "    y_max = min(grid_dims[1], y + distance + 1)\n",
    "    \n",
    "    visible_locations = []\n",
    "    for y_pos in range(y_min, y_max):\n",
    "        for x_pos in range(x_min, x_max):\n",
    "            visible_locations.append((x_pos, y_pos))\n",
    "            \n",
    "    return visible_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv():\n",
    "    def __init__(self, starting_loc=(0, 0), redspots=[(1, 2), (3, 2), (4, 4), (6, 1)], goal=(6,4)):\n",
    "        # Initialize coordinates\n",
    "        self.x, self.y = starting_loc\n",
    "        self.init_loc = starting_loc\n",
    "        self.current_location = (self.x, self.y)\n",
    "\n",
    "        self.goal = goal\n",
    "\n",
    "        self.redspots = redspots\n",
    "\n",
    "        self.red_obs = ['Null']\n",
    "        self.green_obs = 'Null'\n",
    "        self.white_obs = ['Null']\n",
    "\n",
    "        self.agent_reward = 0\n",
    "        \n",
    "        print(f\"Starting location is {self.current_location} | Red spot locations are {self.redspots} | Goal is {self.goal}\")\n",
    "    \n",
    "    def step(self, action_label):\n",
    "        if action_label == \"UP\": \n",
    "            self.y = max(0, self.y - 1)  # Move up (decrease y)\n",
    "            \n",
    "        elif action_label == \"DOWN\": \n",
    "            self.y = min(grid_dims[1] - 1, self.y + 1)  # Move down (increase y)\n",
    "\n",
    "        elif action_label == \"LEFT\": \n",
    "            self.x = max(0, self.x - 1)  # Move left (decrease x)\n",
    "\n",
    "        elif action_label == \"RIGHT\": \n",
    "            self.x = min(grid_dims[0] - 1, self.x + 1)  # Move right (increase x)\n",
    "\n",
    "        # Update current_location tuple after movement\n",
    "        self.current_location = (self.x, self.y)\n",
    "        print(f\"self.current_location: {self.current_location}\")\n",
    "        \n",
    "        # Update vision with current coordinates\n",
    "        self.vision = update_vision(self.current_location, grid_dims, 6)\n",
    "\n",
    "        self.loc_obs = self.current_location\n",
    "\n",
    "        # Reset observations at each step\n",
    "        self.red_obs = ['Null']\n",
    "        self.white_obs = ['Null']\n",
    "        self.green_obs = 'Null'\n",
    "\n",
    "        # Update observations based on vision\n",
    "        for spot in self.vision:\n",
    "            if spot in self.redspots:\n",
    "                if 'Null' in self.red_obs:\n",
    "                    self.red_obs = [spot]\n",
    "                else:\n",
    "                    self.red_obs.append(spot)\n",
    "            elif spot == self.goal:\n",
    "                self.green_obs = spot\n",
    "            else:\n",
    "                if 'Null' in self.white_obs:\n",
    "                    self.white_obs = [spot]\n",
    "                else:\n",
    "                    self.white_obs.append(spot)\n",
    "\n",
    "        # Update rewards and observations based on current location\n",
    "        if self.current_location in self.redspots:\n",
    "            self.agent_reward -= 5\n",
    "            if 'Null' in self.red_obs:\n",
    "                self.red_obs = [self.current_location]\n",
    "            else:\n",
    "                self.red_obs.append(self.current_location)\n",
    "        elif self.current_location == self.goal:\n",
    "            self.agent_reward += 20\n",
    "            self.green_obs = self.current_location\n",
    "        else:\n",
    "            if 'Null' in self.white_obs:\n",
    "                self.white_obs = [self.current_location]\n",
    "            else:\n",
    "                self.white_obs.append(self.current_location)\n",
    "        \n",
    "        return self.loc_obs, self.green_obs, self.white_obs, self.red_obs, self.agent_reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x, self.y = self.init_loc\n",
    "        self.current_location = (self.x, self.y)\n",
    "        print(f'Re-initialized location to {self.current_location}')\n",
    "        self.loc_obs = self.current_location\n",
    "        self.green_obs, self.white_obs, self.red_obs, self.agent_reward = 'Null', ['Null'], ['Null'], 0\n",
    "\n",
    "        return self.loc_obs, self.green_obs, self.white_obs, self.red_obs, self.agent_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pymdp import utils\n",
    "\n",
    "class RuleMatrixAgent:\n",
    "    def __init__(self, pymdp_agent, rule_matrix):\n",
    "        self.agent = pymdp_agent\n",
    "        self.rule_matrix = rule_matrix\n",
    "        \n",
    "    def infer_policies(self):\n",
    "        \"\"\"\n",
    "        Policy inference using rule matrix to predict attributes of next locations\n",
    "        \"\"\"\n",
    "        policies = self.agent.policies\n",
    "        policy_values = np.zeros(len(policies))\n",
    "        \n",
    "        # Get current location from beliefs\n",
    "        current_loc = np.argmax(self.agent.qs[0])\n",
    "        \n",
    "        for pol_idx, policy in enumerate(policies):\n",
    "            # Get first action (you could extend this to consider full sequence)\n",
    "            action = policy[0]\n",
    "            \n",
    "            # Use B[0] to predict next location\n",
    "            next_loc_dist = self.agent.B[0][:, current_loc, action]\n",
    "            next_loc = np.argmax(next_loc_dist)\n",
    "            \n",
    "            # Use rule matrix to predict attributes at next location\n",
    "            predicted_attributes = self.rule_matrix[next_loc]\n",
    "            \n",
    "            # Calculate value components\n",
    "            pragmatic_value = self._calculate_pragmatic_value(predicted_attributes)\n",
    "            epistemic_value = self._calculate_epistemic_value(predicted_attributes)\n",
    "            \n",
    "            # Combine values (you can adjust these weights)\n",
    "            policy_values[pol_idx] = pragmatic_value + 0.5 * epistemic_value\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        policy_probs = utils.softmax(-policy_values)  # Negative because we minimize free energy\n",
    "        self.agent.q_pi = policy_probs\n",
    "        \n",
    "        return policy_probs\n",
    "    \n",
    "    def _calculate_pragmatic_value(self, predicted_attributes):\n",
    "        \"\"\"\n",
    "        Calculate pragmatic value by comparing predicted attributes with preferences\n",
    "        \"\"\"\n",
    "        # Get preferences from C matrix\n",
    "        preferences = self.agent.C[1]  # Your preferences over attributes\n",
    "        \n",
    "        # Calculate how well predicted attributes match preferences\n",
    "        # Using negative KL divergence as measure of alignment\n",
    "        pragmatic_value = -np.sum(predicted_attributes * np.log(predicted_attributes / preferences + 1e-16))\n",
    "        \n",
    "        return pragmatic_value\n",
    "    \n",
    "    def _calculate_epistemic_value(self, predicted_attributes):\n",
    "        \"\"\"\n",
    "        Calculate epistemic value (encourages exploration of uncertain locations)\n",
    "        \"\"\"\n",
    "        # Calculate entropy of predictions (higher means more uncertain)\n",
    "        entropy = -np.sum(predicted_attributes * np.log(predicted_attributes + 1e-16))\n",
    "        \n",
    "        return entropy\n",
    "    \n",
    "    def sample_action(self):\n",
    "        \"\"\"Use original agent's action sampling\"\"\"\n",
    "        return self.agent.sample_action()\n",
    "\n",
    "# Helper function to create predicted observations\n",
    "def get_predicted_obs(location_id, attribute_beliefs, A):\n",
    "    \"\"\"\n",
    "    Generate predicted observations given location and attribute beliefs\n",
    "    \"\"\"\n",
    "    # Location observation (from A[0])\n",
    "    loc_obs = A[0][:, location_id, :]  # Shape: [num_loc_obs, num_attr]\n",
    "    \n",
    "    # Attribute observation (from A[1])\n",
    "    attr_obs = np.zeros(A[1].shape[0])  # Shape: [num_attr_obs]\n",
    "    for attr_idx in range(len(attribute_beliefs)):\n",
    "        attr_obs += attribute_beliefs[attr_idx] * A[1][:, location_id, attr_idx]\n",
    "    \n",
    "    return [loc_obs, attr_obs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0), [(1, 2), (3, 2), (4, 4), (6, 1)], (6, 4))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_pos, redspots, goal_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting location is (0, 0) | Red spot locations are [(1, 2), (3, 2), (4, 4), (6, 1)] | Goal is (6, 4)\n"
     ]
    }
   ],
   "source": [
    "my_agent = Agent(A=A, B=B, C=C, D=D, policy_len=6)\n",
    "\n",
    "my_env = GridWorldEnv(starting_loc = agent_pos, redspots=redspots, goal = goal_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initialized location to (0, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 0), 'Null', ['Null'], ['Null'], 0)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_obs, green_obs, white_obs, red_obs, agent_reward = my_env.reset()\n",
    "loc_obs, green_obs, white_obs, red_obs, agent_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_location: (0, 0)\n"
     ]
    }
   ],
   "source": [
    "loc_obs, green_obs, white_obs, red_obs, agent_reward = my_env.step('STAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0),\n",
       " (6, 4),\n",
       " [(0, 0),\n",
       "  (1, 0),\n",
       "  (2, 0),\n",
       "  (3, 0),\n",
       "  (4, 0),\n",
       "  (5, 0),\n",
       "  (6, 0),\n",
       "  (0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (0, 2),\n",
       "  (2, 2),\n",
       "  (4, 2),\n",
       "  (5, 2),\n",
       "  (6, 2),\n",
       "  (0, 3),\n",
       "  (1, 3),\n",
       "  (2, 3),\n",
       "  (3, 3),\n",
       "  (4, 3),\n",
       "  (5, 3),\n",
       "  (6, 3),\n",
       "  (0, 4),\n",
       "  (1, 4),\n",
       "  (2, 4),\n",
       "  (3, 4),\n",
       "  (5, 4),\n",
       "  (0, 0)],\n",
       " [(6, 1), (1, 2), (3, 2), (4, 4)],\n",
       " 0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_obs, green_obs, white_obs, red_obs, agent_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4),\n",
       " (5, 0),\n",
       " (5, 1),\n",
       " (5, 2),\n",
       " (5, 3),\n",
       " (5, 4),\n",
       " (6, 0),\n",
       " (6, 1),\n",
       " (6, 2),\n",
       " (6, 3),\n",
       " (6, 4),\n",
       " (7, 0),\n",
       " (7, 1),\n",
       " (7, 2),\n",
       " (7, 3),\n",
       " (7, 4)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_color_observation(position, red_obs, green_obs, white_obs):\n",
    "\n",
    "    if red_obs != ['Null']:\n",
    "        if position in red_obs: return 1  # RED\n",
    "    if green_obs == position: return 2 # GREEN\n",
    "    elif white_obs != ['Null']:\n",
    "        if position in white_obs: return 0 # WHITE\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_observation(position, red_obs, green_obs, white_obs):\n",
    "    return [grid_locations.index(position), create_color_observation(position, red_obs, green_obs, white_obs), create_color_observation((position[0] + 1, position[1]), red_obs, green_obs, white_obs), create_color_observation((position[0] - 1, position[1]), red_obs, green_obs, white_obs), create_color_observation((position[0], position[1] - 1), red_obs, green_obs, white_obs), create_color_observation((position[0], position[1] + 1), red_obs, green_obs, white_obs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "        0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "        0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "        0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "        0.025, 0.025, 0.025, 0.025]),\n",
       " array([0.33333333, 0.33333333, 0.33333333]))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_agent.qs[0], my_agent.qs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 3, 3, 0]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = create_observation(loc_obs, red_obs, green_obs, white_obs)\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [0, 0, 0, 3, 3, 0]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m qs \u001b[38;5;241m=\u001b[39m my_agent\u001b[38;5;241m.\u001b[39minfer_states(obs) \u001b[38;5;66;03m#directly updates using bayesian inference \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# plot belief posterior\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m plot_beliefs(qs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     17\u001b[0m plot_beliefs(qs[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# use belief posterior to update rule matrix\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ISEF/Active Inference/Active-Inference-2025/auxilaryfunctions.py:33\u001b[0m, in \u001b[0;36mplot_beliefs\u001b[0;34m(belief_dist, title_str)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_beliefs\u001b[39m(belief_dist, title_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    Plot a categorical distribution or belief distribution, stored in the 1-D numpy vector `belief_dist`\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misclose(belief_dist\u001b[38;5;241m.\u001b[39msum(), \u001b[38;5;241m1.0\u001b[39m):\n\u001b[1;32m     36\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistribution not normalized! Please normalize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "history_of_locs = [loc_obs]\n",
    "\n",
    "T = 15\n",
    "\n",
    "for t in range(T):\n",
    "\n",
    "    obs = create_observation(loc_obs, red_obs, green_obs, white_obs)\n",
    "\n",
    "    # generate observations\n",
    "    print(f\"Observation: {obs}\")\n",
    "\n",
    "    # belief posterior\n",
    "    qs = my_agent.infer_states(obs) #directly updates using bayesian inference \n",
    "\n",
    "    # plot belief posterior\n",
    "    plot_beliefs(qs[0])\n",
    "    plot_beliefs(qs[1])\n",
    "\n",
    "    # use belief posterior to update rule matrix\n",
    "    rule_matrix = update_rule_matrix(rule_matrix, qs)\n",
    "    print(f\"Rule Matrix at loc {loc_obs}: {rule_matrix[obs[0]]}\")\n",
    "\n",
    "    # ruled based update on A\n",
    "    # A = rule_based_update_A(rule_matrix, A)\n",
    "\n",
    "    # plot updated A\n",
    "    # plot_A_1(A)\n",
    "\n",
    "\n",
    "    # policy selection\n",
    "    my_agent.infer_policies()\n",
    "    \n",
    "    chosen_action_id = my_agent.sample_action()\n",
    "\n",
    "    movement_id = int(chosen_action_id[0])\n",
    "\n",
    "    choice_action = actions[movement_id]\n",
    "\n",
    "    print(f'Action at time {t}: {choice_action}')\n",
    "\n",
    "    \n",
    "    loc_obs, green_obs, white_obs, red_obs, agent_reward = my_env.step(choice_action)\n",
    "    \n",
    "    print(agent_reward, loc_obs, green_obs, white_obs, red_obs)\n",
    "\n",
    "\n",
    "    history_of_locs.append(loc_obs)\n",
    "\n",
    "    print(f'Grid location at time {t}: {loc_obs}')\n",
    "\n",
    "    print(f'Reward at time {t}: {agent_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
